<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>码医森</title>
    <meta name="description" content="计算机知识的学习站点">
    <meta name="generator" content="VitePress v1.3.4">
    <link rel="preload stylesheet" href="/coderethan.fun/assets/style.D9JbDeNL.css" as="style">
    
    <script type="module" src="/coderethan.fun/assets/app.C5oIWCkS.js"></script>
    <link rel="preload" href="/coderethan.fun/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/coderethan.fun/assets/chunks/theme.D7xZ4-YD.js">
    <link rel="modulepreload" href="/coderethan.fun/assets/chunks/framework.BeQAQrs6.js">
    <link rel="modulepreload" href="/coderethan.fun/assets/Job_Interview_Algorithm_post_model_framework_001_Transformer.md.CeEbpbiM.lean.js">
    <link rel="icon" type="image/svg+xml" href="/imgs/home-page-logo.svg">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css" crossorigin="">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0f60ec36></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0f60ec36> Skip to content </a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-ab179fa1><a class="title" href="/coderethan.fun/" data-v-ab179fa1><!--[--><!--]--><!--[--><img class="VPImage logo" src="/coderethan.fun/imgs/home-page-logo.svg" alt data-v-8426fc1a><!--]--><span data-v-ab179fa1>CoderEthan学习站</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>AI</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/AI/01_deep_learning_theory/" data-v-43f1e123><!--[-->DL基础理论<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/AI/02_distribute_training/" data-v-43f1e123><!--[-->分布式训练<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/AI/03_Transformer/" data-v-43f1e123><!--[-->Transformer个人梳理<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/AI/04_some_notes/" data-v-43f1e123><!--[-->DL个人笔记<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>计算机学科内容</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/IT-learning/408/" data-v-43f1e123><!--[-->408知识<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/IT-learning/c++/" data-v-43f1e123><!--[-->C++基础<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/IT-learning/Java/" data-v-43f1e123><!--[-->Java后端<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/IT-learning/Linux/" data-v-43f1e123><!--[-->Linux技术<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>求职面试</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/Job_Interview/Java/" data-v-43f1e123><!--[-->Java面经<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/Job_Interview/Algorithm_post/" data-v-43f1e123><!--[-->算法岗<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>其他维护</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/update/update_log.html" data-v-43f1e123><!--[-->站点更新<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/question_list/" data-v-43f1e123><!--[-->问题清单<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>感悟和日常</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/about_me/" data-v-43f1e123><!--[-->关于我<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/coderethan.fun/my_think/" data-v-43f1e123><!--[-->站长感悟<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link vp-external-link-icon" href="https://EthanLiu6.github.io" target="_blank" rel="noreferrer" data-v-43f1e123><!--[-->旧版博客<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ethanliu6/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a class="VPSocialLink no-icon" href="https://space.bilibili.com/1327099977/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z"/></svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-b6c34ac9><span class="vpi-more-horizontal icon" data-v-b6c34ac9></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>深色模式</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ethanliu6/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a class="VPSocialLink no-icon" href="https://space.bilibili.com/1327099977/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z"/></svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-17a5e62e><button data-v-17a5e62e>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 has-active" data-v-c40bc020 data-v-b7550ba0><!----><div class="items" data-v-b7550ba0><!--[--><section class="VPSidebarItem level-1 collapsible collapsed has-active" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>Algorithm_post</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><section class="VPSidebarItem level-2 collapsible collapsed has-active" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h4 class="text" data-v-b7550ba0>model_framework</h4><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/model_framework/001_Transformer.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>001_Transformer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/model_framework/002_Normalization.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>002_Normalization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/model_framework/003_Position-Embedding.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>003_Position-Embedding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/model_framework/004_Activation.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>004_Activation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/model_framework/005_Transformer-Other.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>005_Transformer-Other</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/model_framework/006_LLM-Frame.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>006_LLM-Frame</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/model_framework/007_MoE.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>007_MoE</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/model_framework/基础内容面试点.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>基础内容面试点</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/model_framework/手撕内容.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>手撕内容</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-2 collapsible collapsed" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h4 class="text" data-v-b7550ba0>sum_knowledge</h4><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p0-00_场景题.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p0-00_场景题</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p1-01_分词器.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p1-01_分词器</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p1-02_词向量.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p1-02_词向量</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p2-01_注意力机制.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p2-01_注意力机制</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p2-02_位置编码.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p2-02_位置编码</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p2-03_归一化.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p2-03_归一化</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p2-04_残差连接.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p2-04_残差连接</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p3-01_多层感知机.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p3-01_多层感知机</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p3-02_激活函数.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p3-02_激活函数</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p3-03_损失函数.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p3-03_损失函数</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p4-01_预训练技术.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p4-01_预训练技术</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p5-01_后训练技术.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p5-01_后训练技术</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p6-01_推理优化.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p6-01_推理优化</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p7-01_大模型架构.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p7-01_大模型架构</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p8_01_大模型应用.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p8_01_大模型应用</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-3 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/coderethan.fun/Job_Interview/Algorithm_post/sum_knowledge/p9-01_torch的数据.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>p9-01_torch的数据</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>本文目录</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _coderethan_fun_Job_Interview_Algorithm_post_model_framework_001_Transformer" data-v-39a288b8><div><h1 align="center"><p>001_Transformer</p></h1><h2 id="_1-基本架构" tabindex="-1">1. 基本架构 <a class="header-anchor" href="#_1-基本架构" aria-label="Permalink to &quot;1. 基本架构&quot;">​</a></h2><p>中英文对照论文：<a href="https://yiyibooks.cn/arxiv/1706.03762v7/index.html" target="_blank" rel="noreferrer">Attention Is All You Need</a></p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250425144838781.png" alt="image-20250425144838781"><h3 id="_1-1-编码器" tabindex="-1">1.1 编码器 <a class="header-anchor" href="#_1-1-编码器" aria-label="Permalink to &quot;1.1 编码器&quot;">​</a></h3><p>编码器由N = 6 个完全相同的层堆叠而成。 每一层都有两个子层。 第一个子层是一个<code>multi-head self-attention</code>机制，第二个子层是一个简单的、位置完全连接的前馈网络(<code>FFN</code>)。 我们对每个子层再采用一个残差连接(代码使用<code>short_cut</code>或者<code>res_net</code>指代)，接着进行层标准化（代码用<code>Norm</code>指代）。也就是说，每个子层的输出是<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>L</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mi>N</mi><mi>o</mi><mi>r</mi><mi>m</mi><mo>(</mo><mi>x</mi><mo>+</mo><mi>S</mi><mi>u</mi><mi>b</mi><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">LayerNorm(x + Sublayer(x))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit">L</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit" style="margin-right:0.10903em;">N</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">m</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mbin">+</span><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mord mathit">u</span><span class="mord mathit">b</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span>，其中<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>S</mi><mi>u</mi><mi>b</mi><mi>l</mi><mi>a</mi><mi>y</mi><mi>e</mi><mi>r</mi><mo>(</mo><mi>x</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">Sublayer(x)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.05764em;">S</span><span class="mord mathit">u</span><span class="mord mathit">b</span><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mord mathit">a</span><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mclose">)</span></span></span></span> 是由子层本身实现的函数。 为了方便这些残差连接，模型中的所有子层以及嵌入层产生的输出维度都为<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{model}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">m</span><span class="mord mathit">o</span><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> = 512。</p><h3 id="_1-2-解码器" tabindex="-1">1.2 解码器 <a class="header-anchor" href="#_1-2-解码器" aria-label="Permalink to &quot;1.2 解码器&quot;">​</a></h3><p>解码器同样由N = 6 个完全相同的层堆叠而成。除了每个编码器层中的两个子层之外，<strong>解码器还插入第三个子层</strong>，该层对编码器堆栈的输出执行<code>multi-head attention</code>。 与编码器类似，我们在每个子层再采用残差连接，然后进行层标准化。 <strong>我们还修改解码器堆栈中的self-attention子层，以防止位置关注到后面的位置。 这种掩码结合将输出嵌入偏移一个位置，确保对位置的预测 i 只能依赖小于i 的已知输出。</strong>——Masking（sequence masking）</p><h3 id="_1-3-pipeline" tabindex="-1">1.3 Pipeline <a class="header-anchor" href="#_1-3-pipeline" aria-label="Permalink to &quot;1.3 Pipeline&quot;">​</a></h3><p><code>Encoder</code>:</p> Tensor Input -&gt; Input Embedding -&gt; Positional Embedding \\ -&gt;Short-Cut 、 Multi-Head Attention -&gt; Short-Cut + Attention -&gt; Norm \\ -&gt; Short-Cut 、FFN(Linear + Activation) -&gt; Short-Cut + Out -&gt; Norm | ✖️N <p><code>Decoder</code>:</p><p>根据架构图同上整理</p><h2 id="_2-主要组件" tabindex="-1">2. 主要组件 <a class="header-anchor" href="#_2-主要组件" aria-label="Permalink to &quot;2. 主要组件&quot;">​</a></h2><ul><li><p>残差连接（short cut）</p></li><li><p>注意力机制（self attention）</p><p>Scaled Dot-Product Attention</p><p>Multi-Head Attention</p><p>Cross Multi-Head Attention</p></li><li><p>全连接层（FFN）</p></li><li><p>归一化层（Norm）</p></li><li><p>Dropout</p></li><li><p>掩码机制（Masking）</p></li><li><p>位置编码（Position Embedding）</p></li></ul><h3 id="_2-1-scaled-dot-product-attention" tabindex="-1">2.1 Scaled Dot-Product Attention <a class="header-anchor" href="#_2-1-scaled-dot-product-attention" aria-label="Permalink to &quot;2.1 Scaled Dot-Product Attention&quot;">​</a></h3><p>就是标准的注意力机制，需要除以<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msqrt><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8572200000000001em;"></span><span class="strut bottom" style="height:1.04em;vertical-align:-0.18278em;"></span><span class="base textstyle uncramped"><span class="sqrt mord"><span class="sqrt-sign" style="top:-0.017220000000000013em;"><span class="style-wrap reset-textstyle textstyle uncramped">√</span></span><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="mord textstyle cramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span style="top:-0.77722em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped sqrt-line"></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span></span></span></span></p><p>Attention可以描述为将query和一组 <strong>key-value对</strong> 映射到输出(output)，其中query、key、value和 output都是向量(vector)。 输出为value的加权和，其中分配给每个value的权重通过query与相应key的兼容函数来计算。</p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250425145018652.png" alt="image-20250425145018652"> $$ Attention(Q, K, V)=softmax(\frac{Q K^{T}}{\sqrt{d_{k}}}) V $$ <h3 id="_2-2-multi-head-self-attention" tabindex="-1">2.2 Multi-Head self Attention <a class="header-anchor" href="#_2-2-multi-head-self-attention" aria-label="Permalink to &quot;2.2 Multi-Head self Attention&quot;">​</a></h3><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250425150546293.png" alt="image-20250425150546293"> $$ MultiHead(Q, K, V) = Concat(head_{1}, \ldots, head_{h}) W^{O} $$ <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>e</mi><mi>h</mi><mi>e</mi><mi>a</mi><msub><mi>d</mi><mrow><mi>i</mi></mrow></msub><mo>=</mo><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>(</mo><mi>Q</mi><msubsup><mi>W</mi><mrow><mi>i</mi></mrow><mrow><mi>Q</mi></mrow></msubsup><mo separator="true">,</mo><mi>K</mi><msubsup><mi>W</mi><mrow><mi>i</mi></mrow><mrow><mi>K</mi></mrow></msubsup><mo separator="true">,</mo><mi>V</mi><msubsup><mi>W</mi><mrow><mi>i</mi></mrow><mrow><mi>V</mi></mrow></msubsup><mo>)</mo></mrow><annotation encoding="application/x-tex">where head_{i} = Attention(Q W_{i}^{Q}, K W_{i}^{K}, V W_{i}^{V}) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.9592389999999998em;"></span><span class="strut bottom" style="height:1.236103em;vertical-align:-0.276864em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord mathit">h</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.02778em;">r</span><span class="mord mathit">e</span><span class="mord mathit">h</span><span class="mord mathit">e</span><span class="mord mathit">a</span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathit">A</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span><span class="mord mathit">n</span><span class="mord mathit">t</span><span class="mord mathit">i</span><span class="mord mathit">o</span><span class="mord mathit">n</span><span class="mopen">(</span><span class="mord mathit">Q</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.276864em;margin-left:-0.13889em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span></span></span></span><span style="top:-0.4809079999999999em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit">Q</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.07153em;">K</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.247em;margin-left:-0.13889em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span></span></span></span><span style="top:-0.4129999999999999em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.07153em;">K</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.247em;margin-left:-0.13889em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span></span></span></span><span style="top:-0.4129999999999999em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.22222em;">V</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></span></p><p>其中：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msubsup><mi>W</mi><mrow><mi>i</mi></mrow><mrow><mi>Q</mi></mrow></msubsup><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><msub><mi>d</mi><mrow><mi>k</mi></mrow></msub></mrow></msup><mo separator="true">;</mo><msubsup><mi>W</mi><mrow><mi>i</mi></mrow><mrow><mi>K</mi></mrow></msubsup><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><msub><mi>d</mi><mrow><mi>k</mi></mrow></msub></mrow></msup><mo separator="true">;</mo><msubsup><mi>W</mi><mrow><mi>i</mi></mrow><mrow><mi>V</mi></mrow></msubsup><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub><mo>×</mo><msub><mi>d</mi><mrow><mi>v</mi></mrow></msub></mrow></msup><mo separator="true">;</mo><msup><mi>W</mi><mrow><mi>O</mi></mrow></msup><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>h</mi><msub><mi>d</mi><mrow><mi>v</mi></mrow></msub><mo>×</mo><msub><mi>d</mi><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><mi>l</mi></mrow></msub></mrow></msup></mrow><annotation encoding="application/x-tex">W_{i}^{Q} \in \mathbb{R}^{d_{model} \times d_{k}}; W_{i}^{K} \in \mathbb{R}^{d_{model} \times d_{k}}; W_{i}^{V} \in \mathbb{R}^{d_{model} \times d_{v}}; W^{O} \in \mathbb{R}^{hd_{v} \times d_{model}} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.9592389999999998em;"></span><span class="strut bottom" style="height:1.236103em;vertical-align:-0.276864em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.276864em;margin-left:-0.13889em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span></span></span></span><span style="top:-0.4809079999999999em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit">Q</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">∈</span><span class=""><span class="mord displaystyle textstyle uncramped"><span class="mord mathbb">R</span></span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15122857142857138em;margin-right:0.07142857142857144em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit">m</span><span class="mord mathit">o</span><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">×</span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15122857142857138em;margin-right:0.07142857142857144em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">;</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.247em;margin-left:-0.13889em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span></span></span></span><span style="top:-0.4129999999999999em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.07153em;">K</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">∈</span><span class=""><span class="mord displaystyle textstyle uncramped"><span class="mord mathbb">R</span></span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15122857142857138em;margin-right:0.07142857142857144em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit">m</span><span class="mord mathit">o</span><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">×</span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15122857142857138em;margin-right:0.07142857142857144em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">;</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:0.247em;margin-left:-0.13889em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">i</span></span></span></span><span style="top:-0.4129999999999999em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.22222em;">V</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">∈</span><span class=""><span class="mord displaystyle textstyle uncramped"><span class="mord mathbb">R</span></span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15122857142857138em;margin-right:0.07142857142857144em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit">m</span><span class="mord mathit">o</span><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">×</span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.07142857142857144em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit" style="margin-right:0.03588em;">v</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">;</span><span class="mord"><span class="mord mathit" style="margin-right:0.13889em;">W</span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.02778em;">O</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">∈</span><span class=""><span class="mord displaystyle textstyle uncramped"><span class="mord mathbb">R</span></span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit">h</span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.07142857142857144em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit" style="margin-right:0.03588em;">v</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">×</span><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15122857142857138em;margin-right:0.07142857142857144em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit">m</span><span class="mord mathit">o</span><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mord mathit" style="margin-right:0.01968em;">l</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></p><h3 id="_2-3-cross-multi-head-attention" tabindex="-1">2.3 Cross Multi-Head Attention <a class="header-anchor" href="#_2-3-cross-multi-head-attention" aria-label="Permalink to &quot;2.3 Cross Multi-Head Attention&quot;">​</a></h3><p>将encoder的key和value与decoder的query进行attention，论文好像没有明确指出这一块内容</p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250425151609839.png" alt="image-20250425151609839"><h3 id="_2-4-ffn" tabindex="-1">2.4 FFN <a class="header-anchor" href="#_2-4-ffn" aria-label="Permalink to &quot;2.4 FFN&quot;">​</a></h3><p>Position-wise 类型的 Feed-Forward Networks</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250425152721037.png" alt="image-20250425152721037"></p><p>论文指出了几点，我这里height light了一下：</p><ul><li>每个编码和解码层都有一个扩展的FFN子层</li><li>两个线性转换和一个默认的ReLU激活函数</li><li>说相当于用了个两个大小为1的卷积核？</li><li>FFN层先是将输入（MHA的输出）进行进行<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><msub><mi>l</mi><mrow><mi>d</mi><mi>i</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">model_{dim}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord mathit">m</span><span class="mord mathit">o</span><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mord"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.01968em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">d</span><span class="mord mathit">i</span><span class="mord mathit">m</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>✖️4的操作，然后再转成<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>m</mi><mi>o</mi><mi>d</mi><mi>e</mi><msub><mi>l</mi><mrow><mi>d</mi><mi>i</mi><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">model_{dim}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord mathit">m</span><span class="mord mathit">o</span><span class="mord mathit">d</span><span class="mord mathit">e</span><span class="mord"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.01968em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">d</span><span class="mord mathit">i</span><span class="mord mathit">m</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>（两个线性转换）。</li></ul><h2 id="_3-其他组件" tabindex="-1">3. 其他组件 <a class="header-anchor" href="#_3-其他组件" aria-label="Permalink to &quot;3. 其他组件&quot;">​</a></h2><h3 id="_3-1-掩码机制-masking" tabindex="-1">3.1 掩码机制（Masking） <a class="header-anchor" href="#_3-1-掩码机制-masking" aria-label="Permalink to &quot;3.1 掩码机制（Masking）&quot;">​</a></h3><p>mask 表示掩码，它对某些值进行掩盖，使其在参数更新时不产生效果。Transformer 模型里面涉及两种 mask，分别是 padding mask 和 sequence mask。</p><p>两个的计算原理一样：xxxx（待补充）</p><p><strong>思考</strong>：为什么需要添加这两种mask码呢？？？</p><h4 id="padding-mask" tabindex="-1">padding mask <a class="header-anchor" href="#padding-mask" aria-label="Permalink to &quot;padding mask&quot;">​</a></h4><p>什么是 padding mask 呢？因为每个批次输入序列长度是不一样的也就是说，我们要对输入序列进行对齐。具体来说，就是给在较短的序列后面填充 0。但是如果输入的序列太长，则是截取左边的内容，把多余的直接舍弃。因为这些填充的位置，其实是没什么意义的，所以我们的attention机制不应该把注意力放在这些位置上，所以我们需要进行一些处理。</p><p>具体的做法是，把<strong>这些位置</strong>的值<strong>加上一个非常大的负数(负无穷)</strong>，这样的话，经过 softmax，这些位置的概率就会接近0！</p><p><strong>思考</strong>：上句中的 &quot;这些位置&quot; 指哪些位置呢？</p><ul><li>pytorch 代码实现</li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> attention</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(query, key, value, mask</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, dropout</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;Compute &#39;Scaled Dot Product Attention&#39;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    d_k </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> query.size(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    scores </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.matmul(query, key.transpose(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> math.sqrt(d_k)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        scores </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> scores.masked_fill(mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">==</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1e9</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># mask步骤，用 -1e9 代表负无穷</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    p_attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> F.softmax(scores, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">dim</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dropout </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> not</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        p_attn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> dropout(p_attn)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.matmul(p_attn, value), p_attn</span></span></code></pre></div><h4 id="sequence-mask" tabindex="-1">sequence mask <a class="header-anchor" href="#sequence-mask" aria-label="Permalink to &quot;sequence mask&quot;">​</a></h4><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/attention-figure19.jpg" alt="figure19"></p><p>sequence mask 是为了使得 decoder 不能看见未来的信息。对于一个序列，在 time_step 为 t 的时刻，我们的解码输出应该只能依赖于 t 时刻之前的输出，而不能依赖 t 之后的输出。因此我们需要想一个办法，把 t 之后的信息给隐藏起来。这在训练的时候有效，因为训练的时候每次我们是将target数据完整输入进decoder中地，预测时不需要，预测的时候我们只能得到前一时刻预测出的输出。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/attention-figure20.jpg" alt="figure20"></p><p>        那么具体怎么做呢？也很简单：产生一个上三角矩阵，上三角的值全为0。把这个矩阵作用在每一个序列上，就可以达到我们的目的。</p><p><strong>思考：</strong></p><ul><li>decoder 中需要 padding mask 吗？</li></ul><h3 id="_3-2-位置编码-position-embedding" tabindex="-1">3.2 位置编码（Position Embedding） <a class="header-anchor" href="#_3-2-位置编码-position-embedding" aria-label="Permalink to &quot;3.2 位置编码（Position Embedding）&quot;">​</a></h3><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/image-20250425160140494.png" alt="image-20250425160140494"></p><p>论文指出使用的是三角位置编码，可以想想，为啥可以实现位置编码呢？有怎样的效果呢？（后续位置编码章节会讲）</p><h3 id="_3-3-other" tabindex="-1">3.3 Other <a class="header-anchor" href="#_3-3-other" aria-label="Permalink to &quot;3.3 Other&quot;">​</a></h3><p>由于别的一些组件适合一个章节讲解，有很多细节知识，单独列成模块讲解了</p><p>包括：</p><ul><li><p>别的Attention</p></li><li><p>位置编码</p></li><li><p>Norm</p></li><li><p>Activation</p></li><li><p>等等</p></li></ul><h2 id="_4-补充" tabindex="-1">4. 补充 <a class="header-anchor" href="#_4-补充" aria-label="Permalink to &quot;4. 补充&quot;">​</a></h2><p>MQA</p><p>GQA</p><p>Flash Attention</p><p>重计算</p><p>KV-cache</p><p>Page Attention</p><h2 id="_5-代码实现" tabindex="-1">5. 代码实现 <a class="header-anchor" href="#_5-代码实现" aria-label="Permalink to &quot;5. 代码实现&quot;">​</a></h2><h2 id="n-面试问题" tabindex="-1">n. 面试问题 <a class="header-anchor" href="#n-面试问题" aria-label="Permalink to &quot;n. 面试问题&quot;">​</a></h2><ul><li><p>为什么需要qkv参数矩阵，不能共用同一个吗？</p><p>每个的作用不一样，………………</p></li><li><p>为啥要除以<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msqrt><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow></msqrt></mrow><annotation encoding="application/x-tex">\sqrt{d_k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8572200000000001em;"></span><span class="strut bottom" style="height:1.04em;vertical-align:-0.18278em;"></span><span class="base textstyle uncramped"><span class="sqrt mord"><span class="sqrt-sign" style="top:-0.017220000000000013em;"><span class="style-wrap reset-textstyle textstyle uncramped">√</span></span><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="mord textstyle cramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span style="top:-0.77722em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped sqrt-line"></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span></span></span></span></p><p>代码演示矩阵乘法使用缩放和不使用缩放的对比。</p><blockquote><p>当 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mrow><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 的值比较小的时候，两种点积机制(additive 和 Dot-Product)的性能相差相近，当 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mrow><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 比较大时，additive attention 比不带scale 的点积attention性能好。 我们怀疑，对于很大的 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>d</mi><mrow><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">d_{k}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span> 值，点积大幅度增长，将softmax函数推向具有极小梯度的区域。 为了抵消这种影响，我们缩小点积 <span class="katex"><span class="katex-mathml"><math><semantics><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><msqrt><mrow><msub><mi>d</mi><mrow><mi>k</mi></mrow></msub></mrow></msqrt></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{\sqrt{d_{k}}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.845108em;"></span><span class="strut bottom" style="height:1.695108em;vertical-align:-0.8500000000000001em;"></span><span class="base textstyle uncramped"><span class="mord reset-textstyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.585124em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="sqrt mord"><span class="sqrt-sign" style="top:0.0926800000000001em;"><span class="style-wrap reset-scriptstyle textstyle uncramped">√</span></span><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1.4285714285714286em;">​</span></span><span class="mord scriptstyle cramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15122857142857138em;margin-right:0.07142857142857144em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-scriptstyle scriptscriptstyle cramped"><span class="mord scriptscriptstyle cramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span style="top:-0.9930342857142858em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1.4285714285714286em;">​</span></span><span class="reset-scriptstyle textstyle uncramped sqrt-line"></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1.4285714285714286em;">​</span></span>​</span></span></span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.394em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span></span></span></span> 倍。</p></blockquote></li><li><p>为什么拆多头？有什么作用？</p><p>子空间信息多样化（有点类似卷积的多个<code>channel</code>）。好像还可以减少计算量（显存占用量/计算量好像减少了<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi><mi>u</mi><msub><mi>m</mi><mrow><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi></mrow></msub></mrow><annotation encoding="application/x-tex">num_{head}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord mathit">n</span><span class="mord mathit">u</span><span class="mord"><span class="mord mathit">m</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">h</span><span class="mord mathit">e</span><span class="mord mathit">a</span><span class="mord mathit">d</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>倍）</p></li><li><p>self Attention如何实现多模态？</p><p>交叉注意力实现。</p></li><li><p>self attention和传统的attention的区别？</p></li><li><p>想想Transformer架构中存在哪些问题？</p></li></ul></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><div class="edit-info" data-v-e257564d><div class="edit-link" data-v-e257564d><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/EthanLiu6/coderethan.fun/edit/master/docs/Job_Interview/Algorithm_post/model_framework/001_Transformer.md" target="_blank" rel="noreferrer" data-v-e257564d><!--[--><span class="vpi-square-pen edit-link-icon" data-v-e257564d></span> 在 GitHub 上编辑此页面 OR 提出修改意见<!--]--></a></div><div class="last-updated" data-v-e257564d><p class="VPLastUpdated" data-v-e257564d data-v-e98dd255>最后更新于: <time datetime="2025-05-05T11:18:22.000Z" data-v-e98dd255></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><!----></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/coderethan.fun/Job_Interview/Algorithm_post/model_framework/002_Normalization.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>下一篇</span><span class="title" data-v-e257564d>002_Normalization</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>ICP备案号: <a href="https://beian.miit.gov.cn/" target="_blank">蜀ICP备2024103116号</a><br>公安备案号: <a href="https://beian.mps.gov.cn/#/query/webSearch?code=51012202001928" rel="noreferrer" target="_blank">川公网安备51012202001928</a></p><p class="copyright" data-v-e315a0ad>版权所有 © 2024-present  <a href="mailto:16693226842@163.com" target="_blank">Ethan.Liu</a></p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"about_me_index.md\":\"DF0XToGq\",\"ai_01_deep_learning_theory_01-feedforward_network.md\":\"DIpgqYGB\",\"ai_01_deep_learning_theory_02-back_propagation.md\":\"Blbq7YAs\",\"ai_01_deep_learning_theory_03-bp_example_demo.md\":\"xt6vGpEq\",\"ai_01_deep_learning_theory_04-convolution_neural_network.md\":\"YfR-Qt53\",\"ai_01_deep_learning_theory_05-deep_learning_model.md\":\"CTvvbCFX\",\"ai_01_deep_learning_theory_06-pytorch_install.md\":\"BPKuLNgO\",\"ai_01_deep_learning_theory_07-operators.md\":\"LvlW_G0r\",\"ai_01_deep_learning_theory_08-activation_functions.md\":\"vyGttYWL\",\"ai_01_deep_learning_theory_09-recurrent_neural_network.md\":\"DCq2p6kn\",\"ai_01_deep_learning_theory_10-seq2seq.md\":\"BuFx0onP\",\"ai_01_deep_learning_theory_11-1attentions.md\":\"DrzuDLVN\",\"ai_01_deep_learning_theory_11-2attention-extension.md\":\"Xk7hJtKs\",\"ai_01_deep_learning_theory_12-weight-initialization.md\":\"BQ65F-SO\",\"ai_01_deep_learning_theory_13-optimizers.md\":\"BRJ4KeJn\",\"ai_01_deep_learning_theory_14-regularization.md\":\"CXohbHeX\",\"ai_01_deep_learning_theory_15-deep-learning-tuning-guide.md\":\"Bk0rbWUW\",\"ai_01_deep_learning_theory_20-pytorch-tensor.md\":\"BejcuNqN\",\"ai_01_deep_learning_theory_21-pytorch-autograd.md\":\"_vv5eHTO\",\"ai_01_deep_learning_theory_22-pytorch-module.md\":\"C3YBQkER\",\"ai_01_deep_learning_theory_23-1training-example-1.md\":\"BNhBJ0a9\",\"ai_01_deep_learning_theory_23-2decoder.md\":\"DiYSNGB0\",\"ai_01_deep_learning_theory_23-3encoder.md\":\"DRhlWRn4\",\"ai_01_deep_learning_theory_23-4transformer.md\":\"CHmHg_T-\",\"ai_01_deep_learning_theory_24-pytorch-optimizer.md\":\"g3LP7aG2\",\"ai_01_deep_learning_theory_25-pytorch-lr-scheduler.md\":\"CiiBsK2t\",\"ai_01_deep_learning_theory_26-pytorch-dataloader.md\":\"BSphvQJI\",\"ai_01_deep_learning_theory_27-pytorch-model-save.md\":\"BVPcWNXa\",\"ai_01_deep_learning_theory_28-pytorch-tensorboard.md\":\"BaXM3pVi\",\"ai_01_deep_learning_theory_29-pytorch-graph-mode.md\":\"BOOGIsG9\",\"ai_01_deep_learning_theory_30-1training-example-cv.md\":\"D7JJ6CKg\",\"ai_01_deep_learning_theory_30-3main.md\":\"Fmlk240H\",\"ai_01_deep_learning_theory_31-1stable-diffusion.md\":\"Bws0cvyJ\",\"ai_01_deep_learning_theory_31-2sdxl.md\":\"Bd5liW10\",\"ai_01_deep_learning_theory_31-3vae.md\":\"DGDpRfCj\",\"ai_01_deep_learning_theory_40-nlp-bert_ner.md\":\"BpoxirJ4\",\"ai_01_deep_learning_theory_41-nlp-t5_question-answering.md\":\"QuYOTbUH\",\"ai_01_deep_learning_theory_42-nlp-gpt.md\":\"B1LnLqPO\",\"ai_01_deep_learning_theory_43-scaling-law.md\":\"CkjVNj1E\",\"ai_01_deep_learning_theory_44-distribute-training.md\":\"DMSckbyl\",\"ai_01_deep_learning_theory_45-llm-history.md\":\"_g-_wcg_\",\"ai_01_deep_learning_theory_46-llm-gpt-extension.md\":\"FPvyiDwm\",\"ai_01_deep_learning_theory_46-nlp-llama.md\":\"BY7AT8aJ\",\"ai_01_deep_learning_theory_47-llm-deepseek-structure.md\":\"0xSzQeUQ\",\"ai_01_deep_learning_theory_47-nlp-deepseek.md\":\"BsiX7np3\",\"ai_01_deep_learning_theory_index.md\":\"BvD_I_-i\",\"ai_02_distribute_training_00_large-scale-model-trainning.md\":\"BDkg6SXY\",\"ai_02_distribute_training_01_coding.md\":\"DmxjycWq\",\"ai_02_distribute_training_01_offload-and-recompute.md\":\"B6YXqR-r\",\"ai_02_distribute_training_02_amp.md\":\"DNDJ3AzF\",\"ai_02_distribute_training_03_coding.md\":\"ZZALraAN\",\"ai_02_distribute_training_03_pytorch-dp.md\":\"CFbJ5uJI\",\"ai_02_distribute_training_04_pytorch-ddp.md\":\"zIyawoCC\",\"ai_02_distribute_training_05_pytorch-ddp-impl.md\":\"DKOfzXbO\",\"ai_02_distribute_training_05_pytorch-ddp-impl_ddp_origin.md\":\"CKPJt_Ir\",\"ai_02_distribute_training_06_collective-comm.md\":\"CnEbQ-u4\",\"ai_02_distribute_training_06_torchrun-process-group.md\":\"Bjzh6Vz8\",\"ai_02_distribute_training_07_zero-optimizer.md\":\"Cy3_cYlJ\",\"ai_02_distribute_training_08_pytorch-zero-1.md\":\"BzcxCgDK\",\"ai_02_distribute_training_09_pytorch-fsdp-v1.md\":\"CQX5ue8J\",\"ai_02_distribute_training_10_pytorch-fsdp-v2.md\":\"xFf4rkku\",\"ai_02_distribute_training_11_deepspeed-zero-1-2-impl.md\":\"BXI4ZUdq\",\"ai_02_distribute_training_12_deepspeed-zero-3-impl.md\":\"C-eYn_CC\",\"ai_02_distribute_training_13_megatron-zero-1-impl.md\":\"BVlhGBYz\",\"ai_02_distribute_training_14_tp-theory.md\":\"DFc5HZip\",\"ai_02_distribute_training_15_megatron-tp-impl.md\":\"CStsGeTd\",\"ai_02_distribute_training_16_pytorch-tp-impl.md\":\"IqwLqWgk\",\"ai_02_distribute_training_17_pp-theory.md\":\"DLIWlELm\",\"ai_02_distribute_training_18_pytorch-pp-impl.md\":\"DVriXvzt\",\"ai_02_distribute_training_19_deepspeed-pp-impl.md\":\"zgtKtVaU\",\"ai_02_distribute_training_20_megatron-pp-impl.md\":\"BzYtdOww\",\"ai_02_distribute_training_21_sp-theory.md\":\"BldiNa3z\",\"ai_02_distribute_training_22_megatron-sp-impl.md\":\"CVBcVOn3\",\"ai_02_distribute_training_23_3d-parallel-theory.md\":\"DkIyIq5r\",\"ai_02_distribute_training_24_megatron-3d-parallel-impl.md\":\"gvcazdkf\",\"ai_02_distribute_training_25_pytorch-3d-parallel-impl.md\":\"CnjJLBya\",\"ai_02_distribute_training_26_cp-theory.md\":\"BfszhVTk\",\"ai_02_distribute_training_27_megatron-cp-impl.md\":\"BmtUyiTJ\",\"ai_02_distribute_training_28_moe-theory.md\":\"CBT2j6YT\",\"ai_02_distribute_training_28_moe-theory_deepseekmoe.md\":\"DcmH5bX-\",\"ai_02_distribute_training_29_megatron-moe-impl.md\":\"Bja7L7vW\",\"ai_02_distribute_training_30_deepspeed-moe-impl.md\":\"D5CzV7uS\",\"ai_02_distribute_training_31_deepspeed-code-impl.md\":\"DhNHhTj4\",\"ai_02_distribute_training_32_collective-operations.md\":\"CEoZAkd0\",\"ai_02_distribute_training_33_pytorch_distribute.md\":\"Dn3A_aL0\",\"ai_02_distribute_training_index.md\":\"T1UzsBSM\",\"ai_03_transformer_01-transformer的由来.md\":\"Dzy_N2vV\",\"ai_03_transformer_02-transformer架构解读.md\":\"DRvxW43c\",\"ai_03_transformer_03-transformer源码构建.md\":\"DQlNgMWc\",\"ai_03_transformer_index.md\":\"DvhOuLqV\",\"ai_04_some_notes_00-dl_base_notes.md\":\"Chj4c2td\",\"ai_04_some_notes_01-class_logs.md\":\"tAramf61\",\"ai_04_some_notes_02-some_detials.md\":\"DKjALQos\",\"ai_04_some_notes_03-bert理解.md\":\"C80jAmP_\",\"ai_04_some_notes_04-个人补充内容.md\":\"CvMgreuh\",\"ai_04_some_notes_05-review_dl.md\":\"Bk86fR07\",\"ai_04_some_notes_index.md\":\"DgsRlYce\",\"ai_index.md\":\"CKCt2z04\",\"index.md\":\"Cn_peQp3\",\"it-learning_408_index.md\":\"ppUREhtL\",\"it-learning_408_os-4.1 进程同步.md\":\"C2rpoW_B\",\"it-learning_408_os-4.4 信号量机制.md\":\"Dt7xYFBw\",\"it-learning_408_os-4.4 信号量机制pv操作之“可见”.md\":\"fTb3yG59\",\"it-learning_c___01_开发环境搭建与基础数据类型.md\":\"C5gFD_pt\",\"it-learning_c___02_控制流语句与复合数据类型.md\":\"CY7GiVmV\",\"it-learning_c___03_指针与引用.md\":\"BpRI-hHv\",\"it-learning_c___04_自定义数据类型与函数.md\":\"DEitLEHv\",\"it-learning_c___05_头文件与指针的算术运算.md\":\"BRPbP2fc\",\"it-learning_c___06_字符串、数组、指针与函数.md\":\"BYc8WcJ7\",\"it-learning_c___07_函数进阶与内存管理.md\":\"BAGxzN2n\",\"it-learning_c___08_运算符优先级表.md\":\"qe6_-fco\",\"it-learning_c___09_指针、内存管理和类的基础.md\":\"Bls0OzOJ\",\"it-learning_c___10_深入类和对象.md\":\"Dezh8RyI\",\"it-learning_c___11_类的大小、继承与权限控制.md\":\"CFRH3hxf\",\"it-learning_c___12_继承进阶.md\":\"DvSZYtVs\",\"it-learning_c___13_类型转换和多态与虚函数.md\":\"B_P72hnh\",\"it-learning_c___14_纯虚函数、抽象类、深浅拷贝及智能指针.md\":\"B7Tv_eAY\",\"it-learning_c___15_运算符重载与 string 类详解.md\":\"flsIXlM3\",\"it-learning_c___16_有序容器与无序容器.md\":\"D0d3eFo4\",\"it-learning_c___17_模板.md\":\"C8A8QDcv\",\"it-learning_c___18_迭代器与其应用.md\":\"DZF7ctDY\",\"it-learning_c___19_c__ 标准库常用算法.md\":\"F-ezCI8J\",\"it-learning_c___20_c__ 异常处理 - 第19次课.md\":\"ClaKq_88\",\"it-learning_c___21_友元及友元相关内容.md\":\"D4othzV6\",\"it-learning_c___22_c__ io 流详解-feadbc607d7f.md\":\"UrPheL4L\",\"it-learning_c___23_c__ io 流详解.md\":\"Cpyui8bl\",\"it-learning_c___24_位运算符总结.md\":\"aKJNxqS5\",\"it-learning_c___25_c__三种继承方式.md\":\"CO9rudOF\",\"it-learning_c___26_c__11 高级特性.md\":\"DRlUU39v\",\"it-learning_c___27_c__14 新特性.md\":\"_RxabsTe\",\"it-learning_c___28_c__17 新特性.md\":\"DQFcFa9o\",\"it-learning_c___29_多文件和 makefile工程管理.md\":\"Dxyaccwj\",\"it-learning_c___30_c__大型项目cmake工程管理.md\":\"CU3ygGdl\",\"it-learning_c___31_c__ 主要就业方向与技术能力分析报告.md\":\"DJ9EPNMF\",\"it-learning_c___32_c__ 基础知识回顾.md\":\"ChluR7dj\",\"it-learning_c___index.md\":\"BzpicGU1\",\"it-learning_index.md\":\"C9cMawnH\",\"it-learning_java_01.java-se.md\":\"bs0Qdsna\",\"it-learning_java_02.sql.md\":\"BrLhLI3z\",\"it-learning_java_03.java-web.md\":\"CFDrIACU\",\"it-learning_java_05.mybatis.md\":\"f-70Dwbe\",\"it-learning_java_index.md\":\"BL4qA826\",\"it-learning_linux_01.linux基础.md\":\"BLOpk2s4\",\"it-learning_linux_02.shell.md\":\"lO10hp7Q\",\"it-learning_linux_03.mpi并行计算.md\":\"DXICZPnS\",\"it-learning_linux_04.docker.md\":\"BI5M61fP\",\"it-learning_linux_index.md\":\"DkctALpE\",\"job_interview_algorithm_post_index.md\":\"C8w6b2pP\",\"job_interview_algorithm_post_model_framework_001_transformer.md\":\"CeEbpbiM\",\"job_interview_algorithm_post_model_framework_002_normalization.md\":\"wQ2orVQf\",\"job_interview_algorithm_post_model_framework_003_position-embedding.md\":\"BCO0NOSl\",\"job_interview_algorithm_post_model_framework_004_activation.md\":\"CdhiQtww\",\"job_interview_algorithm_post_model_framework_005_transformer-other.md\":\"DMAvJKM1\",\"job_interview_algorithm_post_model_framework_006_llm-frame.md\":\"Dafs6FdM\",\"job_interview_algorithm_post_model_framework_007_moe.md\":\"DlLQcC6O\",\"job_interview_algorithm_post_model_framework_基础内容面试点.md\":\"DuT-baDh\",\"job_interview_algorithm_post_model_framework_手撕内容.md\":\"KRnELWrd\",\"job_interview_algorithm_post_sum_knowledge_index.md\":\"B1LQfVat\",\"job_interview_algorithm_post_sum_knowledge_p0-00_场景题.md\":\"Cay1Rf2C\",\"job_interview_algorithm_post_sum_knowledge_p1-01_分词器.md\":\"BNijw4Sb\",\"job_interview_algorithm_post_sum_knowledge_p1-02_词向量.md\":\"Bs-Lhr7v\",\"job_interview_algorithm_post_sum_knowledge_p2-01_注意力机制.md\":\"DiUNbRJX\",\"job_interview_algorithm_post_sum_knowledge_p2-02_位置编码.md\":\"CuLDke5a\",\"job_interview_algorithm_post_sum_knowledge_p2-03_归一化.md\":\"BU5kvEwi\",\"job_interview_algorithm_post_sum_knowledge_p2-04_残差连接.md\":\"CVDjGAf0\",\"job_interview_algorithm_post_sum_knowledge_p3-01_多层感知机.md\":\"U13u3tgr\",\"job_interview_algorithm_post_sum_knowledge_p3-02_激活函数.md\":\"yipi_QG3\",\"job_interview_algorithm_post_sum_knowledge_p3-03_损失函数.md\":\"Nc_9xyvt\",\"job_interview_algorithm_post_sum_knowledge_p4-01_预训练技术.md\":\"C-Om3ki_\",\"job_interview_algorithm_post_sum_knowledge_p5-01_后训练技术.md\":\"Dq5MqZEP\",\"job_interview_algorithm_post_sum_knowledge_p6-01_推理优化.md\":\"DIDEfISj\",\"job_interview_algorithm_post_sum_knowledge_p7-01_大模型架构.md\":\"B-7JPbGS\",\"job_interview_algorithm_post_sum_knowledge_p8_01_大模型应用.md\":\"Aq5LTQWb\",\"job_interview_algorithm_post_sum_knowledge_p9-01_torch的数据.md\":\"BkXSEEDI\",\"job_interview_index.md\":\"BBgeZzwy\",\"job_interview_java_index.md\":\"DKLbu7of\",\"my_think_01_不同商家的视野.md\":\"sT2yMJGd\",\"my_think_02_学而篇.md\":\"CwD_KnrK\",\"my_think_03_重温士兵突击.md\":\"Bu_XEEtI\",\"my_think_04_你很好，慢慢来.md\":\"CQF1tbFY\",\"my_think_05_健康是第一重要.md\":\"rqodUTPO\",\"my_think_index.md\":\"CDPpgvD7\",\"question_list_doccano账户管理.md\":\"8Jh51eRY\",\"question_list_index.md\":\"6stVy9ev\",\"question_list_专英翻转课堂—pytorch.md\":\"y2YUJt94\",\"question_list_虚拟机网络问题.md\":\"QHa8XAJo\",\"readme.md\":\"V8Yvo9Hy\",\"update_update_log.md\":\"C2PJtEtK\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"码医森\",\"description\":\"计算机知识的学习站点\",\"base\":\"/coderethan.fun/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"siteTitle\":\"CoderEthan学习站\",\"logo\":\"/imgs/home-page-logo.svg\",\"outline\":{\"label\":\"本文目录\",\"level\":[2,4]},\"search\":{\"provider\":\"local\"},\"socialLinks\":[{\"icon\":{\"svg\":\"<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" viewBox=\\\"0 0 496 512\\\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\\\"#6841d2\\\" d=\\\"M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z\\\"/></svg>\"},\"link\":\"https://github.com/ethanliu6/\"},{\"icon\":{\"svg\":\"<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" viewBox=\\\"0 0 512 512\\\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\\\"#6841d2\\\" d=\\\"M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z\\\"/></svg>\"},\"link\":\"https://space.bilibili.com/1327099977/\"}],\"nav\":[{\"text\":\"AI\",\"items\":[{\"text\":\"DL基础理论\",\"link\":\"/AI/01_deep_learning_theory/\"},{\"text\":\"分布式训练\",\"link\":\"/AI/02_distribute_training/\"},{\"text\":\"Transformer个人梳理\",\"link\":\"/AI/03_Transformer/\"},{\"text\":\"DL个人笔记\",\"link\":\"/AI/04_some_notes/\"}]},{\"text\":\"计算机学科内容\",\"items\":[{\"text\":\"408知识\",\"link\":\"/IT-learning/408/\"},{\"text\":\"C++基础\",\"link\":\"/IT-learning/c++/\"},{\"text\":\"Java后端\",\"link\":\"/IT-learning/Java/\"},{\"text\":\"Linux技术\",\"link\":\"/IT-learning/Linux/\"}]},{\"text\":\"求职面试\",\"items\":[{\"text\":\"Java面经\",\"link\":\"/Job_Interview/Java/\"},{\"text\":\"算法岗\",\"link\":\"/Job_Interview/Algorithm_post/\"}]},{\"text\":\"其他维护\",\"items\":[{\"text\":\"站点更新\",\"link\":\"/update/update_log\"},{\"text\":\"问题清单\",\"link\":\"/question_list/\"}]},{\"text\":\"感悟和日常\",\"items\":[{\"text\":\"关于我\",\"link\":\"/about_me/\"},{\"text\":\"站长感悟\",\"link\":\"/my_think/\"},{\"text\":\"旧版博客\",\"link\":\"https://EthanLiu6.github.io\"}]}],\"footer\":{\"message\":\"ICP备案号: <a href=\\\"https://beian.miit.gov.cn/\\\" target=\\\"_blank\\\">蜀ICP备2024103116号</a><br>公安备案号: <a href=\\\"https://beian.mps.gov.cn/#/query/webSearch?code=51012202001928\\\" rel=\\\"noreferrer\\\" target=\\\"_blank\\\">川公网安备51012202001928</a>\",\"copyright\":\"版权所有 © 2024-present  <a href=\\\"mailto:16693226842@163.com\\\" target=\\\"_blank\\\">Ethan.Liu</a>\"},\"editLink\":{\"pattern\":\"https://github.com/EthanLiu6/coderethan.fun/edit/master/docs/:path\",\"text\":\"在 GitHub 上编辑此页面 OR 提出修改意见\"},\"lastUpdated\":{\"text\":\"最后更新于\",\"formatOptions\":{\"dateStyle\":\"long\",\"timeStyle\":\"short\"}},\"docFooter\":{\"prev\":\"上一篇\",\"next\":\"下一篇\"},\"darkModeSwitchLabel\":\"深色模式\",\"lightModeSwitchTitle\":\"切换到浅色模式\",\"darkModeSwitchTitle\":\"切换到深色模式\",\"sidebar\":{\"/AI/\":[{\"items\":[{\"text\":\"01_deep_learning_theory\",\"items\":[{\"text\":\"01-feedforward_network\",\"link\":\"/AI/01_deep_learning_theory/01-feedforward_network.html\"},{\"text\":\"02-back_propagation\",\"link\":\"/AI/01_deep_learning_theory/02-back_propagation.html\"},{\"text\":\"03-bp_example_demo\",\"link\":\"/AI/01_deep_learning_theory/03-bp_example_demo.html\"},{\"text\":\"04-convolution_neural_network\",\"link\":\"/AI/01_deep_learning_theory/04-convolution_neural_network.html\"},{\"text\":\"05-deep_learning_model\",\"link\":\"/AI/01_deep_learning_theory/05-deep_learning_model.html\"},{\"text\":\"06-pytorch_install\",\"link\":\"/AI/01_deep_learning_theory/06-pytorch_install.html\"},{\"text\":\"07-operators\",\"link\":\"/AI/01_deep_learning_theory/07-operators.html\"},{\"text\":\"08-activation_functions\",\"link\":\"/AI/01_deep_learning_theory/08-activation_functions.html\"},{\"text\":\"09-recurrent_neural_network\",\"link\":\"/AI/01_deep_learning_theory/09-recurrent_neural_network.html\"},{\"text\":\"10-seq2seq\",\"link\":\"/AI/01_deep_learning_theory/10-seq2seq.html\"},{\"text\":\"11-1attentions\",\"link\":\"/AI/01_deep_learning_theory/11-1attentions.html\"},{\"text\":\"11-2attention-extension\",\"link\":\"/AI/01_deep_learning_theory/11-2attention-extension.html\"},{\"text\":\"12-weight-initialization\",\"link\":\"/AI/01_deep_learning_theory/12-weight-initialization.html\"},{\"text\":\"13-optimizers\",\"link\":\"/AI/01_deep_learning_theory/13-optimizers.html\"},{\"text\":\"14-regularization\",\"link\":\"/AI/01_deep_learning_theory/14-regularization.html\"},{\"text\":\"15-deep-learning-tuning-guide\",\"link\":\"/AI/01_deep_learning_theory/15-deep-learning-tuning-guide.html\"},{\"text\":\"20-pytorch-tensor\",\"link\":\"/AI/01_deep_learning_theory/20-pytorch-tensor.html\"},{\"text\":\"21-pytorch-autograd\",\"link\":\"/AI/01_deep_learning_theory/21-pytorch-autograd.html\"},{\"text\":\"22-pytorch-module\",\"link\":\"/AI/01_deep_learning_theory/22-pytorch-module.html\"},{\"text\":\"23-1training-example-1\",\"link\":\"/AI/01_deep_learning_theory/23-1training-example-1.html\"},{\"text\":\"23-2decoder\",\"link\":\"/AI/01_deep_learning_theory/23-2decoder.html\"},{\"text\":\"23-3encoder\",\"link\":\"/AI/01_deep_learning_theory/23-3encoder.html\"},{\"text\":\"23-4transformer\",\"link\":\"/AI/01_deep_learning_theory/23-4transformer.html\"},{\"text\":\"24-pytorch-optimizer\",\"link\":\"/AI/01_deep_learning_theory/24-pytorch-optimizer.html\"},{\"text\":\"25-pytorch-lr-scheduler\",\"link\":\"/AI/01_deep_learning_theory/25-pytorch-lr-scheduler.html\"},{\"text\":\"26-pytorch-dataloader\",\"link\":\"/AI/01_deep_learning_theory/26-pytorch-dataloader.html\"},{\"text\":\"27-pytorch-model-save\",\"link\":\"/AI/01_deep_learning_theory/27-pytorch-model-save.html\"},{\"text\":\"28-pytorch-tensorboard\",\"link\":\"/AI/01_deep_learning_theory/28-pytorch-tensorboard.html\"},{\"text\":\"29-pytorch-graph-mode\",\"link\":\"/AI/01_deep_learning_theory/29-pytorch-graph-mode.html\"},{\"text\":\"30-1training-example-cv\",\"link\":\"/AI/01_deep_learning_theory/30-1training-example-cv.html\"},{\"text\":\"30-3main\",\"link\":\"/AI/01_deep_learning_theory/30-3main.html\"},{\"text\":\"31-1stable-diffusion\",\"link\":\"/AI/01_deep_learning_theory/31-1stable-diffusion.html\"},{\"text\":\"31-2SDXL\",\"link\":\"/AI/01_deep_learning_theory/31-2SDXL.html\"},{\"text\":\"31-3VAE\",\"link\":\"/AI/01_deep_learning_theory/31-3VAE.html\"},{\"text\":\"40-nlp-bert_ner\",\"link\":\"/AI/01_deep_learning_theory/40-nlp-bert_ner.html\"},{\"text\":\"41-nlp-t5_question-answering\",\"link\":\"/AI/01_deep_learning_theory/41-nlp-t5_question-answering.html\"},{\"text\":\"42-nlp-gpt\",\"link\":\"/AI/01_deep_learning_theory/42-nlp-gpt.html\"},{\"text\":\"43-scaling-law\",\"link\":\"/AI/01_deep_learning_theory/43-scaling-law.html\"},{\"text\":\"44-distribute-training\",\"link\":\"/AI/01_deep_learning_theory/44-distribute-training.html\"},{\"text\":\"45-LLM-History\",\"link\":\"/AI/01_deep_learning_theory/45-LLM-History.html\"},{\"text\":\"46-LLM-GPT-Extension\",\"link\":\"/AI/01_deep_learning_theory/46-LLM-GPT-Extension.html\"},{\"text\":\"46-nlp-llama\",\"link\":\"/AI/01_deep_learning_theory/46-nlp-llama.html\"},{\"text\":\"47-LLM-DeepSeek-Structure\",\"link\":\"/AI/01_deep_learning_theory/47-LLM-DeepSeek-Structure.html\"},{\"text\":\"47-nlp-deepseek\",\"link\":\"/AI/01_deep_learning_theory/47-nlp-deepseek.html\"}],\"collapsed\":true},{\"text\":\"02_distribute_training\",\"items\":[{\"text\":\"00_large-scale-model-trainning\",\"link\":\"/AI/02_distribute_training/00_large-scale-model-trainning.html\"},{\"text\":\"01_coding\",\"link\":\"/AI/02_distribute_training/01_coding.html\"},{\"text\":\"01_offload-and-recompute\",\"link\":\"/AI/02_distribute_training/01_offload-and-recompute.html\"},{\"text\":\"02_amp\",\"link\":\"/AI/02_distribute_training/02_amp.html\"},{\"text\":\"03_coding\",\"link\":\"/AI/02_distribute_training/03_coding.html\"},{\"text\":\"03_pytorch-DP\",\"link\":\"/AI/02_distribute_training/03_pytorch-DP.html\"},{\"text\":\"04_pytorch-DDP\",\"link\":\"/AI/02_distribute_training/04_pytorch-DDP.html\"},{\"text\":\"05_pytorch-DDP-IMPL\",\"link\":\"/AI/02_distribute_training/05_pytorch-DDP-IMPL.html\"},{\"text\":\"05_pytorch-DDP-IMPL_DDP_ORIGIN\",\"link\":\"/AI/02_distribute_training/05_pytorch-DDP-IMPL_DDP_ORIGIN.html\"},{\"text\":\"06_collective-comm\",\"link\":\"/AI/02_distribute_training/06_collective-comm.html\"},{\"text\":\"06_torchrun-process-group\",\"link\":\"/AI/02_distribute_training/06_torchrun-process-group.html\"},{\"text\":\"07_ZeRO-Optimizer\",\"link\":\"/AI/02_distribute_training/07_ZeRO-Optimizer.html\"},{\"text\":\"08_pytorch-ZeRO-1\",\"link\":\"/AI/02_distribute_training/08_pytorch-ZeRO-1.html\"},{\"text\":\"09_pytorch-FSDP-v1\",\"link\":\"/AI/02_distribute_training/09_pytorch-FSDP-v1.html\"},{\"text\":\"10_pytorch-FSDP-v2\",\"link\":\"/AI/02_distribute_training/10_pytorch-FSDP-v2.html\"},{\"text\":\"11_deepspeed-ZeRO-1-2-IMPL\",\"link\":\"/AI/02_distribute_training/11_deepspeed-ZeRO-1-2-IMPL.html\"},{\"text\":\"12_deepspeed-ZeRO-3-IMPL\",\"link\":\"/AI/02_distribute_training/12_deepspeed-ZeRO-3-IMPL.html\"},{\"text\":\"13_megatron-ZeRO-1-IMPL\",\"link\":\"/AI/02_distribute_training/13_megatron-ZeRO-1-IMPL.html\"},{\"text\":\"14_TP-Theory\",\"link\":\"/AI/02_distribute_training/14_TP-Theory.html\"},{\"text\":\"15_megatron-TP-IMPL\",\"link\":\"/AI/02_distribute_training/15_megatron-TP-IMPL.html\"},{\"text\":\"16_pytorch-TP-IMPL\",\"link\":\"/AI/02_distribute_training/16_pytorch-TP-IMPL.html\"},{\"text\":\"17_PP-Theory\",\"link\":\"/AI/02_distribute_training/17_PP-Theory.html\"},{\"text\":\"18_pytorch-PP-IMPL\",\"link\":\"/AI/02_distribute_training/18_pytorch-PP-IMPL.html\"},{\"text\":\"19_deepspeed-PP-IMPL\",\"link\":\"/AI/02_distribute_training/19_deepspeed-PP-IMPL.html\"},{\"text\":\"20_megatron-PP-IMPL\",\"link\":\"/AI/02_distribute_training/20_megatron-PP-IMPL.html\"},{\"text\":\"21_SP-Theory\",\"link\":\"/AI/02_distribute_training/21_SP-Theory.html\"},{\"text\":\"22_megatron-SP-IMPL\",\"link\":\"/AI/02_distribute_training/22_megatron-SP-IMPL.html\"},{\"text\":\"23_3D-Parallel-Theory\",\"link\":\"/AI/02_distribute_training/23_3D-Parallel-Theory.html\"},{\"text\":\"24_megatron-3D-Parallel-IMPL\",\"link\":\"/AI/02_distribute_training/24_megatron-3D-Parallel-IMPL.html\"},{\"text\":\"25_pytorch-3D-Parallel-IMPL\",\"link\":\"/AI/02_distribute_training/25_pytorch-3D-Parallel-IMPL.html\"},{\"text\":\"26_CP-Theory\",\"link\":\"/AI/02_distribute_training/26_CP-Theory.html\"},{\"text\":\"27_megatron-CP-IMPL\",\"link\":\"/AI/02_distribute_training/27_megatron-CP-IMPL.html\"},{\"text\":\"28_MOE-Theory\",\"link\":\"/AI/02_distribute_training/28_MOE-Theory.html\"},{\"text\":\"28_MOE-Theory_DeepSeekMOE\",\"link\":\"/AI/02_distribute_training/28_MOE-Theory_DeepSeekMOE.html\"},{\"text\":\"29_megatron-MOE-IMPL\",\"link\":\"/AI/02_distribute_training/29_megatron-MOE-IMPL.html\"},{\"text\":\"30_deepspeed-MOE-IMPL\",\"link\":\"/AI/02_distribute_training/30_deepspeed-MOE-IMPL.html\"},{\"text\":\"31_deepspeed-code-IMPL\",\"link\":\"/AI/02_distribute_training/31_deepspeed-code-IMPL.html\"},{\"text\":\"32_collective-operations\",\"link\":\"/AI/02_distribute_training/32_collective-operations.html\"},{\"text\":\"33_pytorch_distribute\",\"link\":\"/AI/02_distribute_training/33_pytorch_distribute.html\"}],\"collapsed\":true},{\"text\":\"03_Transformer\",\"items\":[{\"text\":\"01-Transformer的由来\",\"link\":\"/AI/03_Transformer/01-Transformer的由来.html\"},{\"text\":\"02-Transformer架构解读\",\"link\":\"/AI/03_Transformer/02-Transformer架构解读.html\"},{\"text\":\"03-Transformer源码构建\",\"link\":\"/AI/03_Transformer/03-Transformer源码构建.html\"}],\"collapsed\":true},{\"text\":\"04_some_notes\",\"items\":[{\"text\":\"00-DL_base_notes\",\"link\":\"/AI/04_some_notes/00-DL_base_notes.html\"},{\"text\":\"01-class_logs\",\"link\":\"/AI/04_some_notes/01-class_logs.html\"},{\"text\":\"02-some_detials\",\"link\":\"/AI/04_some_notes/02-some_detials.html\"},{\"text\":\"03-Bert理解\",\"link\":\"/AI/04_some_notes/03-Bert理解.html\"},{\"text\":\"04-个人补充内容\",\"link\":\"/AI/04_some_notes/04-个人补充内容.html\"},{\"text\":\"05-Review_DL\",\"link\":\"/AI/04_some_notes/05-Review_DL.html\"}],\"collapsed\":true}]}],\"/IT-learning/\":[{\"items\":[{\"text\":\"408\",\"items\":[{\"text\":\"OS-4.1 进程同步\",\"link\":\"/IT-learning/408/OS-4.1 进程同步.html\"},{\"text\":\"OS-4.4 信号量机制\",\"link\":\"/IT-learning/408/OS-4.4 信号量机制.html\"},{\"text\":\"OS-4.4 信号量机制pv操作之“可见”\",\"link\":\"/IT-learning/408/OS-4.4 信号量机制pv操作之“可见”.html\"}],\"collapsed\":true},{\"text\":\"Java\",\"items\":[{\"text\":\"01.java-se\",\"link\":\"/IT-learning/Java/01.java-se.html\"},{\"text\":\"02.sql\",\"link\":\"/IT-learning/Java/02.sql.html\"},{\"text\":\"03.java-web\",\"link\":\"/IT-learning/Java/03.java-web.html\"},{\"text\":\"05.MyBatis\",\"link\":\"/IT-learning/Java/05.MyBatis.html\"}],\"collapsed\":true},{\"text\":\"Linux\",\"items\":[{\"text\":\"01.Linux基础\",\"link\":\"/IT-learning/Linux/01.Linux基础.html\"},{\"text\":\"02.Shell\",\"link\":\"/IT-learning/Linux/02.Shell.html\"},{\"text\":\"03.MPI并行计算\",\"link\":\"/IT-learning/Linux/03.MPI并行计算.html\"},{\"text\":\"04.Docker\",\"link\":\"/IT-learning/Linux/04.Docker.html\"}],\"collapsed\":true},{\"text\":\"c++\",\"items\":[{\"text\":\"01_开发环境搭建与基础数据类型\",\"link\":\"/IT-learning/c++/01_开发环境搭建与基础数据类型.html\"},{\"text\":\"02_控制流语句与复合数据类型\",\"link\":\"/IT-learning/c++/02_控制流语句与复合数据类型.html\"},{\"text\":\"03_指针与引用\",\"link\":\"/IT-learning/c++/03_指针与引用.html\"},{\"text\":\"04_自定义数据类型与函数\",\"link\":\"/IT-learning/c++/04_自定义数据类型与函数.html\"},{\"text\":\"05_头文件与指针的算术运算\",\"link\":\"/IT-learning/c++/05_头文件与指针的算术运算.html\"},{\"text\":\"06_字符串、数组、指针与函数\",\"link\":\"/IT-learning/c++/06_字符串、数组、指针与函数.html\"},{\"text\":\"07_函数进阶与内存管理\",\"link\":\"/IT-learning/c++/07_函数进阶与内存管理.html\"},{\"text\":\"08_运算符优先级表\",\"link\":\"/IT-learning/c++/08_运算符优先级表.html\"},{\"text\":\"09_指针、内存管理和类的基础\",\"link\":\"/IT-learning/c++/09_指针、内存管理和类的基础.html\"},{\"text\":\"10_深入类和对象\",\"link\":\"/IT-learning/c++/10_深入类和对象.html\"},{\"text\":\"11_类的大小、继承与权限控制\",\"link\":\"/IT-learning/c++/11_类的大小、继承与权限控制.html\"},{\"text\":\"12_继承进阶\",\"link\":\"/IT-learning/c++/12_继承进阶.html\"},{\"text\":\"13_类型转换和多态与虚函数\",\"link\":\"/IT-learning/c++/13_类型转换和多态与虚函数.html\"},{\"text\":\"14_纯虚函数、抽象类、深浅拷贝及智能指针\",\"link\":\"/IT-learning/c++/14_纯虚函数、抽象类、深浅拷贝及智能指针.html\"},{\"text\":\"15_运算符重载与 String 类详解\",\"link\":\"/IT-learning/c++/15_运算符重载与 String 类详解.html\"},{\"text\":\"16_有序容器与无序容器\",\"link\":\"/IT-learning/c++/16_有序容器与无序容器.html\"},{\"text\":\"17_模板\",\"link\":\"/IT-learning/c++/17_模板.html\"},{\"text\":\"18_迭代器与其应用\",\"link\":\"/IT-learning/c++/18_迭代器与其应用.html\"},{\"text\":\"19_C++ 标准库常用算法\",\"link\":\"/IT-learning/c++/19_C++ 标准库常用算法.html\"},{\"text\":\"20_C++ 异常处理 - 第19次课\",\"link\":\"/IT-learning/c++/20_C++ 异常处理 - 第19次课.html\"},{\"text\":\"21_友元及友元相关内容\",\"link\":\"/IT-learning/c++/21_友元及友元相关内容.html\"},{\"text\":\"22_C++ IO 流详解-feadbc607d7f\",\"link\":\"/IT-learning/c++/22_C++ IO 流详解-feadbc607d7f.html\"},{\"text\":\"23_C++ IO 流详解\",\"link\":\"/IT-learning/c++/23_C++ IO 流详解.html\"},{\"text\":\"24_位运算符总结\",\"link\":\"/IT-learning/c++/24_位运算符总结.html\"},{\"text\":\"25_C++三种继承方式\",\"link\":\"/IT-learning/c++/25_C++三种继承方式.html\"},{\"text\":\"26_C++11 高级特性\",\"link\":\"/IT-learning/c++/26_C++11 高级特性.html\"},{\"text\":\"27_C++14 新特性\",\"link\":\"/IT-learning/c++/27_C++14 新特性.html\"},{\"text\":\"28_C++17 新特性\",\"link\":\"/IT-learning/c++/28_C++17 新特性.html\"},{\"text\":\"29_多文件和 Makefile工程管理\",\"link\":\"/IT-learning/c++/29_多文件和 Makefile工程管理.html\"},{\"text\":\"30_C++大型项目CMake工程管理\",\"link\":\"/IT-learning/c++/30_C++大型项目CMake工程管理.html\"},{\"text\":\"31_C++ 主要就业方向与技术能力分析报告\",\"link\":\"/IT-learning/c++/31_C++ 主要就业方向与技术能力分析报告.html\"},{\"text\":\"32_C++ 基础知识回顾\",\"link\":\"/IT-learning/c++/32_C++ 基础知识回顾.html\"}],\"collapsed\":true}]}],\"/Job_Interview/\":[{\"items\":[{\"text\":\"Algorithm_post\",\"items\":[{\"text\":\"model_framework\",\"items\":[{\"text\":\"001_Transformer\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/001_Transformer.html\"},{\"text\":\"002_Normalization\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/002_Normalization.html\"},{\"text\":\"003_Position-Embedding\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/003_Position-Embedding.html\"},{\"text\":\"004_Activation\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/004_Activation.html\"},{\"text\":\"005_Transformer-Other\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/005_Transformer-Other.html\"},{\"text\":\"006_LLM-Frame\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/006_LLM-Frame.html\"},{\"text\":\"007_MoE\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/007_MoE.html\"},{\"text\":\"基础内容面试点\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/基础内容面试点.html\"},{\"text\":\"手撕内容\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/手撕内容.html\"}],\"collapsed\":true},{\"text\":\"sum_knowledge\",\"items\":[{\"text\":\"p0-00_场景题\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p0-00_场景题.html\"},{\"text\":\"p1-01_分词器\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p1-01_分词器.html\"},{\"text\":\"p1-02_词向量\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p1-02_词向量.html\"},{\"text\":\"p2-01_注意力机制\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p2-01_注意力机制.html\"},{\"text\":\"p2-02_位置编码\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p2-02_位置编码.html\"},{\"text\":\"p2-03_归一化\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p2-03_归一化.html\"},{\"text\":\"p2-04_残差连接\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p2-04_残差连接.html\"},{\"text\":\"p3-01_多层感知机\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p3-01_多层感知机.html\"},{\"text\":\"p3-02_激活函数\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p3-02_激活函数.html\"},{\"text\":\"p3-03_损失函数\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p3-03_损失函数.html\"},{\"text\":\"p4-01_预训练技术\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p4-01_预训练技术.html\"},{\"text\":\"p5-01_后训练技术\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p5-01_后训练技术.html\"},{\"text\":\"p6-01_推理优化\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p6-01_推理优化.html\"},{\"text\":\"p7-01_大模型架构\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p7-01_大模型架构.html\"},{\"text\":\"p8_01_大模型应用\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p8_01_大模型应用.html\"},{\"text\":\"p9-01_torch的数据\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p9-01_torch的数据.html\"}],\"collapsed\":true}],\"collapsed\":true}]}],\"/my_think/\":[{\"items\":[{\"text\":\"01_不同商家的视野\",\"link\":\"/my_think/01_不同商家的视野.html\"},{\"text\":\"02_学而篇\",\"link\":\"/my_think/02_学而篇.html\"},{\"text\":\"03_重温士兵突击\",\"link\":\"/my_think/03_重温士兵突击.html\"},{\"text\":\"04_你很好，慢慢来\",\"link\":\"/my_think/04_你很好，慢慢来.html\"},{\"text\":\"05_健康是第一重要\",\"link\":\"/my_think/05_健康是第一重要.html\"}]}],\"/question_list/\":[{\"items\":[{\"text\":\"doccano账户管理\",\"link\":\"/question_list/doccano账户管理.html\"},{\"text\":\"专英翻转课堂—PyTorch\",\"link\":\"/question_list/专英翻转课堂—PyTorch.html\"},{\"text\":\"虚拟机网络问题\",\"link\":\"/question_list/虚拟机网络问题.html\"}]}],\"/update/\":[{\"items\":[{\"text\":\"update_log\",\"link\":\"/update/update_log.html\"}]}]}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>