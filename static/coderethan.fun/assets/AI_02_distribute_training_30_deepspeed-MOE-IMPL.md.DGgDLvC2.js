import{_ as l,c as a,o as r,a2 as t}from"./chunks/framework.DA-Pb-tg.js";const c=JSON.parse('{"title":"1. E + D parallel","description":"","frontmatter":{},"headers":[],"relativePath":"AI/02_distribute_training/30_deepspeed-MOE-IMPL.md","filePath":"AI/02_distribute_training/30_deepspeed-MOE-IMPL.md","lastUpdated":1743069065000}'),i={name:"AI/02_distribute_training/30_deepspeed-MOE-IMPL.md"};function p(o,e,_,d,s,n){return r(),a("div",null,e[0]||(e[0]=[t('<h1 id="_1-e-d-parallel" tabindex="-1">1. E + D parallel <a class="header-anchor" href="#_1-e-d-parallel" aria-label="Permalink to &quot;1. E + D parallel&quot;">​</a></h1><ul><li>world_size = 16</li><li>expert_parallel_size = 2 # number of experts in same group</li><li>data_parallel_group = [0,1,...,15] - all reduce is only on non-MoE</li><li>expert_data_parallel_group = [0,2,4,6,8,10,12,14], [1,3,5,7,9,11,13,15] - all reduce is only on MoE params</li><li>expert_parallel_group = [0,1], [2,3], [4,5], [6,7], [8,9] - no all reduce, but all to all</li><li>use_data_before_expert_parallel_ (bool): Use the D + E instead of E + D topology</li></ul><h1 id="_2-e-m-d-parallel" tabindex="-1">2 E + M + D parallel <a class="header-anchor" href="#_2-e-m-d-parallel" aria-label="Permalink to &quot;2 E + M + D parallel&quot;">​</a></h1><ul><li>world_size = 16</li><li>model_degree = 2</li><li>expert_degree = 4 # number of experts in same group</li><li>data_parallel_group =[0,2,4,6,8,10,12,14], [1,3,5,7,9,11,13,15]</li><li>mp_group = [0,1], [2,3], [4,5], [6,7], [8,9], [10,11], [12,13], [14,15]</li><li>expert_parallel_group = [0,2,4,6], [8,10,12,14] [1,3,5,7], [9,11,13,15]</li><li>expert_data_parallel_group = [0,8],[2,10],[4,12],[6,14], [1,9],[3,11],[5,13],[7,15]</li></ul>',4)]))}const m=l(i,[["render",p]]);export{c as __pageData,m as default};
