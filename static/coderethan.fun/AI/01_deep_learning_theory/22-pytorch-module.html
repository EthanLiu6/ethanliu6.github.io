<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>torch.nn.Module | 码医森</title>
    <meta name="description" content="计算机知识的学习站点">
    <meta name="generator" content="VitePress v1.3.4">
    <link rel="preload stylesheet" href="/assets/style.CflK-Lwn.css" as="style">
    
    <script type="module" src="/assets/app.B-WnmxOD.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.C1K20kGz.js">
    <link rel="modulepreload" href="/assets/chunks/framework.DA-Pb-tg.js">
    <link rel="modulepreload" href="/assets/AI_01_deep_learning_theory_22-pytorch-module.md.DjCl8s56.lean.js">
    <link rel="icon" type="image/svg+xml" href="/imgs/home-page-logo.svg">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css" crossorigin="">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0f60ec36></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0f60ec36> Skip to content </a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-ab179fa1><a class="title" href="/" data-v-ab179fa1><!--[--><!--]--><!--[--><img class="VPImage logo" src="/imgs/home-page-logo.svg" alt data-v-8426fc1a><!--]--><span data-v-ab179fa1>CoderEthan学习站</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>AI</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/AI/01_deep_learning_theory/" data-v-43f1e123><!--[-->DL基础理论<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/AI/02_distribute_training/" data-v-43f1e123><!--[-->分布式训练<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/AI/03_Transformer/" data-v-43f1e123><!--[-->Transformer个人梳理<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/AI/04_some_notes/" data-v-43f1e123><!--[-->DL个人笔记<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>计算机学科内容</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/408/" data-v-43f1e123><!--[-->408知识<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/c++/" data-v-43f1e123><!--[-->C++基础<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/Java/" data-v-43f1e123><!--[-->Java后端<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/Linux/" data-v-43f1e123><!--[-->Linux技术<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>求职面试</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/Job_Interview/Java/" data-v-43f1e123><!--[-->Java面经<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/Job_Interview/Algorithm_post/" data-v-43f1e123><!--[-->算法岗<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>其他维护</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/update/update_log.html" data-v-43f1e123><!--[-->站点更新<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/question_list/" data-v-43f1e123><!--[-->问题清单<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>感悟和日常</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/about_me/" data-v-43f1e123><!--[-->关于我<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/my_think/" data-v-43f1e123><!--[-->站长感悟<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link vp-external-link-icon" href="https://EthanLiu6.github.io" target="_blank" rel="noreferrer" data-v-43f1e123><!--[-->旧版博客<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ethanliu6/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a class="VPSocialLink no-icon" href="https://space.bilibili.com/1327099977/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z"/></svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-b6c34ac9><span class="vpi-more-horizontal icon" data-v-b6c34ac9></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>深色模式</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ethanliu6/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a class="VPSocialLink no-icon" href="https://space.bilibili.com/1327099977/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z"/></svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-17a5e62e><button data-v-17a5e62e>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 has-active" data-v-c40bc020 data-v-b7550ba0><!----><div class="items" data-v-b7550ba0><!--[--><section class="VPSidebarItem level-1 collapsible collapsed has-active" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>01_deep_learning_theory</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/01-feedforward_network.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01-feedforward_network</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/02-back_propagation.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>02-back_propagation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/03-bp_example_demo.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03-bp_example_demo</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/04-convolution_neural_network.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>04-convolution_neural_network</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/05-deep_learning_model.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>05-deep_learning_model</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/06-pytorch_install.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>06-pytorch_install</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/07-operators.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>07-operators</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/08-activation_functions.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>08-activation_functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/09-recurrent_neural_network.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>09-recurrent_neural_network</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/10-seq2seq.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>10-seq2seq</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/11-1attentions.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>11-1attentions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/11-2attention-extension.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>11-2attention-extension</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/12-weight-initialization.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>12-weight-initialization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/13-optimizers.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>13-optimizers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/14-regularization.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>14-regularization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/15-deep-learning-tuning-guide.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>15-deep-learning-tuning-guide</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/20-pytorch-tensor.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>20-pytorch-tensor</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/21-pytorch-autograd.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>21-pytorch-autograd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/22-pytorch-module.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>22-pytorch-module</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/23-1training-example-1.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-1training-example-1</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/23-2decoder.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-2decoder</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/23-3encoder.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-3encoder</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/23-4transformer.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-4transformer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/24-pytorch-optimizer.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>24-pytorch-optimizer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/25-pytorch-lr-scheduler.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>25-pytorch-lr-scheduler</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/26-pytorch-dataloader.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>26-pytorch-dataloader</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/27-pytorch-model-save.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>27-pytorch-model-save</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/28-pytorch-tensorboard.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>28-pytorch-tensorboard</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/29-pytorch-graph-mode.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>29-pytorch-graph-mode</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/30-1training-example-cv.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>30-1training-example-cv</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/30-3main.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>30-3main</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/31-1stable-diffusion.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>31-1stable-diffusion</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/31-2SDXL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>31-2SDXL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/31-3VAE.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>31-3VAE</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/40-nlp-bert_ner.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>40-nlp-bert_ner</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/41-nlp-t5_question-answering.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>41-nlp-t5_question-answering</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/42-nlp-gpt.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>42-nlp-gpt</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/43-scaling-law.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>43-scaling-law</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/44-distribute-training.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>44-distribute-training</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/45-LLM-History.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>45-LLM-History</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/46-LLM-GPT-Extension.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>46-LLM-GPT-Extension</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/46-nlp-llama.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>46-nlp-llama</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/47-LLM-DeepSeek-Structure.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>47-LLM-DeepSeek-Structure</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/47-nlp-deepseek.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>47-nlp-deepseek</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>02_distribute_training</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/00_large-scale-model-trainning.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>00_large-scale-model-trainning</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/01_coding.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01_coding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/01_offload-and-recompute.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01_offload-and-recompute</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/02_amp.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>02_amp</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/03_coding.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03_coding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/03_pytorch-DP.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03_pytorch-DP</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/04_pytorch-DDP.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>04_pytorch-DDP</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/05_pytorch-DDP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>05_pytorch-DDP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/05_pytorch-DDP-IMPL_DDP_ORIGIN.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>05_pytorch-DDP-IMPL_DDP_ORIGIN</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/06_collective-comm.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>06_collective-comm</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/06_torchrun-process-group.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>06_torchrun-process-group</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/07_ZeRO-Optimizer.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>07_ZeRO-Optimizer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/08_pytorch-ZeRO-1.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>08_pytorch-ZeRO-1</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/09_pytorch-FSDP-v1.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>09_pytorch-FSDP-v1</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/10_pytorch-FSDP-v2.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>10_pytorch-FSDP-v2</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/11_deepspeed-ZeRO-1-2-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>11_deepspeed-ZeRO-1-2-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/12_deepspeed-ZeRO-3-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>12_deepspeed-ZeRO-3-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/13_megatron-ZeRO-1-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>13_megatron-ZeRO-1-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/14_TP-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>14_TP-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/15_megatron-TP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>15_megatron-TP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/16_pytorch-TP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>16_pytorch-TP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/17_PP-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>17_PP-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/18_pytorch-PP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>18_pytorch-PP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/19_deepspeed-PP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>19_deepspeed-PP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/20_megatron-PP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>20_megatron-PP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/21_SP-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>21_SP-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/22_megatron-SP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>22_megatron-SP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/23_3D-Parallel-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23_3D-Parallel-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/24_megatron-3D-Parallel-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>24_megatron-3D-Parallel-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/25_pytorch-3D-Parallel-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>25_pytorch-3D-Parallel-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/26_CP-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>26_CP-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/27_megatron-CP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>27_megatron-CP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/28_MOE-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>28_MOE-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/28_MOE-Theory_DeepSeekMOE.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>28_MOE-Theory_DeepSeekMOE</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/29_megatron-MOE-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>29_megatron-MOE-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/30_deepspeed-MOE-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>30_deepspeed-MOE-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/31_deepspeed-code-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>31_deepspeed-code-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/32_collective-operations.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>32_collective-operations</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/33_pytorch_distribute.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>33_pytorch_distribute</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>03_Transformer</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/03_Transformer/01-Transformer的由来.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01-Transformer的由来</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/03_Transformer/02-Transformer架构解读.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>02-Transformer架构解读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/03_Transformer/03-Transformer源码构建.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03-Transformer源码构建</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>04_some_notes</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/04_some_notes/00-DL_base_notes.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>00-DL_base_notes</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/04_some_notes/01-class_logs.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01-class_logs</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/04_some_notes/02-some_detials.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>02-some_detials</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/04_some_notes/03-Bert理解.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03-Bert理解</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/04_some_notes/04-个人补充内容.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>04-个人补充内容</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/04_some_notes/05-Review_DL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>05-Review_DL</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>本文目录</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _AI_01_deep_learning_theory_22-pytorch-module" data-v-39a288b8><div><h1 id="torch-nn-module" tabindex="-1">torch.nn.Module <a class="header-anchor" href="#torch-nn-module" aria-label="Permalink to &quot;torch.nn.Module&quot;">​</a></h1><ul><li><a href="https://github.com/pytorch/pytorch/tree/270111b7b611d174967ed204776985cefca9c144/torch/nn" target="_blank" rel="noreferrer">src code</a></li></ul><p><strong>实践：找到本机pytorch 库 中对应的torch.nn 的位置。</strong> <br></p><h1 id="_1-pytorch-自带的-torch-nn-layer" tabindex="-1">1 pytorch 自带的 torch.nn layer <a class="header-anchor" href="#_1-pytorch-自带的-torch-nn-layer" aria-label="Permalink to &quot;1 pytorch 自带的 torch.nn layer&quot;">​</a></h1><ul><li><a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noreferrer">pytorch user guide</a></li></ul><p><strong>思考：为什么要定义torch.nn 模块呢？？？</strong> <br></p><h2 id="_1-1-用-torch-nn-解决之前的问题" tabindex="-1">1.1 用 torch.nn 解决之前的问题 <a class="header-anchor" href="#_1-1-用-torch-nn-解决之前的问题" aria-label="Permalink to &quot;1.1 用 torch.nn 解决之前的问题&quot;">​</a></h2><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> nn_demo</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">():</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    1. 数据准备：输入数据 + lable 数据</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    2. 网络结构的搭建：激活函数 + 损失函数 + 权重初始化；</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    3. 优化器选择；</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    4. 训练策略：学习率的控制 + 梯度清0 + 更新权重 + 正则化；</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &#39;&#39;&#39;</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    input</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]).reshape(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).to(torch.float32)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    linear_1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    act_1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.Sigmoid()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    linear_2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    act_2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.Sigmoid()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    criteration </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.MSELoss()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.optim.SGD([{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;params&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: linear_1.parameters()},</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">                                 {</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;params&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: linear_2.parameters()}], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    label </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.99</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]).reshape(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">100</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        optimizer.zero_grad()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> linear_1(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> act_1(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> linear_2(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> act_2(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> criteration(output, label)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        loss.backward()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        optimizer.step() </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 更新权重      </span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(loss)</span></span></code></pre></div><h2 id="_1-2-tensor-和-parameter-的区别" tabindex="-1">1.2 Tensor 和 Parameter 的区别 <a class="header-anchor" href="#_1-2-tensor-和-parameter-的区别" aria-label="Permalink to &quot;1.2 Tensor 和 Parameter 的区别&quot;">​</a></h2><ul><li>通过查阅代码解决；</li></ul><p><strong>思考：上述做法还有优化空间吗？？？</strong> <br></p><h1 id="_2-定义我们自己的module" tabindex="-1">2 定义我们自己的module <a class="header-anchor" href="#_2-定义我们自己的module" aria-label="Permalink to &quot;2 定义我们自己的module&quot;">​</a></h1><h2 id="_2-1-代码案例" tabindex="-1">2.1 代码案例 <a class="header-anchor" href="#_2-1-代码案例" aria-label="Permalink to &quot;2.1 代码案例&quot;">​</a></h2><ul><li>代码案例1：<br></li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> FullConnect</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, k, n):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(FullConnect, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">() </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初始化父类</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.full_connect1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">30</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.full_connect2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">20</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.activation1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.ReLU()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.activation2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sigmoid()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, input):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.full_connect1(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># type(input) = Tensor</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.activation1(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.full_connect2(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.activation2(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">           </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> full_connect_demo</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> FullConnect(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">30</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># model的实例化</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    input</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.rand(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">30</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 我们拿不到input的梯度</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    loss_function </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.CrossEntropyLoss()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    lable </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.Tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]).to(torch.int64)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> optim.SGD(model.parameters(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">100</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        model.train()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        optimizer.zero_grad()      </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># output: float</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> loss_function(output, lable)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        loss.backward()</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # print(&quot;================model weight grad before update: &quot;, model.full_connect1.weight[0])</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        optimizer.step()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;=======loss: &quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, loss)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # print(&quot;================model weight grad before update: &quot;, model.full_connect1.weight[0])</span></span></code></pre></div><ul><li>代码案例2：<br></li></ul><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> ModuleDemo</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">torch</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(ModuleDemo, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear_1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.act_1 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.LeakyReLU()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear_2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.act_2 </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.LeakyReLU()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, input):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear_1(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.act_1(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear_2(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.act_2(x)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # loss = self.criteration(output, label)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> output</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> module_train</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    torch.manual_seed(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    input</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]).reshape(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).to(torch.float32)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    label </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.tensor([</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.01</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.99</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]).reshape(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ModuleDemo()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    criteration </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn.MSELoss()    </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    optimizer </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.optim.Adam(model.parameters(), </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">lr</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # optimizer = torch.optim.Adagrad(model.parameters(), lr=0.1)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # optimizer = torch.optim.Adadelta(model.parameters(), lr=0.1)</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # optimizer = torch.optim.AdamW(model.parameters(), lr=0.1)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">100</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        optimizer.zero_grad()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> criteration(output, label)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        loss.backward()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        optimizer.step()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;=========loss[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">i</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">]: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loss</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><h2 id="_2-2-customer-layer-要点" tabindex="-1">2.2 customer layer 要点 <a class="header-anchor" href="#_2-2-customer-layer-要点" aria-label="Permalink to &quot;2.2 customer layer 要点&quot;">​</a></h2><ol><li>自定义的模型应该继承自基类 nn.Module；</li><li>custom 模块还可以包含其他模块，从而可以将它们嵌套在树形结构中, 子模块为当前模块的普通属性；</li><li>上述子模块在 custom modle 中的__init__函数初始化；</li><li>在子类上进行赋值之前，必须先调用父类的 <strong>init</strong>()；</li><li>需要有 forward函数: 我们具体的实现过程，计算过程。</li></ol><h1 id="_3-nn-module-中的容器" tabindex="-1">3 nn.Module 中的容器 <a class="header-anchor" href="#_3-nn-module-中的容器" aria-label="Permalink to &quot;3 nn.Module 中的容器&quot;">​</a></h1><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> sequential_demo</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">():</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    seq_modules </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Sequential(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">28</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">28</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">512</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">512</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">512</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        nn.ReLU(),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">512</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    input_image </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.rand(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">3</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">28</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">28</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    logits </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> seq_modules(input_image)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;logits: &quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, logits.shape)</span></span></code></pre></div><h1 id="_4-nn-module-属性详解" tabindex="-1">4 nn.Module 属性详解 <a class="header-anchor" href="#_4-nn-module-属性详解" aria-label="Permalink to &quot;4 nn.Module 属性详解&quot;">​</a></h1><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 是否生成模块的补丁列表</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 补丁列表记录了模块中所有可导操作的详细信息，包括输入张量、输出张量、参数、缓冲区等</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">dump_patches: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> # </span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_version: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> # 版本号，对应向后兼容很重要</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">training: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"> # 是否处于训练模式</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_parameters: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Optional[Parameter]] </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 模型的当前类的_parameters</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_buffers: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Optional[Tensor]] </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 模型的 buffers，可通过register_buffers 来定义</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 存储模块中的非持久性缓冲区（non-persistent buffer）的集合，非持久性缓冲区不会被保存为模型的状态字典（state_dict）的缓冲区</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_non_persistent_buffers_set: Set[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># register_buffer 的 persistent = False 时触发</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 反向传播过程中，在梯度计算之前执行的钩子函数， register_full_backward_pre_hook 来注册</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_backward_pre_hooks: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Callable] </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 反向传播过程中，在梯度计算之后执行的钩子函数，</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_backward_hooks: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Callable] </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># register_full_backward_hook 来注册, register_backward_hook 来注册被禁用</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_is_full_backward_hook: Optional[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 判断反向传播钩子函数是否完全覆盖了模块的所有梯度输出</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 前向钩子函数，前向执行完后调用，用register_forward_hook来注册</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_forward_hooks: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Callable] </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 判断前向钩子函数是否带参数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_forward_hooks_with_kwargs: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">] </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 前向钩子函数是否always 被调用</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_forward_hooks_always_called: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 前向 pre 钩子函数，register_forward_pre_hook来注册</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_forward_pre_hooks: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Callable]</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># pre 前向钩子函数是否带参数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_forward_pre_hooks_with_kwargs: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># state_dict 函数内获取状态后执行, _register_state_dict_hook 来注册</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_state_dict_hooks: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Callable] </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 加载状态的pre 钩子函数，_register_load_state_dict_pre_hook 来注册</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_load_state_dict_pre_hooks: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Callable] </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># state_dict 函数内获取状态前执行，register_state_dict_pre_hook 来注册</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_state_dict_pre_hooks: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Callable] </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 加载状态时的后向钩子函数， register_load_state_dict_post_hook 来注册</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_load_state_dict_post_hooks: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Callable]</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 存储子模块，子模块还可以有子模块</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_modules: Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Optional[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Module&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]] </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># False 时不能传参数，True时 可以传参数 给到父类</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">call_super_init: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># torch.compile: Optimizes given model/function using TorchDynamo and specified backend.</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># self._compiled_call_impl = torch.compile(self._call_impl, *args, **kwargs)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">_compiled_call_impl : Optional[Callable] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span></span></code></pre></div><h1 id="_5-torch-nn-module-常用功能" tabindex="-1">5 torch.nn.Module 常用功能 <a class="header-anchor" href="#_5-torch-nn-module-常用功能" aria-label="Permalink to &quot;5 torch.nn.Module 常用功能&quot;">​</a></h1><h2 id="_5-1-parameters-设置机制" tabindex="-1">5.1 _parameters 设置机制 <a class="header-anchor" href="#_5-1-parameters-设置机制" aria-label="Permalink to &quot;5.1  _parameters 设置机制&quot;">​</a></h2><p>        nn.Module 使用了 Python 的 <strong>setattr</strong> 机制，当在类中定义成员时，<strong>setattr</strong> 会检测成员的 type 派生于哪些类型。如果派生于 Parameter 类，则被归于 _parameters ；如果派生于 Module ，则划归于 _modules。因此，如果类中定义的成员被封装到Python的普通数据类型中，则不会自动归类，比如：self.layers = [nn.Linear(1024, 80), nn.Linear(80, 10]，检测到是list类型，则会视为普通属性。<br></p><h2 id="_5-2-buffers-功能展示" tabindex="-1">5.2 _buffers 功能展示 <a class="header-anchor" href="#_5-2-buffers-功能展示" aria-label="Permalink to &quot;5.2 _buffers 功能展示&quot;">​</a></h2><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;&#39;通常，这用于注册一个不被视为模型参数的缓冲区。例如，BatchNorm 的 running_mean 不是一个参数，但它是模块的状态的一部分。</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">缓冲区默认是持久的，并将与参数一起保存。通过将 persistent 属性设置为 False，可以改变这种行为。</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">持久性缓冲区和非持久性缓冲区之间唯一的区别是后者不会成为该模块的 state_dict 的一部分。</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">可以通过给定的名称将缓冲区作为属性进行访问。</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">self.register_buffer(&#39;running_mean&#39;, torch.zeros(num_features))</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;&#39;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MyModule</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.register_buffer(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;batch_mean&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.register_buffer(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;batch_var&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">persistent</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.register_buffer(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;running_mean&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, torch.zeros(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.register_buffer(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;running_var&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, torch.ones(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 计算当前批次的均值和方差</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        batch_mean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.mean(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        batch_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.var(x)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 更新运行时的均值和方差</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.training:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">            if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.batch_mean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">is</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">                self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.batch_mean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch_mean.detach()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">                self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.batch_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch_var.detach()</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">            else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">                self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.batch_mean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.batch_mean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch_mean.detach()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">                self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.batch_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.batch_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch_var.detach()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_mean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_mean </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch_mean.detach()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> batch_var.detach()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 使用运行时的均值和方差进行归一化</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        normalized_x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_mean) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.sqrt(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.running_var </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 1e-5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> normalized_x</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 创建模型实例</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">module </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyModule()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 模拟训练过程</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> epoch </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">in</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> range</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 模拟每个批次的输入数据</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    input_data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.randn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 前向传播</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> module(input_data)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 输出当前批次的均值和方差</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Batch Mean: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">module.batch_mean.item()</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">, Batch Variance: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">module.batch_var.item()</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 输出最终的运行时均值和方差</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">f</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Running Mean: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">module.running_mean.item()</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">, Running Variance: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">{</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">module.running_var.item()</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">}</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><h2 id="_5-3-前向钩子函数展示" tabindex="-1">5.3 前向钩子函数展示 <a class="header-anchor" href="#_5-3-前向钩子函数展示" aria-label="Permalink to &quot;5.3 前向钩子函数展示&quot;">​</a></h2><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> hook_fn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(module, input, output):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">        # 钩子函数的自定义操作</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Executing hook function...&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Module:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, module)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Input:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Output:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, output)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;-------------------&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MyModule</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">().</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">            self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">            </span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, input):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">            return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">input</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    module </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyModule()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 注册前向钩子函数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    handle </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> module.register_forward_hook(hook_fn)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 执行前向传播</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    input_tensor </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.randn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> module(input_tensor)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 移除钩子函数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    handle.remove()</span></span></code></pre></div><h2 id="_5-4-反向钩子函数展示" tabindex="-1">5.4 反向钩子函数展示 <a class="header-anchor" href="#_5-4-反向钩子函数展示" aria-label="Permalink to &quot;5.4 反向钩子函数展示&quot;">​</a></h2><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.nn </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 反向传播钩子函数</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> backward_hook_fn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(module, grad_input, grad_output):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 自定义操作</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Executing backward hook function...&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Module:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, module)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Gradient Input:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, grad_input)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Gradient Output:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, grad_output)</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;-------------------&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 定义模型</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">class</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> MyModel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">nn</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        super</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(MyModel, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">).</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">()</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">        self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> nn.Linear(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, x):</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">        return</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> self</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.linear(x)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> MyModel()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 注册反向传播钩子函数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook_handle </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model.register_backward_hook(backward_hook_fn)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 定义输入数据和目标标签</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">input_data </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.randn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">10</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">target </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.randn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 前向传播</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> model(input_data)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 计算损失</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loss </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> output.sum()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 反向传播</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">loss.backward()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 移除钩子函数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">hook_handle.remove()</span></span></code></pre></div><h2 id="_6-nn-module-方法全解" tabindex="-1">6 nn.Module 方法全解 <a class="header-anchor" href="#_6-nn-module-方法全解" aria-label="Permalink to &quot;6 nn.Module 方法全解&quot;">​</a></h2><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 构造函数 --&gt; 一系列属性初始化</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __init__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">args, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs) -&gt; </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># forward 函数</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">forward: Callable[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Any] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> _forward_unimplemented</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 添加一个buffer 到 module，注册一个不被视为模型参数的缓冲区，但可能是模型状态的一部分</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> register_buffer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, name: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, tensor: Optional[Tensor], persistent: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Adds a parameter to the module</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> register_parameter</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, name: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, param: Optional[Parameter]) -&gt; </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 向module 添加 子module，</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 提供了一种标准化的方式来将子模块添加到模型中。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 通过使用 add_module，您可以确保模型的子模块被正确地注册和命名，并在模型的其他部分中进行访问。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> add_module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, name: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, module: Optional[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Module&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]) -&gt; </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># add_module 的别名</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> register_module</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, name: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, module: Optional[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Module&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]) -&gt; </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 通过名称获取子模块</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> get_submodule</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, target: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Module&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 通过名称获取parameter</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> get_parameter</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, target: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Parameter&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 通过名称获取 buffer</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> get_buffer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, target: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Tensor&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 获取额外状态，用户应该实现此函数，否则直接报错，额外的状态应该是可 picklable 的</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> get_extra_state</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self) -&gt; Any:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 设置额外状态，子类实现此函数，否则直接报错</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> set_extra_state</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, state: Any):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 内部使用，递归的将所有子模块的_parameters 和 _buffers 应用用户指定的函数 fn 进行操作</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _apply</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, fn, recurse</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 外部使用，递归的将所有子模块应用 fn 进行处理</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> apply</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T, fn: Callable[[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Module&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># _parameters 和 _buffers 转到cuda 设备上</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> cuda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T, device: Optional[Union[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, device]] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将所有模型参数和缓冲区移动到 IPU（Intel Processor for AI）上。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> ipu</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T, device: Optional[Union[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, device]] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">#将所有模型参数和缓冲区移动到 XPU 可扩展处理单元（extensible Processing Unit）上。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> xpu</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T, device: Optional[Union[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, device]] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将所有模型参数和缓冲区移动到 CPU 上。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> cpu</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># in-place 的 将所有参数和缓冲区转换为 dst_type 类型</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> type</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T, dst_type: Union[dtype, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># inplace 的将所有参数和缓冲区转换为 float 类型</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> float</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># inplace 的将所有参数和缓冲区转换为 double 类型</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> double</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># inplace 的将所有参数和缓冲区转换为 half 类型</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> half</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># inplace 的将所有参数和缓冲区转换为 bfloat16 类型</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> bfloat16</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将参数和缓冲区移动到指定的设备，而无需复制存储空间。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> to_empty</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, device: Union[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, device], recurse: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将参数和缓冲区移动到指定的设备</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@overload</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> to</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T, device: Optional[Union[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, device]] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> ...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, dtype: Optional[Union[dtype, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]]</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> ...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, non_blocking: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> ...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将参数和缓冲区转成指定的数据类型</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@overload</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> to</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T, dtype: Union[dtype, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], non_blocking: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> ...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将参数和缓冲区转成Tensor 对应的数据类型 和 device类型</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@overload</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> to</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T, tensor: Tensor, non_blocking: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> ...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 调用以上三种to</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> to</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">args, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">   </span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在模块上注册一个反向传播 pre 钩子。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> register_full_backward_pre_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    self,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    hook: Callable[[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Module&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, _grad_t], Union[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, _grad_t]],</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    prepend: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ) -&gt; RemovableHandle:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在模块上注册一个反向传播钩子。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 这个函数已被弃用，建议改用 torch.nn.Module.register_full_backward_hook 方法。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将来版本中，该函数的行为将会发生变化。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> register_backward_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    self, hook: Callable[[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Module&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, _grad_t, _grad_t], Union[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, _grad_t]]</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ) -&gt; RemovableHandle:</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在模块上注册一个反向传播钩子。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> register_full_backward_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    self,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    hook: Callable[[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Module&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, _grad_t, _grad_t], Union[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, _grad_t]],</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    prepend: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ) -&gt; RemovableHandle:</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回用于在调用函数中使用的反向传播钩子。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 它返回两个列表，一个包含完整的反向传播钩子（full backward hooks），</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 另一个包含非完整的反向传播钩子（non-full backward hooks）。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _get_backward_hooks</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回反向传播pre 钩子</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _get_backward_pre_hooks</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 用于在注册非完整反向传播钩子时发出警告：未来版本中可能会对非完整钩子的行为进行更改。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _maybe_warn_non_full_backward_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, inputs, result, grad_fn):</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在模块上注册一个前向传播预钩子。该预钩子将在每次调用 forward 函数之前被调用。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> register_forward_pre_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    self,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    hook: Union[</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        Callable[[T, Tuple[Any, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]], Optional[Any]],</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        Callable[[T, Tuple[Any, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Any]], Optional[Tuple[Any, Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Any]]]],</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ],</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    prepend: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    with_kwargs: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ) -&gt; RemovableHandle:</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在模块上注册一个前向传播钩子。该钩子将在每次调用 forward 函数计算输出之后被调用。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> register_forward_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    self,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    hook: Union[</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        Callable[[T, Tuple[Any, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], Any], Optional[Any]],</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        Callable[[T, Tuple[Any, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Any], Any], Optional[Any]],</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ],</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    *</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    prepend: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    with_kwargs: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    always_call: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ) -&gt; RemovableHandle:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在forward 时，同时进行 tracing，以捕获静态图，此时eager mode 运行速度会降低</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _slow_forward</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">input, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 对前向传播进行装饰：控制forward的调度，可能会处理一些其他的内部机制，如跟踪计算图、梯度传播等。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _wrapped_call_impl</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">args, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 模型真正执行之处</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _call_impl</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">args, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># __call__ 魔术方法，让Module 成为 Callable 对象</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">__call__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> : Callable[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Any] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> _wrapped_call_impl</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 该方法应返回一个表示对象状态的可序列化对象，通常是一个字典。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># pickle.dump()、pickle.dumps() 时可被自动调用。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __getstate__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 更新module的状态</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __setstate__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, state):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在访问不存在的属性时被调用</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __getattr__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, name: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; Any:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在module属性设置过程中插入自己的逻辑</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __setattr__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, name: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, value: Union[Tensor, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Module&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]) -&gt; </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 删除 属性</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __delattr__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, name):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 注册 state_dict 钩子函数：</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 这些钩子函数将被传入以下参数：self，state_dict，prefix，local_metadata；</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在设置完self的state_dict之后调用。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 请注意，只有self及其子模块的参数和缓存才能保证存在于state_dict中。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 这些钩子函数可以原地修改state_dict，也可以返回一个新的state_dict。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _register_state_dict_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, hook):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 注册 state_dict 的pre 钩子函数；</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 这些钩子函数将在调用self的state_dict之前，使用参数self、prefix和keep_vars进行调用。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 注册的钩子函数可用于在进行state_dict调用之前执行预处理操作。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> register_state_dict_pre_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, hook):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 被state_dict 方法内部调用；</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将模块的状态保存到包含模块状态但不包含其子模块状态的destination字典中。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在torch.nn.Module.state_dict中的每个子模块上调用此方法。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 在极少数情况下，子类可以通过覆盖此方法并添加自定义逻辑来实现特定于类的行为。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _save_to_state_dict</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, destination, prefix, keep_vars):</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 用户可以选择性地传递一个可映射对象给state_dict，在这种情况下，state_dict将返回相同的对象。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 但如果未传递任何对象，将创建并返回一个OrderedDict。</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">T_destination </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> TypeVar(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;T_destination&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">bound</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Any])</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 状态字典的重载</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@overload</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> state_dict</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, destination: T_destination, prefix: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> ...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, keep_vars: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> ...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; T_destination:</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@overload</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> state_dict</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, prefix: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> ...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, keep_vars: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> ...</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; Dict[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Any]:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回一个包含模块整个状态的字典。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 包括参数和持久性缓冲区（例如运行平均值）。键是相应的参数和缓冲区名称。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 设置为None的参数和缓冲区不包括在内。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回的对象是一个浅拷贝。它包含对模块参数和缓冲区的引用。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> state_dict</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">args, destination</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, prefix</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, keep_vars</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 注册 state_dict 的前置钩子函数，将执行 state_dict 前 被调用</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _register_load_state_dict_pre_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, hook, with_module</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 注册一个后置钩子函数，在调用模块的load_state_dict方法之后运行。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> register_load_state_dict_post_hook</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, hook):</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 被load_state_dict 调用，</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将参数和缓冲区从state_dict复制到当前模块，但不包括其子模块。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 这个方法在torch.nn.Module.load_state_dict中的每个子模块上调用。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 提供给这个模块的state_dict中保存的元数据作为local_metadata参数。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 对于没有元数据的状态字典，local_metadata为空。子类可以使用local_metadata.get(&quot;version&quot;, None)中的版本号实现特定于类的向后兼容加载。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 此外，local_metadata还可以包含assign_to_params_buffers键，指示是否应该将键分配给其在state_dict中对应的张量。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _load_from_state_dict</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs):</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将参数（_parameters）和缓冲区(_buffers)从state_dict复制到当前模块及其子模块。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 如果strict为True，则state_dict的键必须与该模块的torch.nn.Module.state_dict函数返回的键完全匹配。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> load_state_dict</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, state_dict: Mapping[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Any],  strict: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, assign: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> False</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 用于生成模块的各种名称和成员的辅助方法。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _named_members</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, get_members_fn, prefix</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, recurse</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, remove_duplicate: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回一个迭代器，用于遍历模块的参数。通常将其传递给优化器(optimizer)使用。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> parameters</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, recurse: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; Iterator[Parameter]:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回一个迭代器，遍历模块的参数，同时产出参数的名称和参数本身。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> named_parameters</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        self,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        prefix: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        recurse: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        remove_duplicate: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        ) -&gt; Iterator[Tuple[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Parameter]]:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回一个迭代器，用以遍历模块的buffers</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> buffers</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, recurse: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; Iterator[Tensor]:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回一个迭代器，遍历模块的buffers，同时产出buffers的名称和参数本身。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> named_buffers</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, prefix: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, recurse: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, remove_duplicate: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; Iterator[Tuple[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, Tensor]]:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回一个迭代器，用于遍历直接子模块。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> children</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self) -&gt; Iterator[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Module&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回一个迭代器，用于遍历直接子模块，同时产出模块的名称和模块本身</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> named_children</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self) -&gt; Iterator[Tuple[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Module&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]]:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回一个迭代器，用于遍历网络中的所有模块。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> modules</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self) -&gt; Iterator[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Module&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回一个迭代器，用于遍历网络中的所有模块，同时产出模块的名称和模块本身。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> named_modules</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, memo: Optional[Set[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Module&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, prefix: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, remove_duplicate: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将module 设置为 training 模式</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> train</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T, mode: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 将module 设置为 eval 模式</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> eval</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 更改是否自动梯度过程中应记录此module中参数；</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 该方法会in-place 地设置参数的requires_grad属性。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 该方法对于冻结模块的一部分以进行微调或单独训练模型的部分（例如，GAN训练）非常有用。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 有关requires_grad_()方法与几种类似机制之间的比较，请参阅:ref:locally-disable-grad-doc。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> requires_grad_</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T, requires_grad: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; T:</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 重置所有模型参数的梯度，可以清为0，也可以直接置为None</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> zero_grad</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, set_to_none: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">bool</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) -&gt; </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> share_memory</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self: T) -&gt; T:</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 用于将张量的内存共享给其他进程，cuda默认为True</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _get_name</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self): </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回类实例的名称</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 用于返回模块的额外表示形式（extra representation）。该方法可以用来提供有关模块的附加信息，通常用于调试和打印模块的可读表示。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> extra_repr</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self) -&gt; </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">str</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __repr__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self): </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 定义对象的字符串表示形式。使用 repr() 函数或在交互式环境中直接输出对象时被调用</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __dir__</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self): </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 返回该对象的属性和方法的名称列表</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 用于创建模块的副本，以便在每个设备上进行并行计算。副本本身不具有参数，副本引用原始module。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _replicate_for_data_parallel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 使用torch.compile编译该模块的前向传播。</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 该模块的__call__方法会被编译，并且所有的参数会原样传递给torch.compile。</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> compile</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(self, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">args, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">**</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kwargs):</span></span></code></pre></div><ul><li><a href="https://pytorch.org/docs/2.1/notes/autograd.html#locally-disable-grad-doc" target="_blank" rel="noreferrer">locally-disable-grad-doc</a></li></ul></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><div class="edit-info" data-v-e257564d><div class="edit-link" data-v-e257564d><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/EthanLiu6/coderethan.fun/edit/master/docs/AI/01_deep_learning_theory/22-pytorch-module.md" target="_blank" rel="noreferrer" data-v-e257564d><!--[--><span class="vpi-square-pen edit-link-icon" data-v-e257564d></span> 在 GitHub 上编辑此页面 OR 提出修改意见<!--]--></a></div><div class="last-updated" data-v-e257564d><p class="VPLastUpdated" data-v-e257564d data-v-e98dd255>最后更新于: <time datetime="2025-03-27T09:51:05.000Z" data-v-e98dd255></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/AI/01_deep_learning_theory/21-pytorch-autograd.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>上一篇</span><span class="title" data-v-e257564d>21-pytorch-autograd</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/AI/01_deep_learning_theory/23-1training-example-1.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>下一篇</span><span class="title" data-v-e257564d>23-1training-example-1</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>ICP备案号: <a href="https://beian.miit.gov.cn/" target="_blank">蜀ICP备2024103116号</a><br>公安备案号: <a href="https://beian.mps.gov.cn/#/query/webSearch?code=51012202001928" rel="noreferrer" target="_blank">川公网安备51012202001928</a></p><p class="copyright" data-v-e315a0ad>版权所有 © 2024-present  <a href="mailto:16693226842@163.com" target="_blank">Ethan.Liu</a></p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"about_me_index.md\":\"mz4kR9Fi\",\"ai_01_deep_learning_theory_01-feedforward_network.md\":\"CcvQrxgt\",\"ai_01_deep_learning_theory_02-back_propagation.md\":\"BtjZwJU_\",\"ai_01_deep_learning_theory_03-bp_example_demo.md\":\"DDBE4U1G\",\"ai_01_deep_learning_theory_04-convolution_neural_network.md\":\"CxA35loH\",\"ai_01_deep_learning_theory_05-deep_learning_model.md\":\"Ct7liYj1\",\"ai_01_deep_learning_theory_06-pytorch_install.md\":\"Clcubooi\",\"ai_01_deep_learning_theory_07-operators.md\":\"kIS9XbIQ\",\"ai_01_deep_learning_theory_08-activation_functions.md\":\"B1C9PY4H\",\"ai_01_deep_learning_theory_09-recurrent_neural_network.md\":\"CzW3agM_\",\"ai_01_deep_learning_theory_10-seq2seq.md\":\"6D8B4Rlq\",\"ai_01_deep_learning_theory_11-1attentions.md\":\"Cvpw08iV\",\"ai_01_deep_learning_theory_11-2attention-extension.md\":\"DC_8b5oC\",\"ai_01_deep_learning_theory_12-weight-initialization.md\":\"C1v8tMs3\",\"ai_01_deep_learning_theory_13-optimizers.md\":\"BJt7iJF7\",\"ai_01_deep_learning_theory_14-regularization.md\":\"Bx5ZYl-4\",\"ai_01_deep_learning_theory_15-deep-learning-tuning-guide.md\":\"CWN3mKn4\",\"ai_01_deep_learning_theory_20-pytorch-tensor.md\":\"BFcyl0Px\",\"ai_01_deep_learning_theory_21-pytorch-autograd.md\":\"DS522bLB\",\"ai_01_deep_learning_theory_22-pytorch-module.md\":\"DjCl8s56\",\"ai_01_deep_learning_theory_23-1training-example-1.md\":\"DH8M-Obn\",\"ai_01_deep_learning_theory_23-2decoder.md\":\"Cq0AY57n\",\"ai_01_deep_learning_theory_23-3encoder.md\":\"D0g53JSA\",\"ai_01_deep_learning_theory_23-4transformer.md\":\"DHbayc0z\",\"ai_01_deep_learning_theory_24-pytorch-optimizer.md\":\"Bn_0Gw79\",\"ai_01_deep_learning_theory_25-pytorch-lr-scheduler.md\":\"DxyT4Fmr\",\"ai_01_deep_learning_theory_26-pytorch-dataloader.md\":\"RYWx6b8M\",\"ai_01_deep_learning_theory_27-pytorch-model-save.md\":\"B7Q4ONf_\",\"ai_01_deep_learning_theory_28-pytorch-tensorboard.md\":\"VHNB3XsJ\",\"ai_01_deep_learning_theory_29-pytorch-graph-mode.md\":\"BL6cmN4L\",\"ai_01_deep_learning_theory_30-1training-example-cv.md\":\"DRhcPsAc\",\"ai_01_deep_learning_theory_30-3main.md\":\"Ci1wkkl4\",\"ai_01_deep_learning_theory_31-1stable-diffusion.md\":\"7ssTYEJp\",\"ai_01_deep_learning_theory_31-2sdxl.md\":\"B5ng9y6A\",\"ai_01_deep_learning_theory_31-3vae.md\":\"Cxzp-WBt\",\"ai_01_deep_learning_theory_40-nlp-bert_ner.md\":\"CcuO1-mQ\",\"ai_01_deep_learning_theory_41-nlp-t5_question-answering.md\":\"_6IyzXZC\",\"ai_01_deep_learning_theory_42-nlp-gpt.md\":\"_Nxmo9wM\",\"ai_01_deep_learning_theory_43-scaling-law.md\":\"xoZlgvkY\",\"ai_01_deep_learning_theory_44-distribute-training.md\":\"CNK33TAz\",\"ai_01_deep_learning_theory_45-llm-history.md\":\"Czmd8z8v\",\"ai_01_deep_learning_theory_46-llm-gpt-extension.md\":\"DehUuq2v\",\"ai_01_deep_learning_theory_46-nlp-llama.md\":\"Cvowveq1\",\"ai_01_deep_learning_theory_47-llm-deepseek-structure.md\":\"REY-Au_D\",\"ai_01_deep_learning_theory_47-nlp-deepseek.md\":\"C1weFA21\",\"ai_01_deep_learning_theory_index.md\":\"DULtN52e\",\"ai_02_distribute_training_00_large-scale-model-trainning.md\":\"ScK-rTES\",\"ai_02_distribute_training_01_coding.md\":\"BpOoZXvs\",\"ai_02_distribute_training_01_offload-and-recompute.md\":\"DH1t2mgl\",\"ai_02_distribute_training_02_amp.md\":\"UHS_a1Tv\",\"ai_02_distribute_training_03_coding.md\":\"CmvCR_VM\",\"ai_02_distribute_training_03_pytorch-dp.md\":\"DlSpdrVa\",\"ai_02_distribute_training_04_pytorch-ddp.md\":\"BdX4eQnE\",\"ai_02_distribute_training_05_pytorch-ddp-impl.md\":\"C3ka-I-H\",\"ai_02_distribute_training_05_pytorch-ddp-impl_ddp_origin.md\":\"B0ExxsWg\",\"ai_02_distribute_training_06_collective-comm.md\":\"Cl7RSZCa\",\"ai_02_distribute_training_06_torchrun-process-group.md\":\"0t1Ne9wO\",\"ai_02_distribute_training_07_zero-optimizer.md\":\"C6XSUzAS\",\"ai_02_distribute_training_08_pytorch-zero-1.md\":\"ySTPyj3V\",\"ai_02_distribute_training_09_pytorch-fsdp-v1.md\":\"B72E4KDO\",\"ai_02_distribute_training_10_pytorch-fsdp-v2.md\":\"icJHYy7W\",\"ai_02_distribute_training_11_deepspeed-zero-1-2-impl.md\":\"qP_Pfxun\",\"ai_02_distribute_training_12_deepspeed-zero-3-impl.md\":\"Csv92XRa\",\"ai_02_distribute_training_13_megatron-zero-1-impl.md\":\"Db7_6tfb\",\"ai_02_distribute_training_14_tp-theory.md\":\"esuC_Liu\",\"ai_02_distribute_training_15_megatron-tp-impl.md\":\"DEVXuzJf\",\"ai_02_distribute_training_16_pytorch-tp-impl.md\":\"D8qf5ngw\",\"ai_02_distribute_training_17_pp-theory.md\":\"CM8M3C9i\",\"ai_02_distribute_training_18_pytorch-pp-impl.md\":\"B29AeAKF\",\"ai_02_distribute_training_19_deepspeed-pp-impl.md\":\"ChAcoPgP\",\"ai_02_distribute_training_20_megatron-pp-impl.md\":\"BUm1IzVm\",\"ai_02_distribute_training_21_sp-theory.md\":\"d7qyOraH\",\"ai_02_distribute_training_22_megatron-sp-impl.md\":\"D1orG262\",\"ai_02_distribute_training_23_3d-parallel-theory.md\":\"B1-vwyBl\",\"ai_02_distribute_training_24_megatron-3d-parallel-impl.md\":\"zPy3o2Oy\",\"ai_02_distribute_training_25_pytorch-3d-parallel-impl.md\":\"BVILcMDg\",\"ai_02_distribute_training_26_cp-theory.md\":\"B1coDnHY\",\"ai_02_distribute_training_27_megatron-cp-impl.md\":\"DdJsMNrL\",\"ai_02_distribute_training_28_moe-theory.md\":\"DMjnS_8q\",\"ai_02_distribute_training_28_moe-theory_deepseekmoe.md\":\"OTnWcHUV\",\"ai_02_distribute_training_29_megatron-moe-impl.md\":\"pJxFgCRW\",\"ai_02_distribute_training_30_deepspeed-moe-impl.md\":\"DGgDLvC2\",\"ai_02_distribute_training_31_deepspeed-code-impl.md\":\"WjUqYD_P\",\"ai_02_distribute_training_32_collective-operations.md\":\"DnU5ghvq\",\"ai_02_distribute_training_33_pytorch_distribute.md\":\"BJeB5n4-\",\"ai_02_distribute_training_index.md\":\"UwwL-uUg\",\"ai_03_transformer_01-transformer的由来.md\":\"CJuvJ6VA\",\"ai_03_transformer_02-transformer架构解读.md\":\"D7Q52fUF\",\"ai_03_transformer_03-transformer源码构建.md\":\"DNOcryKw\",\"ai_03_transformer_index.md\":\"CUW2DYfu\",\"ai_04_some_notes_00-dl_base_notes.md\":\"CugAcIEx\",\"ai_04_some_notes_01-class_logs.md\":\"CRBe6gh8\",\"ai_04_some_notes_02-some_detials.md\":\"WK9iM9IR\",\"ai_04_some_notes_03-bert理解.md\":\"D4ypihZd\",\"ai_04_some_notes_04-个人补充内容.md\":\"D67da2ij\",\"ai_04_some_notes_05-review_dl.md\":\"CB6AAWFj\",\"ai_04_some_notes_index.md\":\"BWjDxHIM\",\"ai_index.md\":\"FceT-BLG\",\"index.md\":\"DK1IDkdq\",\"it-learning_408_index.md\":\"DQ7Ub8n-\",\"it-learning_408_os-4.1 进程同步.md\":\"ImosRfCq\",\"it-learning_408_os-4.4 信号量机制.md\":\"CnMjdS0S\",\"it-learning_408_os-4.4 信号量机制pv操作之“可见”.md\":\"KW2s8fDp\",\"it-learning_c___01_开发环境搭建与基础数据类型.md\":\"DVAfnfKI\",\"it-learning_c___02_控制流语句与复合数据类型.md\":\"o_Iw4hag\",\"it-learning_c___03_指针与引用.md\":\"Bw6bYMMc\",\"it-learning_c___04_自定义数据类型与函数.md\":\"Cyyzd5R-\",\"it-learning_c___05_头文件与指针的算术运算.md\":\"DejaB1_U\",\"it-learning_c___06_字符串、数组、指针与函数.md\":\"D3aHSP55\",\"it-learning_c___07_函数进阶与内存管理.md\":\"DqUS2M8n\",\"it-learning_c___08_运算符优先级表.md\":\"CtazDwSH\",\"it-learning_c___09_指针、内存管理和类的基础.md\":\"L48egUic\",\"it-learning_c___10_深入类和对象.md\":\"BpLLILo4\",\"it-learning_c___11_类的大小、继承与权限控制.md\":\"DYFJyGgE\",\"it-learning_c___12_继承进阶.md\":\"CqNcG1Ig\",\"it-learning_c___13_类型转换和多态与虚函数.md\":\"DaeCEerH\",\"it-learning_c___14_纯虚函数、抽象类、深浅拷贝及智能指针.md\":\"B5cvBNtL\",\"it-learning_c___15_运算符重载与 string 类详解.md\":\"CZX-FnOl\",\"it-learning_c___16_有序容器与无序容器.md\":\"CJwgGEAo\",\"it-learning_c___17_模板.md\":\"4CdEsdGf\",\"it-learning_c___18_迭代器与其应用.md\":\"DmftJhgX\",\"it-learning_c___19_c__ 标准库常用算法.md\":\"Bymm15dk\",\"it-learning_c___20_c__ 异常处理 - 第19次课.md\":\"Sn8BieQI\",\"it-learning_c___21_友元及友元相关内容.md\":\"D1xuHqMb\",\"it-learning_c___22_c__ io 流详解-feadbc607d7f.md\":\"BD7P3tXk\",\"it-learning_c___23_c__ io 流详解.md\":\"azsZ5g77\",\"it-learning_c___24_位运算符总结.md\":\"BOkaz89o\",\"it-learning_c___25_c__三种继承方式.md\":\"DUn7n_et\",\"it-learning_c___26_c__11 高级特性.md\":\"CyrPVDkT\",\"it-learning_c___27_c__14 新特性.md\":\"6YQuRCGz\",\"it-learning_c___28_c__17 新特性.md\":\"BqJAdDo-\",\"it-learning_c___29_多文件和 makefile工程管理.md\":\"DvfAbEZ0\",\"it-learning_c___30_c__大型项目cmake工程管理.md\":\"CJvCgGVT\",\"it-learning_c___31_c__ 主要就业方向与技术能力分析报告.md\":\"CqJbtbjv\",\"it-learning_c___32_c__ 基础知识回顾.md\":\"Dx5_xIPx\",\"it-learning_c___index.md\":\"BAg94tAw\",\"it-learning_index.md\":\"D1maUb85\",\"it-learning_java_01.java-se.md\":\"CV9z-Ph2\",\"it-learning_java_02.sql.md\":\"gilr6jOh\",\"it-learning_java_03.java-web.md\":\"DXRkrx3K\",\"it-learning_java_05.mybatis.md\":\"HjU_MlJz\",\"it-learning_java_index.md\":\"DkRBc8cW\",\"it-learning_linux_01.linux基础.md\":\"BBs1RcBf\",\"it-learning_linux_02.shell.md\":\"BCfUk33T\",\"it-learning_linux_03.mpi并行计算.md\":\"gpRl9TGp\",\"it-learning_linux_04.docker.md\":\"DN_C173y\",\"it-learning_linux_index.md\":\"BVALaZgc\",\"job_interview_algorithm_post_index.md\":\"hS-i5N_u\",\"job_interview_algorithm_post_model_framework_001_transformer.md\":\"LvqqCzf9\",\"job_interview_algorithm_post_model_framework_002_normalization.md\":\"N-q7VS0F\",\"job_interview_algorithm_post_model_framework_003_position-embedding.md\":\"BzS9FT0f\",\"job_interview_algorithm_post_model_framework_004_activation.md\":\"CxfcY-oh\",\"job_interview_algorithm_post_model_framework_005_transformer-other.md\":\"B2njneQr\",\"job_interview_algorithm_post_model_framework_006_llm-frame.md\":\"DGroGrLz\",\"job_interview_algorithm_post_model_framework_007_moe.md\":\"BMQgyvEU\",\"job_interview_algorithm_post_model_framework_基础内容面试点.md\":\"B1pwzhK0\",\"job_interview_algorithm_post_model_framework_手撕内容.md\":\"DuGvZX1g\",\"job_interview_algorithm_post_sum_knowledge_index.md\":\"DTUo71x7\",\"job_interview_algorithm_post_sum_knowledge_p0-00_场景题.md\":\"Z5BhOUcP\",\"job_interview_algorithm_post_sum_knowledge_p1-01_分词器.md\":\"DG2eb09I\",\"job_interview_algorithm_post_sum_knowledge_p1-02_词向量.md\":\"DjxrHTfc\",\"job_interview_algorithm_post_sum_knowledge_p2-01_注意力机制.md\":\"BGzOB_m0\",\"job_interview_algorithm_post_sum_knowledge_p2-02_位置编码.md\":\"CMuG2lT2\",\"job_interview_algorithm_post_sum_knowledge_p2-03_归一化.md\":\"Cq0n4AiK\",\"job_interview_algorithm_post_sum_knowledge_p2-04_残差连接.md\":\"DuEkWZPo\",\"job_interview_algorithm_post_sum_knowledge_p3-01_多层感知机.md\":\"Lo5LuBKV\",\"job_interview_algorithm_post_sum_knowledge_p3-02_激活函数.md\":\"B5tCzgM2\",\"job_interview_algorithm_post_sum_knowledge_p3-03_损失函数.md\":\"3OZi1xk0\",\"job_interview_algorithm_post_sum_knowledge_p4-01_预训练技术.md\":\"DjankyqI\",\"job_interview_algorithm_post_sum_knowledge_p5-01_后训练技术.md\":\"J2ab4E7V\",\"job_interview_algorithm_post_sum_knowledge_p6-01_推理优化.md\":\"nrc9Je7c\",\"job_interview_algorithm_post_sum_knowledge_p7-01_大模型架构.md\":\"BcXRF7RO\",\"job_interview_algorithm_post_sum_knowledge_p8_01_大模型应用.md\":\"C7EIiF_5\",\"job_interview_algorithm_post_sum_knowledge_p9-01_torch的数据.md\":\"DU-tVO0q\",\"job_interview_index.md\":\"CK06T0i_\",\"job_interview_java_index.md\":\"C0TwjbqV\",\"my_think_01_不同商家的视野.md\":\"oNKuD8ev\",\"my_think_02_学而篇.md\":\"DIXp_fou\",\"my_think_03_重温士兵突击.md\":\"iuGDsQYW\",\"my_think_04_你很好，慢慢来.md\":\"D80QW609\",\"my_think_05_健康是第一重要.md\":\"xhbjArk5\",\"my_think_index.md\":\"Ys8bgN2a\",\"question_list_doccano账户管理.md\":\"4xMMl7Bn\",\"question_list_index.md\":\"Bx3eFS0B\",\"question_list_专英翻转课堂—pytorch.md\":\"C2nclqWo\",\"question_list_虚拟机网络问题.md\":\"Cxh_Plki\",\"readme.md\":\"DJufORId\",\"update_update_log.md\":\"axEQFBi_\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"码医森\",\"description\":\"计算机知识的学习站点\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"siteTitle\":\"CoderEthan学习站\",\"logo\":\"/imgs/home-page-logo.svg\",\"outline\":{\"label\":\"本文目录\",\"level\":[2,4]},\"search\":{\"provider\":\"local\"},\"socialLinks\":[{\"icon\":{\"svg\":\"<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" viewBox=\\\"0 0 496 512\\\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\\\"#6841d2\\\" d=\\\"M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z\\\"/></svg>\"},\"link\":\"https://github.com/ethanliu6/\"},{\"icon\":{\"svg\":\"<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" viewBox=\\\"0 0 512 512\\\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\\\"#6841d2\\\" d=\\\"M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z\\\"/></svg>\"},\"link\":\"https://space.bilibili.com/1327099977/\"}],\"nav\":[{\"text\":\"AI\",\"items\":[{\"text\":\"DL基础理论\",\"link\":\"/AI/01_deep_learning_theory/\"},{\"text\":\"分布式训练\",\"link\":\"/AI/02_distribute_training/\"},{\"text\":\"Transformer个人梳理\",\"link\":\"/AI/03_Transformer/\"},{\"text\":\"DL个人笔记\",\"link\":\"/AI/04_some_notes/\"}]},{\"text\":\"计算机学科内容\",\"items\":[{\"text\":\"408知识\",\"link\":\"/IT-learning/408/\"},{\"text\":\"C++基础\",\"link\":\"/IT-learning/c++/\"},{\"text\":\"Java后端\",\"link\":\"/IT-learning/Java/\"},{\"text\":\"Linux技术\",\"link\":\"/IT-learning/Linux/\"}]},{\"text\":\"求职面试\",\"items\":[{\"text\":\"Java面经\",\"link\":\"/Job_Interview/Java/\"},{\"text\":\"算法岗\",\"link\":\"/Job_Interview/Algorithm_post/\"}]},{\"text\":\"其他维护\",\"items\":[{\"text\":\"站点更新\",\"link\":\"/update/update_log\"},{\"text\":\"问题清单\",\"link\":\"/question_list/\"}]},{\"text\":\"感悟和日常\",\"items\":[{\"text\":\"关于我\",\"link\":\"/about_me/\"},{\"text\":\"站长感悟\",\"link\":\"/my_think/\"},{\"text\":\"旧版博客\",\"link\":\"https://EthanLiu6.github.io\"}]}],\"footer\":{\"message\":\"ICP备案号: <a href=\\\"https://beian.miit.gov.cn/\\\" target=\\\"_blank\\\">蜀ICP备2024103116号</a><br>公安备案号: <a href=\\\"https://beian.mps.gov.cn/#/query/webSearch?code=51012202001928\\\" rel=\\\"noreferrer\\\" target=\\\"_blank\\\">川公网安备51012202001928</a>\",\"copyright\":\"版权所有 © 2024-present  <a href=\\\"mailto:16693226842@163.com\\\" target=\\\"_blank\\\">Ethan.Liu</a>\"},\"editLink\":{\"pattern\":\"https://github.com/EthanLiu6/coderethan.fun/edit/master/docs/:path\",\"text\":\"在 GitHub 上编辑此页面 OR 提出修改意见\"},\"lastUpdated\":{\"text\":\"最后更新于\",\"formatOptions\":{\"dateStyle\":\"long\",\"timeStyle\":\"short\"}},\"docFooter\":{\"prev\":\"上一篇\",\"next\":\"下一篇\"},\"darkModeSwitchLabel\":\"深色模式\",\"lightModeSwitchTitle\":\"切换到浅色模式\",\"darkModeSwitchTitle\":\"切换到深色模式\",\"sidebar\":{\"/AI/\":[{\"items\":[{\"text\":\"01_deep_learning_theory\",\"items\":[{\"text\":\"01-feedforward_network\",\"link\":\"/AI/01_deep_learning_theory/01-feedforward_network.html\"},{\"text\":\"02-back_propagation\",\"link\":\"/AI/01_deep_learning_theory/02-back_propagation.html\"},{\"text\":\"03-bp_example_demo\",\"link\":\"/AI/01_deep_learning_theory/03-bp_example_demo.html\"},{\"text\":\"04-convolution_neural_network\",\"link\":\"/AI/01_deep_learning_theory/04-convolution_neural_network.html\"},{\"text\":\"05-deep_learning_model\",\"link\":\"/AI/01_deep_learning_theory/05-deep_learning_model.html\"},{\"text\":\"06-pytorch_install\",\"link\":\"/AI/01_deep_learning_theory/06-pytorch_install.html\"},{\"text\":\"07-operators\",\"link\":\"/AI/01_deep_learning_theory/07-operators.html\"},{\"text\":\"08-activation_functions\",\"link\":\"/AI/01_deep_learning_theory/08-activation_functions.html\"},{\"text\":\"09-recurrent_neural_network\",\"link\":\"/AI/01_deep_learning_theory/09-recurrent_neural_network.html\"},{\"text\":\"10-seq2seq\",\"link\":\"/AI/01_deep_learning_theory/10-seq2seq.html\"},{\"text\":\"11-1attentions\",\"link\":\"/AI/01_deep_learning_theory/11-1attentions.html\"},{\"text\":\"11-2attention-extension\",\"link\":\"/AI/01_deep_learning_theory/11-2attention-extension.html\"},{\"text\":\"12-weight-initialization\",\"link\":\"/AI/01_deep_learning_theory/12-weight-initialization.html\"},{\"text\":\"13-optimizers\",\"link\":\"/AI/01_deep_learning_theory/13-optimizers.html\"},{\"text\":\"14-regularization\",\"link\":\"/AI/01_deep_learning_theory/14-regularization.html\"},{\"text\":\"15-deep-learning-tuning-guide\",\"link\":\"/AI/01_deep_learning_theory/15-deep-learning-tuning-guide.html\"},{\"text\":\"20-pytorch-tensor\",\"link\":\"/AI/01_deep_learning_theory/20-pytorch-tensor.html\"},{\"text\":\"21-pytorch-autograd\",\"link\":\"/AI/01_deep_learning_theory/21-pytorch-autograd.html\"},{\"text\":\"22-pytorch-module\",\"link\":\"/AI/01_deep_learning_theory/22-pytorch-module.html\"},{\"text\":\"23-1training-example-1\",\"link\":\"/AI/01_deep_learning_theory/23-1training-example-1.html\"},{\"text\":\"23-2decoder\",\"link\":\"/AI/01_deep_learning_theory/23-2decoder.html\"},{\"text\":\"23-3encoder\",\"link\":\"/AI/01_deep_learning_theory/23-3encoder.html\"},{\"text\":\"23-4transformer\",\"link\":\"/AI/01_deep_learning_theory/23-4transformer.html\"},{\"text\":\"24-pytorch-optimizer\",\"link\":\"/AI/01_deep_learning_theory/24-pytorch-optimizer.html\"},{\"text\":\"25-pytorch-lr-scheduler\",\"link\":\"/AI/01_deep_learning_theory/25-pytorch-lr-scheduler.html\"},{\"text\":\"26-pytorch-dataloader\",\"link\":\"/AI/01_deep_learning_theory/26-pytorch-dataloader.html\"},{\"text\":\"27-pytorch-model-save\",\"link\":\"/AI/01_deep_learning_theory/27-pytorch-model-save.html\"},{\"text\":\"28-pytorch-tensorboard\",\"link\":\"/AI/01_deep_learning_theory/28-pytorch-tensorboard.html\"},{\"text\":\"29-pytorch-graph-mode\",\"link\":\"/AI/01_deep_learning_theory/29-pytorch-graph-mode.html\"},{\"text\":\"30-1training-example-cv\",\"link\":\"/AI/01_deep_learning_theory/30-1training-example-cv.html\"},{\"text\":\"30-3main\",\"link\":\"/AI/01_deep_learning_theory/30-3main.html\"},{\"text\":\"31-1stable-diffusion\",\"link\":\"/AI/01_deep_learning_theory/31-1stable-diffusion.html\"},{\"text\":\"31-2SDXL\",\"link\":\"/AI/01_deep_learning_theory/31-2SDXL.html\"},{\"text\":\"31-3VAE\",\"link\":\"/AI/01_deep_learning_theory/31-3VAE.html\"},{\"text\":\"40-nlp-bert_ner\",\"link\":\"/AI/01_deep_learning_theory/40-nlp-bert_ner.html\"},{\"text\":\"41-nlp-t5_question-answering\",\"link\":\"/AI/01_deep_learning_theory/41-nlp-t5_question-answering.html\"},{\"text\":\"42-nlp-gpt\",\"link\":\"/AI/01_deep_learning_theory/42-nlp-gpt.html\"},{\"text\":\"43-scaling-law\",\"link\":\"/AI/01_deep_learning_theory/43-scaling-law.html\"},{\"text\":\"44-distribute-training\",\"link\":\"/AI/01_deep_learning_theory/44-distribute-training.html\"},{\"text\":\"45-LLM-History\",\"link\":\"/AI/01_deep_learning_theory/45-LLM-History.html\"},{\"text\":\"46-LLM-GPT-Extension\",\"link\":\"/AI/01_deep_learning_theory/46-LLM-GPT-Extension.html\"},{\"text\":\"46-nlp-llama\",\"link\":\"/AI/01_deep_learning_theory/46-nlp-llama.html\"},{\"text\":\"47-LLM-DeepSeek-Structure\",\"link\":\"/AI/01_deep_learning_theory/47-LLM-DeepSeek-Structure.html\"},{\"text\":\"47-nlp-deepseek\",\"link\":\"/AI/01_deep_learning_theory/47-nlp-deepseek.html\"}],\"collapsed\":true},{\"text\":\"02_distribute_training\",\"items\":[{\"text\":\"00_large-scale-model-trainning\",\"link\":\"/AI/02_distribute_training/00_large-scale-model-trainning.html\"},{\"text\":\"01_coding\",\"link\":\"/AI/02_distribute_training/01_coding.html\"},{\"text\":\"01_offload-and-recompute\",\"link\":\"/AI/02_distribute_training/01_offload-and-recompute.html\"},{\"text\":\"02_amp\",\"link\":\"/AI/02_distribute_training/02_amp.html\"},{\"text\":\"03_coding\",\"link\":\"/AI/02_distribute_training/03_coding.html\"},{\"text\":\"03_pytorch-DP\",\"link\":\"/AI/02_distribute_training/03_pytorch-DP.html\"},{\"text\":\"04_pytorch-DDP\",\"link\":\"/AI/02_distribute_training/04_pytorch-DDP.html\"},{\"text\":\"05_pytorch-DDP-IMPL\",\"link\":\"/AI/02_distribute_training/05_pytorch-DDP-IMPL.html\"},{\"text\":\"05_pytorch-DDP-IMPL_DDP_ORIGIN\",\"link\":\"/AI/02_distribute_training/05_pytorch-DDP-IMPL_DDP_ORIGIN.html\"},{\"text\":\"06_collective-comm\",\"link\":\"/AI/02_distribute_training/06_collective-comm.html\"},{\"text\":\"06_torchrun-process-group\",\"link\":\"/AI/02_distribute_training/06_torchrun-process-group.html\"},{\"text\":\"07_ZeRO-Optimizer\",\"link\":\"/AI/02_distribute_training/07_ZeRO-Optimizer.html\"},{\"text\":\"08_pytorch-ZeRO-1\",\"link\":\"/AI/02_distribute_training/08_pytorch-ZeRO-1.html\"},{\"text\":\"09_pytorch-FSDP-v1\",\"link\":\"/AI/02_distribute_training/09_pytorch-FSDP-v1.html\"},{\"text\":\"10_pytorch-FSDP-v2\",\"link\":\"/AI/02_distribute_training/10_pytorch-FSDP-v2.html\"},{\"text\":\"11_deepspeed-ZeRO-1-2-IMPL\",\"link\":\"/AI/02_distribute_training/11_deepspeed-ZeRO-1-2-IMPL.html\"},{\"text\":\"12_deepspeed-ZeRO-3-IMPL\",\"link\":\"/AI/02_distribute_training/12_deepspeed-ZeRO-3-IMPL.html\"},{\"text\":\"13_megatron-ZeRO-1-IMPL\",\"link\":\"/AI/02_distribute_training/13_megatron-ZeRO-1-IMPL.html\"},{\"text\":\"14_TP-Theory\",\"link\":\"/AI/02_distribute_training/14_TP-Theory.html\"},{\"text\":\"15_megatron-TP-IMPL\",\"link\":\"/AI/02_distribute_training/15_megatron-TP-IMPL.html\"},{\"text\":\"16_pytorch-TP-IMPL\",\"link\":\"/AI/02_distribute_training/16_pytorch-TP-IMPL.html\"},{\"text\":\"17_PP-Theory\",\"link\":\"/AI/02_distribute_training/17_PP-Theory.html\"},{\"text\":\"18_pytorch-PP-IMPL\",\"link\":\"/AI/02_distribute_training/18_pytorch-PP-IMPL.html\"},{\"text\":\"19_deepspeed-PP-IMPL\",\"link\":\"/AI/02_distribute_training/19_deepspeed-PP-IMPL.html\"},{\"text\":\"20_megatron-PP-IMPL\",\"link\":\"/AI/02_distribute_training/20_megatron-PP-IMPL.html\"},{\"text\":\"21_SP-Theory\",\"link\":\"/AI/02_distribute_training/21_SP-Theory.html\"},{\"text\":\"22_megatron-SP-IMPL\",\"link\":\"/AI/02_distribute_training/22_megatron-SP-IMPL.html\"},{\"text\":\"23_3D-Parallel-Theory\",\"link\":\"/AI/02_distribute_training/23_3D-Parallel-Theory.html\"},{\"text\":\"24_megatron-3D-Parallel-IMPL\",\"link\":\"/AI/02_distribute_training/24_megatron-3D-Parallel-IMPL.html\"},{\"text\":\"25_pytorch-3D-Parallel-IMPL\",\"link\":\"/AI/02_distribute_training/25_pytorch-3D-Parallel-IMPL.html\"},{\"text\":\"26_CP-Theory\",\"link\":\"/AI/02_distribute_training/26_CP-Theory.html\"},{\"text\":\"27_megatron-CP-IMPL\",\"link\":\"/AI/02_distribute_training/27_megatron-CP-IMPL.html\"},{\"text\":\"28_MOE-Theory\",\"link\":\"/AI/02_distribute_training/28_MOE-Theory.html\"},{\"text\":\"28_MOE-Theory_DeepSeekMOE\",\"link\":\"/AI/02_distribute_training/28_MOE-Theory_DeepSeekMOE.html\"},{\"text\":\"29_megatron-MOE-IMPL\",\"link\":\"/AI/02_distribute_training/29_megatron-MOE-IMPL.html\"},{\"text\":\"30_deepspeed-MOE-IMPL\",\"link\":\"/AI/02_distribute_training/30_deepspeed-MOE-IMPL.html\"},{\"text\":\"31_deepspeed-code-IMPL\",\"link\":\"/AI/02_distribute_training/31_deepspeed-code-IMPL.html\"},{\"text\":\"32_collective-operations\",\"link\":\"/AI/02_distribute_training/32_collective-operations.html\"},{\"text\":\"33_pytorch_distribute\",\"link\":\"/AI/02_distribute_training/33_pytorch_distribute.html\"}],\"collapsed\":true},{\"text\":\"03_Transformer\",\"items\":[{\"text\":\"01-Transformer的由来\",\"link\":\"/AI/03_Transformer/01-Transformer的由来.html\"},{\"text\":\"02-Transformer架构解读\",\"link\":\"/AI/03_Transformer/02-Transformer架构解读.html\"},{\"text\":\"03-Transformer源码构建\",\"link\":\"/AI/03_Transformer/03-Transformer源码构建.html\"}],\"collapsed\":true},{\"text\":\"04_some_notes\",\"items\":[{\"text\":\"00-DL_base_notes\",\"link\":\"/AI/04_some_notes/00-DL_base_notes.html\"},{\"text\":\"01-class_logs\",\"link\":\"/AI/04_some_notes/01-class_logs.html\"},{\"text\":\"02-some_detials\",\"link\":\"/AI/04_some_notes/02-some_detials.html\"},{\"text\":\"03-Bert理解\",\"link\":\"/AI/04_some_notes/03-Bert理解.html\"},{\"text\":\"04-个人补充内容\",\"link\":\"/AI/04_some_notes/04-个人补充内容.html\"},{\"text\":\"05-Review_DL\",\"link\":\"/AI/04_some_notes/05-Review_DL.html\"}],\"collapsed\":true}]}],\"/IT-learning/\":[{\"items\":[{\"text\":\"408\",\"items\":[{\"text\":\"OS-4.1 进程同步\",\"link\":\"/IT-learning/408/OS-4.1 进程同步.html\"},{\"text\":\"OS-4.4 信号量机制\",\"link\":\"/IT-learning/408/OS-4.4 信号量机制.html\"},{\"text\":\"OS-4.4 信号量机制pv操作之“可见”\",\"link\":\"/IT-learning/408/OS-4.4 信号量机制pv操作之“可见”.html\"}],\"collapsed\":true},{\"text\":\"Java\",\"items\":[{\"text\":\"01.java-se\",\"link\":\"/IT-learning/Java/01.java-se.html\"},{\"text\":\"02.sql\",\"link\":\"/IT-learning/Java/02.sql.html\"},{\"text\":\"03.java-web\",\"link\":\"/IT-learning/Java/03.java-web.html\"},{\"text\":\"05.MyBatis\",\"link\":\"/IT-learning/Java/05.MyBatis.html\"}],\"collapsed\":true},{\"text\":\"Linux\",\"items\":[{\"text\":\"01.Linux基础\",\"link\":\"/IT-learning/Linux/01.Linux基础.html\"},{\"text\":\"02.Shell\",\"link\":\"/IT-learning/Linux/02.Shell.html\"},{\"text\":\"03.MPI并行计算\",\"link\":\"/IT-learning/Linux/03.MPI并行计算.html\"},{\"text\":\"04.Docker\",\"link\":\"/IT-learning/Linux/04.Docker.html\"}],\"collapsed\":true},{\"text\":\"c++\",\"items\":[{\"text\":\"01_开发环境搭建与基础数据类型\",\"link\":\"/IT-learning/c++/01_开发环境搭建与基础数据类型.html\"},{\"text\":\"02_控制流语句与复合数据类型\",\"link\":\"/IT-learning/c++/02_控制流语句与复合数据类型.html\"},{\"text\":\"03_指针与引用\",\"link\":\"/IT-learning/c++/03_指针与引用.html\"},{\"text\":\"04_自定义数据类型与函数\",\"link\":\"/IT-learning/c++/04_自定义数据类型与函数.html\"},{\"text\":\"05_头文件与指针的算术运算\",\"link\":\"/IT-learning/c++/05_头文件与指针的算术运算.html\"},{\"text\":\"06_字符串、数组、指针与函数\",\"link\":\"/IT-learning/c++/06_字符串、数组、指针与函数.html\"},{\"text\":\"07_函数进阶与内存管理\",\"link\":\"/IT-learning/c++/07_函数进阶与内存管理.html\"},{\"text\":\"08_运算符优先级表\",\"link\":\"/IT-learning/c++/08_运算符优先级表.html\"},{\"text\":\"09_指针、内存管理和类的基础\",\"link\":\"/IT-learning/c++/09_指针、内存管理和类的基础.html\"},{\"text\":\"10_深入类和对象\",\"link\":\"/IT-learning/c++/10_深入类和对象.html\"},{\"text\":\"11_类的大小、继承与权限控制\",\"link\":\"/IT-learning/c++/11_类的大小、继承与权限控制.html\"},{\"text\":\"12_继承进阶\",\"link\":\"/IT-learning/c++/12_继承进阶.html\"},{\"text\":\"13_类型转换和多态与虚函数\",\"link\":\"/IT-learning/c++/13_类型转换和多态与虚函数.html\"},{\"text\":\"14_纯虚函数、抽象类、深浅拷贝及智能指针\",\"link\":\"/IT-learning/c++/14_纯虚函数、抽象类、深浅拷贝及智能指针.html\"},{\"text\":\"15_运算符重载与 String 类详解\",\"link\":\"/IT-learning/c++/15_运算符重载与 String 类详解.html\"},{\"text\":\"16_有序容器与无序容器\",\"link\":\"/IT-learning/c++/16_有序容器与无序容器.html\"},{\"text\":\"17_模板\",\"link\":\"/IT-learning/c++/17_模板.html\"},{\"text\":\"18_迭代器与其应用\",\"link\":\"/IT-learning/c++/18_迭代器与其应用.html\"},{\"text\":\"19_C++ 标准库常用算法\",\"link\":\"/IT-learning/c++/19_C++ 标准库常用算法.html\"},{\"text\":\"20_C++ 异常处理 - 第19次课\",\"link\":\"/IT-learning/c++/20_C++ 异常处理 - 第19次课.html\"},{\"text\":\"21_友元及友元相关内容\",\"link\":\"/IT-learning/c++/21_友元及友元相关内容.html\"},{\"text\":\"22_C++ IO 流详解-feadbc607d7f\",\"link\":\"/IT-learning/c++/22_C++ IO 流详解-feadbc607d7f.html\"},{\"text\":\"23_C++ IO 流详解\",\"link\":\"/IT-learning/c++/23_C++ IO 流详解.html\"},{\"text\":\"24_位运算符总结\",\"link\":\"/IT-learning/c++/24_位运算符总结.html\"},{\"text\":\"25_C++三种继承方式\",\"link\":\"/IT-learning/c++/25_C++三种继承方式.html\"},{\"text\":\"26_C++11 高级特性\",\"link\":\"/IT-learning/c++/26_C++11 高级特性.html\"},{\"text\":\"27_C++14 新特性\",\"link\":\"/IT-learning/c++/27_C++14 新特性.html\"},{\"text\":\"28_C++17 新特性\",\"link\":\"/IT-learning/c++/28_C++17 新特性.html\"},{\"text\":\"29_多文件和 Makefile工程管理\",\"link\":\"/IT-learning/c++/29_多文件和 Makefile工程管理.html\"},{\"text\":\"30_C++大型项目CMake工程管理\",\"link\":\"/IT-learning/c++/30_C++大型项目CMake工程管理.html\"},{\"text\":\"31_C++ 主要就业方向与技术能力分析报告\",\"link\":\"/IT-learning/c++/31_C++ 主要就业方向与技术能力分析报告.html\"},{\"text\":\"32_C++ 基础知识回顾\",\"link\":\"/IT-learning/c++/32_C++ 基础知识回顾.html\"}],\"collapsed\":true}]}],\"/Job_Interview/\":[{\"items\":[{\"text\":\"Algorithm_post\",\"items\":[{\"text\":\"model_framework\",\"items\":[{\"text\":\"001_Transformer\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/001_Transformer.html\"},{\"text\":\"002_Normalization\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/002_Normalization.html\"},{\"text\":\"003_Position-Embedding\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/003_Position-Embedding.html\"},{\"text\":\"004_Activation\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/004_Activation.html\"},{\"text\":\"005_Transformer-Other\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/005_Transformer-Other.html\"},{\"text\":\"006_LLM-Frame\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/006_LLM-Frame.html\"},{\"text\":\"007_MoE\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/007_MoE.html\"},{\"text\":\"基础内容面试点\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/基础内容面试点.html\"},{\"text\":\"手撕内容\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/手撕内容.html\"}],\"collapsed\":true},{\"text\":\"sum_knowledge\",\"items\":[{\"text\":\"p0-00_场景题\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p0-00_场景题.html\"},{\"text\":\"p1-01_分词器\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p1-01_分词器.html\"},{\"text\":\"p1-02_词向量\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p1-02_词向量.html\"},{\"text\":\"p2-01_注意力机制\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p2-01_注意力机制.html\"},{\"text\":\"p2-02_位置编码\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p2-02_位置编码.html\"},{\"text\":\"p2-03_归一化\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p2-03_归一化.html\"},{\"text\":\"p2-04_残差连接\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p2-04_残差连接.html\"},{\"text\":\"p3-01_多层感知机\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p3-01_多层感知机.html\"},{\"text\":\"p3-02_激活函数\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p3-02_激活函数.html\"},{\"text\":\"p3-03_损失函数\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p3-03_损失函数.html\"},{\"text\":\"p4-01_预训练技术\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p4-01_预训练技术.html\"},{\"text\":\"p5-01_后训练技术\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p5-01_后训练技术.html\"},{\"text\":\"p6-01_推理优化\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p6-01_推理优化.html\"},{\"text\":\"p7-01_大模型架构\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p7-01_大模型架构.html\"},{\"text\":\"p8_01_大模型应用\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p8_01_大模型应用.html\"},{\"text\":\"p9-01_torch的数据\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p9-01_torch的数据.html\"}],\"collapsed\":true}],\"collapsed\":true}]}],\"/my_think/\":[{\"items\":[{\"text\":\"01_不同商家的视野\",\"link\":\"/my_think/01_不同商家的视野.html\"},{\"text\":\"02_学而篇\",\"link\":\"/my_think/02_学而篇.html\"},{\"text\":\"03_重温士兵突击\",\"link\":\"/my_think/03_重温士兵突击.html\"},{\"text\":\"04_你很好，慢慢来\",\"link\":\"/my_think/04_你很好，慢慢来.html\"},{\"text\":\"05_健康是第一重要\",\"link\":\"/my_think/05_健康是第一重要.html\"}]}],\"/question_list/\":[{\"items\":[{\"text\":\"doccano账户管理\",\"link\":\"/question_list/doccano账户管理.html\"},{\"text\":\"专英翻转课堂—PyTorch\",\"link\":\"/question_list/专英翻转课堂—PyTorch.html\"},{\"text\":\"虚拟机网络问题\",\"link\":\"/question_list/虚拟机网络问题.html\"}]}],\"/update/\":[{\"items\":[{\"text\":\"update_log\",\"link\":\"/update/update_log.html\"}]}]}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>