<!DOCTYPE html>
<html lang="zh-CN" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>0 LLM简史：从Transformer（2017）到DeepSeek-R1（2025） | 码医森</title>
    <meta name="description" content="计算机知识的学习站点">
    <meta name="generator" content="VitePress v1.3.4">
    <link rel="preload stylesheet" href="/assets/style.CflK-Lwn.css" as="style">
    
    <script type="module" src="/assets/app.B-WnmxOD.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.Di8DUHzh.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/theme.C1K20kGz.js">
    <link rel="modulepreload" href="/assets/chunks/framework.DA-Pb-tg.js">
    <link rel="modulepreload" href="/assets/AI_01_deep_learning_theory_45-LLM-History.md.Czmd8z8v.lean.js">
    <link rel="icon" type="image/svg+xml" href="/imgs/home-page-logo.svg">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css" crossorigin="">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"auto",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><div class="Layout" data-v-5d98c3a5><!--[--><!--]--><!--[--><span tabindex="-1" data-v-0f60ec36></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-0f60ec36> Skip to content </a><!--]--><!----><header class="VPNav" data-v-5d98c3a5 data-v-ae24b3ad><div class="VPNavBar" data-v-ae24b3ad data-v-6aa21345><div class="wrapper" data-v-6aa21345><div class="container" data-v-6aa21345><div class="title" data-v-6aa21345><div class="VPNavBarTitle has-sidebar" data-v-6aa21345 data-v-ab179fa1><a class="title" href="/" data-v-ab179fa1><!--[--><!--]--><!--[--><img class="VPImage logo" src="/imgs/home-page-logo.svg" alt data-v-8426fc1a><!--]--><span data-v-ab179fa1>CoderEthan学习站</span><!--[--><!--]--></a></div></div><div class="content" data-v-6aa21345><div class="content-body" data-v-6aa21345><!--[--><!--]--><div class="VPNavBarSearch search" data-v-6aa21345><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><span class="vp-icon DocSearch-Search-Icon"></span><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-6aa21345 data-v-dc692963><span id="main-nav-aria-label" class="visually-hidden" data-v-dc692963> Main Navigation </span><!--[--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>AI</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/AI/01_deep_learning_theory/" data-v-43f1e123><!--[-->DL基础理论<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/AI/02_distribute_training/" data-v-43f1e123><!--[-->分布式训练<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/AI/03_Transformer/" data-v-43f1e123><!--[-->Transformer个人梳理<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/AI/04_some_notes/" data-v-43f1e123><!--[-->DL个人笔记<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>计算机学科内容</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/408/" data-v-43f1e123><!--[-->408知识<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/c++/" data-v-43f1e123><!--[-->C++基础<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/Java/" data-v-43f1e123><!--[-->Java后端<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/IT-learning/Linux/" data-v-43f1e123><!--[-->Linux技术<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>求职面试</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/Job_Interview/Java/" data-v-43f1e123><!--[-->Java面经<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/Job_Interview/Algorithm_post/" data-v-43f1e123><!--[-->算法岗<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>其他维护</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/update/update_log.html" data-v-43f1e123><!--[-->站点更新<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/question_list/" data-v-43f1e123><!--[-->问题清单<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--[--><div class="VPFlyout VPNavBarMenuGroup" data-v-dc692963 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" data-v-b6c34ac9><span class="text" data-v-b6c34ac9><!----><span data-v-b6c34ac9>感悟和日常</span><span class="vpi-chevron-down text-icon" data-v-b6c34ac9></span></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><div class="items" data-v-b98bc113><!--[--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/about_me/" data-v-43f1e123><!--[-->关于我<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link" href="/my_think/" data-v-43f1e123><!--[-->站长感悟<!--]--></a></div><!--]--><!--[--><div class="VPMenuLink" data-v-b98bc113 data-v-43f1e123><a class="VPLink link vp-external-link-icon" href="https://EthanLiu6.github.io" target="_blank" rel="noreferrer" data-v-43f1e123><!--[-->旧版博客<!--]--></a></div><!--]--><!--]--></div><!--[--><!--]--></div></div></div><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-6aa21345 data-v-6c893767><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-6c893767 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div><div class="VPSocialLinks VPNavBarSocialLinks social-links" data-v-6aa21345 data-v-0394ad82 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ethanliu6/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a class="VPSocialLink no-icon" href="https://space.bilibili.com/1327099977/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z"/></svg></a><!--]--></div><div class="VPFlyout VPNavBarExtra extra" data-v-6aa21345 data-v-bb2aa2f0 data-v-b6c34ac9><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-b6c34ac9><span class="vpi-more-horizontal icon" data-v-b6c34ac9></span></button><div class="menu" data-v-b6c34ac9><div class="VPMenu" data-v-b6c34ac9 data-v-b98bc113><!----><!--[--><!--[--><!----><div class="group" data-v-bb2aa2f0><div class="item appearance" data-v-bb2aa2f0><p class="label" data-v-bb2aa2f0>深色模式</p><div class="appearance-action" data-v-bb2aa2f0><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title aria-checked="false" data-v-bb2aa2f0 data-v-5337faa4 data-v-1d5665e3><span class="check" data-v-1d5665e3><span class="icon" data-v-1d5665e3><!--[--><span class="vpi-sun sun" data-v-5337faa4></span><span class="vpi-moon moon" data-v-5337faa4></span><!--]--></span></span></button></div></div></div><div class="group" data-v-bb2aa2f0><div class="item social-links" data-v-bb2aa2f0><div class="VPSocialLinks social-links-list" data-v-bb2aa2f0 data-v-7bc22406><!--[--><a class="VPSocialLink no-icon" href="https://github.com/ethanliu6/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></a><a class="VPSocialLink no-icon" href="https://space.bilibili.com/1327099977/" aria-label target="_blank" rel="noopener" data-v-7bc22406 data-v-eee4e7cb><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill="#6841d2" d="M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z"/></svg></a><!--]--></div></div></div><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-6aa21345 data-v-e5dd9c1c><span class="container" data-v-e5dd9c1c><span class="top" data-v-e5dd9c1c></span><span class="middle" data-v-e5dd9c1c></span><span class="bottom" data-v-e5dd9c1c></span></span></button></div></div></div></div><div class="divider" data-v-6aa21345><div class="divider-line" data-v-6aa21345></div></div></div><!----></header><div class="VPLocalNav has-sidebar empty" data-v-5d98c3a5 data-v-a6f0e41e><div class="container" data-v-a6f0e41e><button class="menu" aria-expanded="false" aria-controls="VPSidebarNav" data-v-a6f0e41e><span class="vpi-align-left menu-icon" data-v-a6f0e41e></span><span class="menu-text" data-v-a6f0e41e>Menu</span></button><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-a6f0e41e data-v-17a5e62e><button data-v-17a5e62e>Return to top</button><!----></div></div></div><aside class="VPSidebar" data-v-5d98c3a5 data-v-319d5ca6><div class="curtain" data-v-319d5ca6></div><nav class="nav" id="VPSidebarNav" aria-labelledby="sidebar-aria-label" tabindex="-1" data-v-319d5ca6><span class="visually-hidden" id="sidebar-aria-label" data-v-319d5ca6> Sidebar Navigation </span><!--[--><!--]--><!--[--><div class="no-transition group" data-v-c40bc020><section class="VPSidebarItem level-0 has-active" data-v-c40bc020 data-v-b7550ba0><!----><div class="items" data-v-b7550ba0><!--[--><section class="VPSidebarItem level-1 collapsible collapsed has-active" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>01_deep_learning_theory</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/01-feedforward_network.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01-feedforward_network</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/02-back_propagation.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>02-back_propagation</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/03-bp_example_demo.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03-bp_example_demo</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/04-convolution_neural_network.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>04-convolution_neural_network</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/05-deep_learning_model.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>05-deep_learning_model</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/06-pytorch_install.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>06-pytorch_install</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/07-operators.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>07-operators</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/08-activation_functions.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>08-activation_functions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/09-recurrent_neural_network.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>09-recurrent_neural_network</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/10-seq2seq.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>10-seq2seq</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/11-1attentions.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>11-1attentions</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/11-2attention-extension.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>11-2attention-extension</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/12-weight-initialization.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>12-weight-initialization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/13-optimizers.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>13-optimizers</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/14-regularization.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>14-regularization</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/15-deep-learning-tuning-guide.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>15-deep-learning-tuning-guide</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/20-pytorch-tensor.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>20-pytorch-tensor</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/21-pytorch-autograd.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>21-pytorch-autograd</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/22-pytorch-module.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>22-pytorch-module</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/23-1training-example-1.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-1training-example-1</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/23-2decoder.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-2decoder</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/23-3encoder.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-3encoder</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/23-4transformer.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23-4transformer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/24-pytorch-optimizer.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>24-pytorch-optimizer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/25-pytorch-lr-scheduler.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>25-pytorch-lr-scheduler</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/26-pytorch-dataloader.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>26-pytorch-dataloader</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/27-pytorch-model-save.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>27-pytorch-model-save</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/28-pytorch-tensorboard.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>28-pytorch-tensorboard</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/29-pytorch-graph-mode.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>29-pytorch-graph-mode</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/30-1training-example-cv.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>30-1training-example-cv</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/30-3main.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>30-3main</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/31-1stable-diffusion.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>31-1stable-diffusion</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/31-2SDXL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>31-2SDXL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/31-3VAE.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>31-3VAE</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/40-nlp-bert_ner.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>40-nlp-bert_ner</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/41-nlp-t5_question-answering.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>41-nlp-t5_question-answering</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/42-nlp-gpt.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>42-nlp-gpt</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/43-scaling-law.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>43-scaling-law</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/44-distribute-training.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>44-distribute-training</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/45-LLM-History.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>45-LLM-History</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/46-LLM-GPT-Extension.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>46-LLM-GPT-Extension</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/46-nlp-llama.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>46-nlp-llama</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/47-LLM-DeepSeek-Structure.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>47-LLM-DeepSeek-Structure</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/01_deep_learning_theory/47-nlp-deepseek.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>47-nlp-deepseek</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>02_distribute_training</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/00_large-scale-model-trainning.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>00_large-scale-model-trainning</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/01_coding.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01_coding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/01_offload-and-recompute.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01_offload-and-recompute</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/02_amp.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>02_amp</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/03_coding.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03_coding</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/03_pytorch-DP.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03_pytorch-DP</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/04_pytorch-DDP.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>04_pytorch-DDP</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/05_pytorch-DDP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>05_pytorch-DDP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/05_pytorch-DDP-IMPL_DDP_ORIGIN.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>05_pytorch-DDP-IMPL_DDP_ORIGIN</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/06_collective-comm.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>06_collective-comm</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/06_torchrun-process-group.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>06_torchrun-process-group</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/07_ZeRO-Optimizer.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>07_ZeRO-Optimizer</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/08_pytorch-ZeRO-1.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>08_pytorch-ZeRO-1</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/09_pytorch-FSDP-v1.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>09_pytorch-FSDP-v1</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/10_pytorch-FSDP-v2.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>10_pytorch-FSDP-v2</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/11_deepspeed-ZeRO-1-2-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>11_deepspeed-ZeRO-1-2-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/12_deepspeed-ZeRO-3-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>12_deepspeed-ZeRO-3-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/13_megatron-ZeRO-1-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>13_megatron-ZeRO-1-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/14_TP-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>14_TP-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/15_megatron-TP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>15_megatron-TP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/16_pytorch-TP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>16_pytorch-TP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/17_PP-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>17_PP-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/18_pytorch-PP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>18_pytorch-PP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/19_deepspeed-PP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>19_deepspeed-PP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/20_megatron-PP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>20_megatron-PP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/21_SP-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>21_SP-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/22_megatron-SP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>22_megatron-SP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/23_3D-Parallel-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>23_3D-Parallel-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/24_megatron-3D-Parallel-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>24_megatron-3D-Parallel-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/25_pytorch-3D-Parallel-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>25_pytorch-3D-Parallel-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/26_CP-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>26_CP-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/27_megatron-CP-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>27_megatron-CP-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/28_MOE-Theory.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>28_MOE-Theory</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/28_MOE-Theory_DeepSeekMOE.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>28_MOE-Theory_DeepSeekMOE</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/29_megatron-MOE-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>29_megatron-MOE-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/30_deepspeed-MOE-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>30_deepspeed-MOE-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/31_deepspeed-code-IMPL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>31_deepspeed-code-IMPL</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/32_collective-operations.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>32_collective-operations</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/02_distribute_training/33_pytorch_distribute.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>33_pytorch_distribute</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>03_Transformer</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/03_Transformer/01-Transformer的由来.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01-Transformer的由来</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/03_Transformer/02-Transformer架构解读.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>02-Transformer架构解读</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/03_Transformer/03-Transformer源码构建.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03-Transformer源码构建</p><!--]--></a><!----></div><!----></div><!--]--></div></section><section class="VPSidebarItem level-1 collapsible collapsed" data-v-b7550ba0 data-v-b7550ba0><div class="item" role="button" tabindex="0" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><h3 class="text" data-v-b7550ba0>04_some_notes</h3><div class="caret" role="button" aria-label="toggle section" tabindex="0" data-v-b7550ba0><span class="vpi-chevron-right caret-icon" data-v-b7550ba0></span></div></div><div class="items" data-v-b7550ba0><!--[--><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/04_some_notes/00-DL_base_notes.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>00-DL_base_notes</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/04_some_notes/01-class_logs.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>01-class_logs</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/04_some_notes/02-some_detials.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>02-some_detials</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/04_some_notes/03-Bert理解.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>03-Bert理解</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/04_some_notes/04-个人补充内容.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>04-个人补充内容</p><!--]--></a><!----></div><!----></div><div class="VPSidebarItem level-2 is-link" data-v-b7550ba0 data-v-b7550ba0><div class="item" data-v-b7550ba0><div class="indicator" data-v-b7550ba0></div><a class="VPLink link link" href="/AI/04_some_notes/05-Review_DL.html" data-v-b7550ba0><!--[--><p class="text" data-v-b7550ba0>05-Review_DL</p><!--]--></a><!----></div><!----></div><!--]--></div></section><!--]--></div></section></div><!--]--><!--[--><!--]--></nav></aside><div class="VPContent has-sidebar" id="VPContent" data-v-5d98c3a5 data-v-1428d186><div class="VPDoc has-sidebar has-aside" data-v-1428d186 data-v-39a288b8><!--[--><!--]--><div class="container" data-v-39a288b8><div class="aside" data-v-39a288b8><div class="aside-curtain" data-v-39a288b8></div><div class="aside-container" data-v-39a288b8><div class="aside-content" data-v-39a288b8><div class="VPDocAside" data-v-39a288b8 data-v-3f215769><!--[--><!--]--><!--[--><!--]--><nav aria-labelledby="doc-outline-aria-label" class="VPDocAsideOutline" data-v-3f215769 data-v-a5bbad30><div class="content" data-v-a5bbad30><div class="outline-marker" data-v-a5bbad30></div><div aria-level="2" class="outline-title" id="doc-outline-aria-label" role="heading" data-v-a5bbad30>本文目录</div><ul class="VPDocOutlineItem root" data-v-a5bbad30 data-v-b933a997><!--[--><!--]--></ul></div></nav><!--[--><!--]--><div class="spacer" data-v-3f215769></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-39a288b8><div class="content-container" data-v-39a288b8><!--[--><!--]--><main class="main" data-v-39a288b8><div style="position:relative;" class="vp-doc _AI_01_deep_learning_theory_45-LLM-History" data-v-39a288b8><div><h1 id="_0-llm简史-从transformer-2017-到deepseek-r1-2025" tabindex="-1">0 LLM简史：从Transformer（2017）到DeepSeek-R1（2025） <a class="header-anchor" href="#_0-llm简史-从transformer-2017-到deepseek-r1-2025" aria-label="Permalink to &quot;0 LLM简史：从Transformer（2017）到DeepSeek-R1（2025）&quot;">​</a></h1><p><img src="https://mmbiz.qpic.cn/mmbiz_jpg/8AEic8PL2YEp3Vpx1hKpj932kjKQ7Sia5Fj4yPvibTZgEMyuGvAsvVNfgy4WdYn0xc8n01mG68MXLrmeLelKUGadQ/0?wx_fmt=jpeg" alt="cover_image"></p><p>2025年初，中国推出了具有开创性且高性价比的「大型语言模型」（Large Language Model——LLM）DeepSeek-R1，引发了AI的巨大变革。本文回顾了LLM的发展历程，起点是2017年<code>革命性的Transformer架构</code>，该架构通过「<strong>自注意力机制</strong>」(Self- Attention) <strong>彻底重塑了自然语言处理</strong>。到2018年，BERT和GPT等模型崭露头角，显著提升了上下文理解和文本生成能力。2020年，拥有1750亿参数的GPT-3展示了卓越的「少样本(few-shot)」和「零样本zero-shot」学习能力。然而，「幻觉」问题 — —即生成内容与事实不符，甚至出现「一本正经地胡说八道」的现象 — —成为了一个关键挑战。2022年，OpenAI通过开发「对话式」的ChatGPT应对这一问题，采用了「<strong>监督微调</strong>」（SFT）和「<strong>基于人类反馈的强化学习</strong>」（RLHF）。到2023年，像GPT-4这样的「多模态模型」整合了文本、图像和音频处理能力，使LLM能够以更接近人类的「听」、「说」、「看」能力。</p><p><strong>对话式ChatGPT 和 传统问答系统/搜索引擎的不同</strong></p><table tabindex="0"><thead><tr><th style="text-align:center;">特性</th><th style="text-align:center;">对话式 ChatGPT</th><th style="text-align:center;">传统问答系统/搜索引擎</th></tr></thead><tbody><tr><td style="text-align:center;">交互模式</td><td style="text-align:center;">多轮、动态对话</td><td style="text-align:center;">单次输入、单次输出</td></tr><tr><td style="text-align:center;">上下文处理</td><td style="text-align:center;">支持上下文关联</td><td style="text-align:center;">每次查询独立处理</td></tr><tr><td style="text-align:center;">回答生成</td><td style="text-align:center;">生成自然语言文本</td><td style="text-align:center;">返回链接、摘要或固定模板内容</td></tr><tr><td style="text-align:center;">灵活性</td><td style="text-align:center;">适应模糊、复杂问题</td><td style="text-align:center;">依赖关键词匹配，对模糊问题敏感</td></tr></tbody></table><p>    近期推出的OpenAI-o1和DeepSeek-R1「<strong>推理模型</strong>」(<code>Reasoning Model</code>)在复杂问题解决方面取得突破，赋予LLM更接近人类「系统思维」的深度推理能力，<code>标志着人工智能在模拟人类思维模式上迈出了重要一步</code>。此外，DeepSeek-R1模型以其「<strong>超成本效益</strong>」和「<strong>开源</strong>」设计挑战了AI领域的传统规范，推动了先进LLM的普及，并促进了各行业的创新。</p><h1 id="_1-什么是语言模型-language-models" tabindex="-1">1. 什么是语言模型 (Language Models)？ <a class="header-anchor" href="#_1-什么是语言模型-language-models" aria-label="Permalink to &quot;1. 什么是语言模型 (Language Models)？&quot;">​</a></h1><p>「语言模型」是一种「人工智能系统」，旨在处理、理解和生成类似人类的语言。它们从大型数据集中学习模式和结构，使得能够产生连贯且上下文相关的文本，应用于翻译、摘要、聊天机器人和内容生成等领域。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure2.png" alt="figure2"></p><p><em>语言模型就是这样一个模型：对于任意的词序列，它能够计算出这个序列是一句话的概率。或者说语言模型能预测单词序列的下一个词是什么。</em></p><h2 id="_1-1-大型语言模型-llms" tabindex="-1">1.1 大型语言模型（LLMs） <a class="header-anchor" href="#_1-1-大型语言模型-llms" aria-label="Permalink to &quot;1.1 大型语言模型（LLMs）&quot;">​</a></h2><p>    「语言模型」（LMs）和「大型语言模型」（LLMs）这两个术语虽然经常被互换使用，但实际上它们基于规模、架构、训练数据和能力指代不同的概念。LLMs 是 LMs 的一个子集，其规模显著更大，通常包含数十亿个参数（例如，GPT-3 拥有 1750 亿个参数）。这种更大的规模使 LLMs 能够在广泛的任务中表现出卓越的性能。</p><p>“LLM”这一术语在 2018 至 2019 年间随着基于 Transformer 架构的模型（如 BERT 和 GPT-1）的出现开始受到关注。然而，在 2020 年 <code>GPT-3 发布后，这个词才被广泛使用</code>，展示了这些大规模模型的重大影响力和强大能力。</p><h2 id="_1-2-自回归语言模型-autoregressive-language-models" tabindex="-1">1.2 自回归语言模型 （Autoregressive Language Models） <a class="header-anchor" href="#_1-2-自回归语言模型-autoregressive-language-models" aria-label="Permalink to &quot;1.2 自回归语言模型 （Autoregressive Language Models）&quot;">​</a></h2><p>    大多数LLMs以「自回归方式」(Autoregressive)操作，这意味着它们根据前面的「文本」预测下一个「字」（或token／sub-word）的「概率分布」(propability distribution)。这种自回归特性使模型能够学习复杂的语言模式和依赖关系，从而善于「<strong>文本生成</strong>」。</p><p>    在数学上，LLM 是一个概率模型（Probabilistic Model），根据之前的输入文本 $ x_1, x_2, \ldots, x_{n-1} $ 预测下一个字 $ x_n $ 的概率分布。这可以表示为：<br></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>P</mi><mo>(</mo><msub><mi>x</mi><mi>n</mi></msub><mi mathvariant="normal">∣</mi><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">P(x_n|x_1, x_2, \ldots, x_{n-1}) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">P</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">n</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathrm">∣</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="minner">…</span><span class="mpunct">,</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">n</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></span></p><p>    在文本生成任时，LLM通过<strong>解码算法(Decoding Algorithm)</strong> 来确定下一个输出的token。这一过程可以采用不同的策略：既可以选择概率最高的下个字（即贪婪搜索），也可以从预测的概率分布中<strong>随机采样一个token</strong>。后一种方法使得每次生成的文本都可能有所不同，这种特性与人类语言的多样性和随机性颇为相似。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure3.png" alt="figure3"></p><h2 id="_1-3-生成能力" tabindex="-1">1.3 生成能力 <a class="header-anchor" href="#_1-3-生成能力" aria-label="Permalink to &quot;1.3 生成能力&quot;">​</a></h2><p>    LLMs的<code>自回归特性</code>使其能够基于前文提供的上下文逐词生成文本。从「提示」(prompt)开始，如下图，模型通过迭代预测下一个词，直到生成完整的序列或达到预定的停止条件。为了生成对提示的完整回答，LLM通过<code>将先前选择的token添加到输入中进行迭代生成</code>，尤如 「文字接龙」游戏。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure4.png" alt="figure4"></p><blockquote><p>LLM的文本生成尤如「文字接龙」游戏。</p></blockquote><p>    这种生成能力推动了多种应用的发展，例如创意写作、对话式人工智能以及自动化客户支持系统。</p><h1 id="_2-transformer革命-2017" tabindex="-1">2. Transformer革命 (2017) <a class="header-anchor" href="#_2-transformer革命-2017" aria-label="Permalink to &quot;2\. Transformer革命 (2017)&quot;">​</a></h1><p>    Vaswani等人在2017年通过其开创性论文<strong>Attention is All You Need</strong>引入了<strong>Transformer架构</strong>，标志着NLP的一个<code>分水岭时刻</code>。它解决了早期模型如循环神经网络（RNNs）和长短期记忆网络（LSTMs）的关键限制，这些模型<code>在长程依赖性和顺序处理方面存在困难</code>。这些问题使得使用RNN或LSTM实现有效的语言模型变得困难，因为它们计算效率低下且容易出现梯度消失等问题。另一方面，Transformers克服了这些障碍，彻底改变了这一领域，并为现代大型语言模型奠定了基础。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure5.png" alt="figure5"></p><blockquote><p>自注意力和Transformer架构</p></blockquote><h2 id="_2-1-transformer架构的关键创新" tabindex="-1">2.1 Transformer架构的关键创新 <a class="header-anchor" href="#_2-1-transformer架构的关键创新" aria-label="Permalink to &quot;2.1 Transformer架构的关键创新&quot;">​</a></h2><ol><li>自注意力机制 (Self-Attention)：与按顺序处理标记并难以应对长程依赖性的RNN不同，Transformers使用自注意力来权衡每个标记相对于其他标记的重要性。这使得模型能够动态关注输入的相关部分。数学上：</li></ol><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>A</mi><mi>t</mi><mi>t</mi><mi>e</mi><mi>n</mi><mi>t</mi><mi>i</mi><mi>o</mi><mi>n</mi><mo>(</mo><mi>Q</mi><mo separator="true">,</mo><mi>K</mi><mo separator="true">,</mo><mi>V</mi><mo>)</mo><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo>(</mo><mfrac><mrow><mi>Q</mi><msup><mi>K</mi><mi>T</mi></msup></mrow><mrow><msqrt><mrow><msub><mi>d</mi><mi>k</mi></msub></mrow></msqrt></mrow></mfrac><mo>)</mo><mi>V</mi></mrow><annotation encoding="application/x-tex">Attention(Q, K, V) = softmax(\frac{QK^T}{\sqrt{d_k}})V </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.5183309999999999em;"></span><span class="strut bottom" style="height:2.448331em;vertical-align:-0.9300000000000002em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit">A</span><span class="mord mathit">t</span><span class="mord mathit">t</span><span class="mord mathit">e</span><span class="mord mathit">n</span><span class="mord mathit">t</span><span class="mord mathit">i</span><span class="mord mathit">o</span><span class="mord mathit">n</span><span class="mopen">(</span><span class="mord mathit">Q</span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.07153em;">K</span><span class="mpunct">,</span><span class="mord mathit" style="margin-right:0.22222em;">V</span><span class="mclose">)</span><span class="mrel">=</span><span class="mord mathit">s</span><span class="mord mathit">o</span><span class="mord mathit" style="margin-right:0.10764em;">f</span><span class="mord mathit">t</span><span class="mord mathit">m</span><span class="mord mathit">a</span><span class="mord mathit">x</span><span class="mopen">(</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.7472200000000002em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="sqrt mord"><span class="sqrt-sign" style="top:-0.017220000000000013em;"><span class="style-wrap reset-textstyle textstyle uncramped">√</span></span><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="mord textstyle cramped"><span class="mord"><span class="mord mathit">d</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit" style="margin-right:0.03148em;">k</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span style="top:-0.77722em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped sqrt-line"></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathit">Q</span><span class="mord"><span class="mord mathit" style="margin-right:0.07153em;">K</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:1em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mclose">)</span><span class="mord mathit" style="margin-right:0.22222em;">V</span></span></span></span></span></p><p>这里，Q、K、V是查询(query)、键(key)和值(value)矩阵，dₖ是键的维度。自注意力允许并行计算，加快训练速度，同时提高全局上下文理解。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure6.png" alt="figure6"></p><ol start="2"><li>多头注意力：多个注意力头并行操作，每个头专注于输入的不同方面。它们的输出被连接并转换，从而实现更丰富的上下文表示。</li></ol><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure7.png" alt="figure"></p><ol start="3"><li><p>前馈网络(FFN)和层归一化(Layer Norm)：每个Transformer层包括应用于每个标记的前馈网络，以及层归一化和残差连接。这些稳定了训练并支持更深的架构。</p></li><li><p>位置编码：由于Transformers本身不编码标记顺序，因此添加了位置编码（位置和频率的正弦函数）以表示词序，在不牺牲并行化的情况下保留顺序信息。</p></li></ol><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure8.png" alt="figure"></p><h2 id="_2-2-对语言建模的影响" tabindex="-1">2.2 对语言建模的影响 <a class="header-anchor" href="#_2-2-对语言建模的影响" aria-label="Permalink to &quot;2.2 对语言建模的影响&quot;">​</a></h2><ul><li>可扩展性：Transformers实现了<strong>完全并行化的计算</strong>，<code>使得在大型数据集上训练大规模模型成为可能</code>。</li><li>上下文理解：自注意力<code>捕捉局部和全局依赖关系</code>，提高了连贯性和上下文意识。</li></ul><p>    Transformer架构的引入为构建<code>以前所未有的精确性和灵活性处理复杂任务的大规模高效语言模型</code>奠定了基础。</p><h2 id="_3-预训练transformer模型时代-2018–2020" tabindex="-1">3. 预训练Transformer模型时代 (2018–2020) <a class="header-anchor" href="#_3-预训练transformer模型时代-2018–2020" aria-label="Permalink to &quot;3\. 预训练Transformer模型时代 (2018–2020)&quot;">​</a></h2><p>    2017年Transformer架构的引入为NLP的新时代铺平了道路，其特点是<strong>预训练模型</strong>的兴起和对<strong>扩展</strong>的前所未有的关注。这一时期见证了两个有影响力的模型家族的出现：<code>BERT和GPT</code>，它们展示了大规模<strong>预训练和微调</strong>范式的强大功能。<br></p><h2 id="_3-1-bert-双向上下文理解-2018" tabindex="-1">3.1. BERT：双向上下文理解 (2018) <a class="header-anchor" href="#_3-1-bert-双向上下文理解-2018" aria-label="Permalink to &quot;3.1. BERT：双向上下文理解 (2018)&quot;">​</a></h2><p>    2018年，谷歌推出了<strong>BERT（Bidirectional Encoder Representations from Transformers）</strong> ，这是一种使用Transformer编码器(Encoder)的突破性模型，<code>在广泛的NLP任务中取得了最先进的性能</code>。与之前单向处理文本（从左到右或从右到左）的模型不同，BERT采用了<code>双向训练方法</code>，使其能够同时<strong>从两个方向捕获上下文</strong>。通过生成深层次的、上下文丰富的文本表示，<code>BERT在文本分类、命名实体识别（NER）、情感分析等语言理解任务中表现出色</code>。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure9.png" alt="figure"></p><p>    BERT的关键创新包括：<br></p><ul><li><strong>掩码语言建模</strong>（Masked Language Modeling — MLM）：BERT不是预测序列中的下一个词，而是被训练预测句子中随机掩码的标记。这迫使模型在进行预测时考虑整个句子的上下文 — — 包括前后词语。例如，给定句子“The cat sat on the [MASK] mat”，BERT会学习根据周围上下文预测“soft”。</li><li><strong>下一句预测</strong>（Next Sentence Prediction — NSP）：除了MLM之外，BERT还接受了称为下一句预测的次要任务训练，其中模型学习预测两个句子是否在文档中连续。这帮助BERT在需要理解句子之间关系的任务中表现出色，例如问答和自然语言推理。</li></ul><p>    BERT的影响：BERT的双向训练使其在GLUE（通用语言理解评估）和SQuAD（斯坦福问答数据集）等基准测试中取得了突破性的表现。它的成功证明了上下文嵌入的重要性— — 这些<strong>表示</strong>根据<code>周围词语</code>动态变化 — — 并为新一代预训练模型铺平了道路。</p><h2 id="_3-2-gpt-生成式预训练和自回归文本生成-2018–2020" tabindex="-1">3.2 GPT：生成式预训练和自回归文本生成（2018–2020） <a class="header-anchor" href="#_3-2-gpt-生成式预训练和自回归文本生成-2018–2020" aria-label="Permalink to &quot;3.2 GPT：生成式预训练和自回归文本生成（2018–2020）&quot;">​</a></h2><p>    虽然BERT优先考虑双向上下文理解，但OpenAI的GPT系列采用了不同的策略，<code>专注于通过自回归预训练实现生成能力</code>。通过利用Transformer的解码器(<strong>Decoder</strong>)，GPT模型<code>在自回归语言模型和文本生成方面表现出色</code>。<strong>GPT(2018)</strong> GPT的第一个版本于2018年发布，是一个大规模的Transformer模型，经过训练以预测序列中的下一个词，类似于传统语言模型。</p><ul><li><strong>单向自回归训练</strong>：GPT使用<code>因果语言建模</code>目标进行训练，其中模型仅基于前面的token预测下一个token。这使得它特别适合于<strong>生成式任务</strong>，如<code>文本补全、摘要生成和对话生成</code>。</li><li><strong>下游任务的微调</strong>：GPT的一个关键贡献是它能够在不需要特定任务架构的情况下针对特定下游任务进行微调。只需添加一个分类头或修改输入格式，GPT就可以适应诸如情感分析、机器翻译和问答等任务。</li></ul><p><strong>举例</strong> <br></p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">情感分析：</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">输入：“这篇电影评论的情感是积极的还是消极的？评论：这部电影太棒了！”</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">输出：“积极”</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">机器翻译：</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">输入：“将英文翻译为中文：Hello,</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> how</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> are</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> you?”</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">输出：“你好，最近怎么样？”</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">问答：</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">输入：“问题：珠穆朗玛峰的高度是多少？上下文：珠穆朗玛峰海拔8848.86米。”</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">输出：“8848.86米”</span></span></code></pre></div><p><strong>GPT-2 (2019)</strong>     在原版GPT的成功基础上，OpenAI发布了GPT-2，这是一个参数量达15亿的更大模型。GPT-2展示了令人印象深刻的零样本(Zero- shot)能力，意味着它可以在没有任何特定任务微调的情况下执行任务。例如，它可以生成连贯的文章、回答问题，甚至在语言之间翻译文本，尽管没有明确针对这些任务进行训练。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure10.png" alt="figure"></p><table tabindex="0"><thead><tr><th>模型</th><th>GPT1</th><th>GPT2</th><th>GPT3</th><th>GPT4</th></tr></thead><tbody><tr><td>参数</td><td>117M</td><td>1.5B</td><td>175B</td><td>1.8T</td></tr></tbody></table><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure11.png" alt="figure"></p><p>    <strong>GPT-3 (2020)</strong> GPT-3的发布标志着语言模型规模扩展的一个转折点。凭借惊人的1750亿参数(175B parameters)，GPT-3突破了大规模预训练的可能性界限。它展示了显著的<strong>少样本(Few-short)和零样本(Zero-short)学习能力</strong>，在推理时只需提供最少或无需示例即可执行任务。GPT-3的生成能力<code>扩展到了创意写作、编程和复杂推理任务，展示了超大模型的潜力</code>。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure12.png" alt="figure"></p><h2 id="_3-3-gpt的影响及规模的作用" tabindex="-1">3.3 GPT的影响及规模的作用 <a class="header-anchor" href="#_3-3-gpt的影响及规模的作用" aria-label="Permalink to &quot;3.3 GPT的影响及规模的作用&quot;">​</a></h2><p>    GPT模型的引入，特别是GPT-3，标志着AI的一个变革时代，展示了<code>自回归架构和生成能力的强大功能</code>。这些模型为内容创作、对话代理和自动推理等应用开辟了新的可能性，在广泛的任务中达到了接近人类的表现。GPT-3凭借其1750亿参数证明了规模的深远影响，表明在大规模数据集上训练的更大模型可以树立新的AI能力标杆。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure13.png" alt="figure"></p><blockquote><p>语言建模性能随着<strong>模型大小、数据集大小和训练使用的计算量</strong>的增加而平稳提升。<a href="https://arxiv.org/pdf/2001.08361" target="_blank" rel="noreferrer">https://arxiv.org/pdf/2001.08361</a></p></blockquote><p>    在2018年至2020年间，该领域由<strong>对规模的不懈追求</strong>驱动。研究人员发现，随着模型规模的增长 — — 从数百万到数十亿参数 — —它们在<code>捕捉复杂模式和泛化到新任务方面变得更好</code>。这种规模效应得到了三个关键因素的支持：</p><ul><li><strong>数据集大小</strong>：更大的模型需要庞大的数据集进行<code>预训练</code>。例如，GPT-3是在大量互联网文本语料库上进行训练的，使其能够学习多样化的语言模式和知识领域。</li><li><strong>计算资源</strong>：强大的硬件（如GPU和TPU）的可用性以及分布式训练技术，使得高效训练具有数十亿参数的模型成为可能。</li><li><strong>高效架构</strong>：混合精度训练和梯度检查点等创新降低了计算成本，使得在合理的时间和预算内进行大规模训练更加实际。</li></ul><p>    这个规模扩展的时代不仅提升了语言模型的性能，还为未来的AI突破奠定了基础，强调了规模、数据和计算在实现最先进结果中的重要性。</p><h1 id="_4-后训练对齐-弥合ai与人类价值观之间的差距-2021–2022" tabindex="-1">4. 后训练对齐：弥合AI与人类价值观之间的差距 (2021–2022) <a class="header-anchor" href="#_4-后训练对齐-弥合ai与人类价值观之间的差距-2021–2022" aria-label="Permalink to &quot;4\. 后训练对齐：弥合AI与人类价值观之间的差距 (2021–2022)&quot;">​</a></h1><p>    GPT-3（一个拥有1750亿参数的LLM）生成几乎无法与人类写作区分的文本的能力引发了关于AI生成内容的真实性和可信度的重大担忧。尽管这一成就标志着AI发展的一个重要里程碑，但也突显了确保这些模型与人类价值观、偏好和期望保持一致的关键挑战。一个主要问题是「幻觉」（Hallucination），即<strong>LLM生成与事实不符、无意义或与输入提示矛盾的内容</strong>，给人一种「<code>一本正经地胡说八道</code>」的印象。为了解决这些挑战，<code>2021年和2022年的研究人员专注于改善与人类意图的一致性并减少幻觉</code>，导致了<strong>监督微调(SFT)</strong> 和基于人类反馈的<strong>强化学习(RLHF)</strong> 等技术的发展。<br></p><h2 id="_4-1-监督微调-sft" tabindex="-1">4.1 监督微调 (SFT) <a class="header-anchor" href="#_4-1-监督微调-sft" aria-label="Permalink to &quot;4.1 监督微调 (SFT)&quot;">​</a></h2><p>    增强GPT-3 <strong>对齐能力</strong>的第一步是监督微调（SFT），这是<strong>RLHF框架</strong>的基础组成部分。SFT类似于指令调优，涉及在<code>高质量的输入-输出对或演示上训练模型</code>，以教它如何遵循指令并生成所需的输出。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure14.png" alt="figure"></p><p>    这些演示经过精心策划，以反映预期的行为和结果，确保模型学会生成准确且符合上下文的响应。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure15.png" alt="figure"></p><p>然而，SFT本身有局限性：</p><ol><li>可扩展性：收集人类演示是<strong>劳动密集型且耗时</strong>的，尤其是对于复杂或小众任务。</li><li>性能：简单模仿人类行为并<strong>不能保证模型会超越人类表现或在未见过的任务上很好地泛化</strong>。</li></ol><p>    为了克服这些挑战，需要一种更具可扩展性和效率的方法，为下一步铺平了道路：<strong>基于人类反馈的强化学习</strong>（Reinforcement Learning from Human Feedback — RLHF）。</p><h2 id="_4-2-基于人类反馈的强化学习-rlhf" tabindex="-1">4.2 基于人类反馈的强化学习 (RLHF) <a class="header-anchor" href="#_4-2-基于人类反馈的强化学习-rlhf" aria-label="Permalink to &quot;4.2 基于人类反馈的强化学习 (RLHF)&quot;">​</a></h2><p>    OpenAI在2022年引入的<strong>RLHF解决了SFT的可扩展性和性能限制</strong>。与需要人类编写完整输出的SFT不同，RLHF涉及<code>根据质量对多个模型生成的输出进行排名</code>。这种方法允许更高效的数据收集和标注，显著增强了可扩展性。</p><p><strong>RLHF过程包括两个关键阶段：</strong></p><ol><li>训练奖励模型：人类注释者<code>对模型生成的多个输出进行排名</code>，创建一个偏好数据集。这些数据用于训练一个<strong>奖励模型(reward model)</strong>，该模型学习<code>根据人类反馈评估输出的质量</code>。</li><li>使用强化学习微调LLM：奖励模型使用<strong>近端策略优化（Proximal Policy Optimization - PPO）（一种强化学习算法）</strong> 指导LLM的微调。通过迭代更新，模型学会了<code>生成更符合人类偏好和期望的输出</code>。</li></ol><p>这个两阶段过程 — — <strong>结合SFT和RLHF</strong> — —使模型不仅能够准确遵循指令，还能<code>适应新任务并持续改进</code>。通过将人类反馈整合到训练循环中，RLHF显著增强了模型生成可靠、符合人类输出的能力，为AI对齐和性能设定了新标准。</p><h2 id="_4-3-chatgpt-推进对话式ai-2022" tabindex="-1">4.3 ChatGPT：推进对话式AI (2022) <a class="header-anchor" href="#_4-3-chatgpt-推进对话式ai-2022" aria-label="Permalink to &quot;4.3 ChatGPT：推进对话式AI (2022)&quot;">​</a></h2><p>    2022年3月，OpenAI推出了GPT-3.5，这是GPT-3的升级版，<strong>架构相同但训练和微调有所改进</strong>。关键增强包括通过改进数据更好地遵循指令，<code>减少了幻觉（尽管未完全消除），以及更多样化、更新的数据集，以生成更相关、上下文感知的响应。</code></p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure16.png" alt="figure"></p><p><strong>ChatGPT:</strong> <br> 基于<strong>GPT-3.5和InstructGPT</strong>，OpenAI于2022年11月推出了ChatGPT，这是一种突破性的<code>对话式AI模型</code>，专门<strong>为自然的多轮对话进行了微调</strong>。ChatGPT的关键改进包括：</p><ul><li><strong>对话聚焦的微调</strong>：在大量<strong>对话数据集上</strong>进行训练，ChatGPT擅长<code>维持对话的上下文和连贯性</code>，实现更引人入胜和类似人类的互动。</li><li><strong>RLHF</strong>：通过整合RLHF，ChatGPT学会了生成<code>不仅有用而且诚实和无害的响应</code>。人类培训师根据质量<strong>对响应进行排名</strong>，使模型能够逐步改进其表现。</li></ul><p><strong>ChatGPT的推出标志着AI的一个关键时刻，通常被称为「ChatGPT时刻」(ChatGPT moment)，因为它展示了对话式AI改变人机交互的潜力。</strong></p><h1 id="_5-多模态模型-连接文本、图像及其他-2023–2024" tabindex="-1">5. 多模态模型：连接文本、图像及其他 (2023–2024) <a class="header-anchor" href="#_5-多模态模型-连接文本、图像及其他-2023–2024" aria-label="Permalink to &quot;5\. 多模态模型：连接文本、图像及其他 (2023–2024)&quot;">​</a></h1><p>    在2023年至2024年间，像GPT-4V和GPT-4o这样的多模态大型语言模型（MLLMs:Multimodal Large Language Models）通过将文本、图像、音频和视频整合到统一系统中重新定义了AI。这些模型扩展了传统语言模型的能力，实现了更丰富的交互和更复杂的问题解决。<br></p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure17.png" alt="figure"></p><h2 id="_5-1-gpt-4v-视觉遇见语言" tabindex="-1">5.1 GPT-4V：视觉遇见语言 <a class="header-anchor" href="#_5-1-gpt-4v-视觉遇见语言" aria-label="Permalink to &quot;5.1 GPT-4V：视觉遇见语言&quot;">​</a></h2><p>    2023年，OpenAI推出了GPT-4V，将GPT-4的<strong>语言能力</strong>与先进的<strong>计算机视觉</strong>相结合。它可以<code>解释图像、生成标题、回答视觉问题，并推断视觉中的上下文关系</code>。其跨模态注意力机制允许文本和图像数据的无缝集成，使其在医疗保健（如分析医学图像）和教育（如互动学习工具）等领域具有价值。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure18.png" alt="figure"></p><h2 id="_5-2-gpt-4o-全模态前沿" tabindex="-1">5.2 GPT-4o：全模态前沿 <a class="header-anchor" href="#_5-2-gpt-4o-全模态前沿" aria-label="Permalink to &quot;5.2 GPT-4o：全模态前沿&quot;">​</a></h2><p>    到2024年初，GPT-4o通过整合音频和视频输入进一步推进了多模态。它在一个统一的表示空间中运行，可以转录音频、描述视频或将文本合成音频。实时交互和增强的创造力 — — 如生成多媒体内容 — — 使其成为娱乐和设计等行业的多功能工具。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure19.png" alt="figure"></p><p>    现实世界的影响: MLLMs革新了医疗保健（诊断）、教育（互动学习）和创意产业（多媒体制作）等领域。它们处理多种模态的能力解锁了创新的新可能性。</p><h1 id="_6-开源和开放权重模型-2023–2024" tabindex="-1">6. 开源和开放权重模型 (2023–2024) <a class="header-anchor" href="#_6-开源和开放权重模型-2023–2024" aria-label="Permalink to &quot;6\. 开源和开放权重模型 (2023–2024)&quot;">​</a></h1><p>    在2023年至2024年间，<strong>开源和开放权重AI模型获得了动力，使先进AI技术的访问民主化。</strong></p><ul><li><strong>开放权重LLMs</strong> ：开放权重模型提供公开访问的模型权重，限制极少。这使得微调和适应成为可能，<strong>但架构和训练数据保持封闭</strong>。它们适合快速部署。例子：Meta AI的LLaMA系列和Mistral AI的Mistral 7B / Mixtral 8x7B</li><li><strong>开源LLMs</strong> ：开源模型使底层代码和结构公开可用。这允许全面理解、修改和定制模型，促进创新和适应性。例子：OPT和BERT。</li><li><strong>社区驱动的创新</strong> ：像<strong>Hugging Face</strong>这样的平台促进了协作，<code>LoRA和PEFT等工具使高效的微调成为可能</code>。</li></ul><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure20.png" alt="figure"></p><p>    社区开发了专门针对医疗、法律和创意领域的模型，同时优先考虑道德AI实践。开源社区目前处于一个激动人心的阶段，得益于尖端对齐技术的出现。这一进展导致越来越多的卓越开放权重模型发布。因此，闭源和开放权重模型之间的差距正在稳步缩小。<strong>LLaMA3.1–405B模型首次历史性地弥合了与闭源对应物的差距</strong>。</p><p><strong>逆向工程反推llama架构</strong></p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Hugging</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Face</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 团队实现了与</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> LLaMA</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 兼容的模型类（LlamaForCausalLM），关键步骤包括：</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">b</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">r</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">1.</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 解析权重文件结构，确定各层维度。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">2.</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 对齐</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> RoPE</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 实现：根据</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> LLaMA</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 的生成效果调整位置编码计算方式。</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">3.</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> 发布配置文件：提供标准化的</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> config.json，用户可直接加载权重。</span></span></code></pre></div><p><strong>7. 推理模型：从「系统1」到「系统2」思维的转变 (2024)</strong></p><p>    2024年，AI开发开始强调<strong>增强「推理」(Reasoning</strong>)**，从简单的模式识别转向更逻辑化和结构化的思维过程。这一转变受到认知心理学双重过程理论的影响，<code>区分了「系统1」（快速、直觉）和「系统2」（缓慢、分析）思维</code>。虽然像GPT-3和GPT-4这样的早期模型在生成文本等「系统1」任务上表现出色，但<code>在深度推理和问题解决方面却有所欠缺</code>。<br></p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure21.png" alt="figure"></p><blockquote><p>「系统1」与「系统2」思维</p></blockquote><h2 id="_7-1-openai-o1-推理能力的一大飞跃-2024" tabindex="-1">7.1 OpenAI-o1：推理能力的一大飞跃(2024) <a class="header-anchor" href="#_7-1-openai-o1-推理能力的一大飞跃-2024" aria-label="Permalink to &quot;7.1 OpenAI-o1：推理能力的一大飞跃(2024)&quot;">​</a></h2><p>    OpenAI于2024年12月发布的o1模型旨在提高AI的推理能力，特别是在代码生成和调试等复杂任务上表现出色。o1模型的一个关键特征是通过 <strong>「思维链」(Chain of Thought－CoT)过程</strong>增强推理能力，使其能够将复杂问题分解为更小、更易管理的步骤。</p><p><strong>推理时间计算与能力</strong></p><ul><li><strong>思维链</strong>：o1模型在提供答案之前花费额外时间「思考」（thinking)，通过生成思维链来增强复杂推理，特别是在科学和数学领域。模型的准确性与在回答前用于思考的计算量的对数相关。</li><li><strong>o1模型套件包括</strong>: o1、o1-mini和o1 pro。o1-mini比o1-preview更快且更具成本效益，适用于编程和STEM相关任务，尽管它缺乏o1-preview的广泛世界知识。</li><li><strong>性能</strong>：o1-preview在物理、化学和生物学的基准测试中达到了大约博士水平的表现。在美国数学邀请赛中，它解决了83%的问题，相比之下GPT-4o解决了13%。它还在Codeforces编程竞赛中排名在第89百分位。</li></ul><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure22.png" alt="figure"></p><p><code>OpenAI-o1的发布标志着AI开发的一个关键时刻，展示了结合生成和推理能力创造能够像人类一样思考和行动的模型的潜力</code>。随着该领域的不断发展，<strong>推理模型有望解锁AI的新前沿</strong>，使机器能够应对人类面临的最具挑战性的问题。</p><p><strong>8. 成本高效的推理模型：DeepSeek-R1 (2025)</strong></p><p>    LLMs通常需要极其庞大的计算资源来进行训练和推理。像GPT-4o和OpenAI-o1这样的最先进LLM模型的闭源性质限制了对尖端AI的「普及化」。</p><h2 id="_8-1-deepseek-v3-2024–12" tabindex="-1">8.1 DeepSeek-V3 (2024–12) <a class="header-anchor" href="#_8-1-deepseek-v3-2024–12" aria-label="Permalink to &quot;8.1 DeepSeek-V3 (2024–12)&quot;">​</a></h2><p>    2024年12月下旬，「深度求索-V3」(DeepSeek-V3)作为一种成本高效的开放权重LLM出现，为AI的可访问性设定了新标准。DeepSeek-V3与OpenAI的ChatGPT等顶级解决方案相媲美，但开发成本显著降低，估计约为<strong>560万美元</strong>，仅为西方公司投资的一小部分。该模型最多包含<strong>6710亿个参数</strong>，其中<strong>370亿个活跃参数</strong>，并采用<strong>专家混合（MoE）架构</strong>，将模型划分为专门处理数学和编码等任务的组件，以减轻训练负担。DeepSeek-V3采用了工程效率，例如改进Key-Value缓存管理和进一步推动专家混合方法。该模型引入了三个关键架构：</p><ul><li><strong>多头潜在注意力</strong>（Multi-head Latent Attention — MLA）：通过压缩注意力键和值来减少内存使用，同时保持性能，并通过旋转位置嵌入（RoPE）增强位置信息。</li><li><strong>DeepSeek专家混合（DeepSeekMoE）</strong>：在前馈网络（FFNs）中采用共享和路由专家的混合，以提高效率并平衡专家利用率。</li><li><strong>多标记预测</strong> (Multi-Token Prediction — MTP)：<code>增强模型生成连贯且上下文相关的输出的能力，特别是对于需要复杂序列生成的任务</code>。</li></ul><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure23.png" alt="figure"></p><p>    DeepSeek-V3的发布引发了全球科技抛售，危及1万亿美元的市值，并导致英伟达股票盘前下跌13%。DeepSeek-V3的价格为每百万输出标记2.19美元，约为OpenAI类似模型成本的1/30。</p><h2 id="_8-2-deepseek-r1-zero-和-deepseek-r1-2025–01" tabindex="-1">8.2 DeepSeek-R1-Zero 和 DeepSeek-R1 (2025–01) <a class="header-anchor" href="#_8-2-deepseek-r1-zero-和-deepseek-r1-2025–01" aria-label="Permalink to &quot;8.2 DeepSeek-R1-Zero 和 DeepSeek-R1 (2025–01)&quot;">​</a></h2><p>    仅仅一个月后，2025年1月下旬，DeepSeek通过发布DeepSeek-R1-Zero和DeepSeek-R1再次引起轰动，这些模型展示了<strong>卓越的推理能力，训练成本极低</strong>。利用<code>先进的强化学习技术，这些模型证明了高性能推理可以在没有通常与尖端AI相关的巨额计算费用的情况下实现</code>。这一突破巩固了DeepSeek作为高效和可扩展AI创新领导者的地位。</p><ul><li><strong>DeepSeek-R1-Zero</strong>：一种基于DeepSeek-V3的推理模型，通过强化学习（RL）增强其推理能力。它完全消除了「监督微调」(SFT)阶段，直接从名为DeepSeek-V3-Base的预训练模型开始。它采用了一种基于「规则的强化学习方法」(Rule-based Reinforcement Learning)，称为「组相对策略优化」（Group Relative Policy Optimization — GRPO），根据预定义规则计算奖励，使训练过程更简单且更具可扩展性。</li></ul><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure24.png" alt="figure"></p><ul><li><strong>DeepSeek-R1</strong>：为了解决DeepSeek-R1-Zero的局限性，如低可读性和语言混杂，DeepSeek-R1纳入了一组有限的高质量冷启动数据和额外的RL训练。该模型经历了多个微调和RL阶段，包括拒绝采样和第二轮RL训练，以提高其通用能力和与人类偏好的一致性。</li></ul><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure25.png" alt="figure"></p><ul><li><strong>蒸馏DeepSeek模型</strong>：DeepSeek开发了较小的、蒸馏版的DeepSeek-R1，参数范围从15亿到700亿，将先进的推理能力带到较弱的硬件上。这些模型使用原始DeepSeek-R1生成的合成数据进行微调，确保在推理任务中表现出色，同时足够轻量化以便本地部署。</li></ul><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure26.png" alt="figure"></p><blockquote><p>DeepSeek 蒸馏DeepSeek模型</p></blockquote><p>    DeepSeek-R1在各种基准测试中表现出竞争力，包括数学、编码、常识和写作。根据使用模式，它相比OpenAI的o1模型等竞争对手提供了显著的成本节省，使用成本便宜20到50倍。</p><p><img src="https://coderethan-1327000741.cos.ap-chengdu.myqcloud.com/blog-pics/figure27.png" alt="figure"></p><h3 id="_8-3-对ai行业的影响" tabindex="-1"><strong>8.3 对AI行业的影响</strong> <a class="header-anchor" href="#_8-3-对ai行业的影响" aria-label="Permalink to &quot;**8.3 对AI行业的影响**&quot;">​</a></h3><p>    DeepSeek-R1的引入<code>挑战了AI领域的既定规范</code>，使先进LLMs得以「普及化」，并促进了一个更具竞争力的生态系统。其可负担性和可访问性预计将推动各行各业的采用和创新增加。最近，领先的云服务提供商如AWS、微软和谷歌云已在其平台上提供DeepSeek-R1。较小的云提供商和DeepSeek母公司以竞争性定价提供它。</p><p><strong>结论</strong></p><p>从2017年Transformer架构的引入到2025年DeepSeek-R1的发展，大型语言模型（LLMs）的演变标志着人工智能领域的一个革命性篇章。LLMs的崛起由四个里程碑式的成就标示：</p><ul><li><strong>Transformers (2017)</strong>：Transformer架构的引入为构建能够以前所未有的精确性和灵活性处理复杂任务的大规模高效模型奠定了基础。</li><li><strong>GPT-3 (2020)</strong>：该模型展示了规模在AI中的变革力量，证明了在大规模数据集上训练的巨大模型可以在广泛的应用中实现接近人类的表现，为AI所能完成的任务设立了新的基准。</li><li><strong>ChatGPT (2022)</strong>：通过将对话式AI带入主流，ChatGPT使高级AI对普通用户来说更加可访问和互动。它还引发了关于广泛采用AI的伦理和社会影响的关键讨论。</li><li><strong>DeepSeek-R1 (2025)</strong>：代表了成本效率的一大飞跃，DeepSeek-R1利用专家混合架构(MoE)和优化算法，与许多美国模型相比，运营成本降低了多达50倍。其开源性质加速尖端AI应用的普及化，赋予各行业创新者权力，并强调了可扩展性、对齐性和可访问性在塑造AI未来中的重要性</li></ul></div></div></main><footer class="VPDocFooter" data-v-39a288b8 data-v-e257564d><!--[--><!--]--><div class="edit-info" data-v-e257564d><div class="edit-link" data-v-e257564d><a class="VPLink link vp-external-link-icon no-icon edit-link-button" href="https://github.com/EthanLiu6/coderethan.fun/edit/master/docs/AI/01_deep_learning_theory/45-LLM-History.md" target="_blank" rel="noreferrer" data-v-e257564d><!--[--><span class="vpi-square-pen edit-link-icon" data-v-e257564d></span> 在 GitHub 上编辑此页面 OR 提出修改意见<!--]--></a></div><div class="last-updated" data-v-e257564d><p class="VPLastUpdated" data-v-e257564d data-v-e98dd255>最后更新于: <time datetime="2025-03-27T09:51:05.000Z" data-v-e98dd255></time></p></div></div><nav class="prev-next" aria-labelledby="doc-footer-aria-label" data-v-e257564d><span class="visually-hidden" id="doc-footer-aria-label" data-v-e257564d>Pager</span><div class="pager" data-v-e257564d><a class="VPLink link pager-link prev" href="/AI/01_deep_learning_theory/44-distribute-training.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>上一篇</span><span class="title" data-v-e257564d>44-distribute-training</span><!--]--></a></div><div class="pager" data-v-e257564d><a class="VPLink link pager-link next" href="/AI/01_deep_learning_theory/46-LLM-GPT-Extension.html" data-v-e257564d><!--[--><span class="desc" data-v-e257564d>下一篇</span><span class="title" data-v-e257564d>46-LLM-GPT-Extension</span><!--]--></a></div></nav></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><footer class="VPFooter has-sidebar" data-v-5d98c3a5 data-v-e315a0ad><div class="container" data-v-e315a0ad><p class="message" data-v-e315a0ad>ICP备案号: <a href="https://beian.miit.gov.cn/" target="_blank">蜀ICP备2024103116号</a><br>公安备案号: <a href="https://beian.mps.gov.cn/#/query/webSearch?code=51012202001928" rel="noreferrer" target="_blank">川公网安备51012202001928</a></p><p class="copyright" data-v-e315a0ad>版权所有 © 2024-present  <a href="mailto:16693226842@163.com" target="_blank">Ethan.Liu</a></p></div></footer><!--[--><!--]--></div></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"about_me_index.md\":\"mz4kR9Fi\",\"ai_01_deep_learning_theory_01-feedforward_network.md\":\"CcvQrxgt\",\"ai_01_deep_learning_theory_02-back_propagation.md\":\"BtjZwJU_\",\"ai_01_deep_learning_theory_03-bp_example_demo.md\":\"DDBE4U1G\",\"ai_01_deep_learning_theory_04-convolution_neural_network.md\":\"CxA35loH\",\"ai_01_deep_learning_theory_05-deep_learning_model.md\":\"Ct7liYj1\",\"ai_01_deep_learning_theory_06-pytorch_install.md\":\"Clcubooi\",\"ai_01_deep_learning_theory_07-operators.md\":\"kIS9XbIQ\",\"ai_01_deep_learning_theory_08-activation_functions.md\":\"B1C9PY4H\",\"ai_01_deep_learning_theory_09-recurrent_neural_network.md\":\"CzW3agM_\",\"ai_01_deep_learning_theory_10-seq2seq.md\":\"6D8B4Rlq\",\"ai_01_deep_learning_theory_11-1attentions.md\":\"Cvpw08iV\",\"ai_01_deep_learning_theory_11-2attention-extension.md\":\"DC_8b5oC\",\"ai_01_deep_learning_theory_12-weight-initialization.md\":\"C1v8tMs3\",\"ai_01_deep_learning_theory_13-optimizers.md\":\"BJt7iJF7\",\"ai_01_deep_learning_theory_14-regularization.md\":\"Bx5ZYl-4\",\"ai_01_deep_learning_theory_15-deep-learning-tuning-guide.md\":\"CWN3mKn4\",\"ai_01_deep_learning_theory_20-pytorch-tensor.md\":\"BFcyl0Px\",\"ai_01_deep_learning_theory_21-pytorch-autograd.md\":\"DS522bLB\",\"ai_01_deep_learning_theory_22-pytorch-module.md\":\"DjCl8s56\",\"ai_01_deep_learning_theory_23-1training-example-1.md\":\"DH8M-Obn\",\"ai_01_deep_learning_theory_23-2decoder.md\":\"Cq0AY57n\",\"ai_01_deep_learning_theory_23-3encoder.md\":\"D0g53JSA\",\"ai_01_deep_learning_theory_23-4transformer.md\":\"DHbayc0z\",\"ai_01_deep_learning_theory_24-pytorch-optimizer.md\":\"Bn_0Gw79\",\"ai_01_deep_learning_theory_25-pytorch-lr-scheduler.md\":\"DxyT4Fmr\",\"ai_01_deep_learning_theory_26-pytorch-dataloader.md\":\"RYWx6b8M\",\"ai_01_deep_learning_theory_27-pytorch-model-save.md\":\"B7Q4ONf_\",\"ai_01_deep_learning_theory_28-pytorch-tensorboard.md\":\"VHNB3XsJ\",\"ai_01_deep_learning_theory_29-pytorch-graph-mode.md\":\"BL6cmN4L\",\"ai_01_deep_learning_theory_30-1training-example-cv.md\":\"DRhcPsAc\",\"ai_01_deep_learning_theory_30-3main.md\":\"Ci1wkkl4\",\"ai_01_deep_learning_theory_31-1stable-diffusion.md\":\"7ssTYEJp\",\"ai_01_deep_learning_theory_31-2sdxl.md\":\"B5ng9y6A\",\"ai_01_deep_learning_theory_31-3vae.md\":\"Cxzp-WBt\",\"ai_01_deep_learning_theory_40-nlp-bert_ner.md\":\"CcuO1-mQ\",\"ai_01_deep_learning_theory_41-nlp-t5_question-answering.md\":\"_6IyzXZC\",\"ai_01_deep_learning_theory_42-nlp-gpt.md\":\"_Nxmo9wM\",\"ai_01_deep_learning_theory_43-scaling-law.md\":\"xoZlgvkY\",\"ai_01_deep_learning_theory_44-distribute-training.md\":\"CNK33TAz\",\"ai_01_deep_learning_theory_45-llm-history.md\":\"Czmd8z8v\",\"ai_01_deep_learning_theory_46-llm-gpt-extension.md\":\"DehUuq2v\",\"ai_01_deep_learning_theory_46-nlp-llama.md\":\"Cvowveq1\",\"ai_01_deep_learning_theory_47-llm-deepseek-structure.md\":\"REY-Au_D\",\"ai_01_deep_learning_theory_47-nlp-deepseek.md\":\"C1weFA21\",\"ai_01_deep_learning_theory_index.md\":\"DULtN52e\",\"ai_02_distribute_training_00_large-scale-model-trainning.md\":\"ScK-rTES\",\"ai_02_distribute_training_01_coding.md\":\"BpOoZXvs\",\"ai_02_distribute_training_01_offload-and-recompute.md\":\"DH1t2mgl\",\"ai_02_distribute_training_02_amp.md\":\"UHS_a1Tv\",\"ai_02_distribute_training_03_coding.md\":\"CmvCR_VM\",\"ai_02_distribute_training_03_pytorch-dp.md\":\"DlSpdrVa\",\"ai_02_distribute_training_04_pytorch-ddp.md\":\"BdX4eQnE\",\"ai_02_distribute_training_05_pytorch-ddp-impl.md\":\"C3ka-I-H\",\"ai_02_distribute_training_05_pytorch-ddp-impl_ddp_origin.md\":\"B0ExxsWg\",\"ai_02_distribute_training_06_collective-comm.md\":\"Cl7RSZCa\",\"ai_02_distribute_training_06_torchrun-process-group.md\":\"0t1Ne9wO\",\"ai_02_distribute_training_07_zero-optimizer.md\":\"C6XSUzAS\",\"ai_02_distribute_training_08_pytorch-zero-1.md\":\"ySTPyj3V\",\"ai_02_distribute_training_09_pytorch-fsdp-v1.md\":\"B72E4KDO\",\"ai_02_distribute_training_10_pytorch-fsdp-v2.md\":\"icJHYy7W\",\"ai_02_distribute_training_11_deepspeed-zero-1-2-impl.md\":\"qP_Pfxun\",\"ai_02_distribute_training_12_deepspeed-zero-3-impl.md\":\"Csv92XRa\",\"ai_02_distribute_training_13_megatron-zero-1-impl.md\":\"Db7_6tfb\",\"ai_02_distribute_training_14_tp-theory.md\":\"esuC_Liu\",\"ai_02_distribute_training_15_megatron-tp-impl.md\":\"DEVXuzJf\",\"ai_02_distribute_training_16_pytorch-tp-impl.md\":\"D8qf5ngw\",\"ai_02_distribute_training_17_pp-theory.md\":\"CM8M3C9i\",\"ai_02_distribute_training_18_pytorch-pp-impl.md\":\"B29AeAKF\",\"ai_02_distribute_training_19_deepspeed-pp-impl.md\":\"ChAcoPgP\",\"ai_02_distribute_training_20_megatron-pp-impl.md\":\"BUm1IzVm\",\"ai_02_distribute_training_21_sp-theory.md\":\"d7qyOraH\",\"ai_02_distribute_training_22_megatron-sp-impl.md\":\"D1orG262\",\"ai_02_distribute_training_23_3d-parallel-theory.md\":\"B1-vwyBl\",\"ai_02_distribute_training_24_megatron-3d-parallel-impl.md\":\"zPy3o2Oy\",\"ai_02_distribute_training_25_pytorch-3d-parallel-impl.md\":\"BVILcMDg\",\"ai_02_distribute_training_26_cp-theory.md\":\"B1coDnHY\",\"ai_02_distribute_training_27_megatron-cp-impl.md\":\"DdJsMNrL\",\"ai_02_distribute_training_28_moe-theory.md\":\"DMjnS_8q\",\"ai_02_distribute_training_28_moe-theory_deepseekmoe.md\":\"OTnWcHUV\",\"ai_02_distribute_training_29_megatron-moe-impl.md\":\"pJxFgCRW\",\"ai_02_distribute_training_30_deepspeed-moe-impl.md\":\"DGgDLvC2\",\"ai_02_distribute_training_31_deepspeed-code-impl.md\":\"WjUqYD_P\",\"ai_02_distribute_training_32_collective-operations.md\":\"DnU5ghvq\",\"ai_02_distribute_training_33_pytorch_distribute.md\":\"BJeB5n4-\",\"ai_02_distribute_training_index.md\":\"UwwL-uUg\",\"ai_03_transformer_01-transformer的由来.md\":\"CJuvJ6VA\",\"ai_03_transformer_02-transformer架构解读.md\":\"D7Q52fUF\",\"ai_03_transformer_03-transformer源码构建.md\":\"DNOcryKw\",\"ai_03_transformer_index.md\":\"CUW2DYfu\",\"ai_04_some_notes_00-dl_base_notes.md\":\"CugAcIEx\",\"ai_04_some_notes_01-class_logs.md\":\"CRBe6gh8\",\"ai_04_some_notes_02-some_detials.md\":\"WK9iM9IR\",\"ai_04_some_notes_03-bert理解.md\":\"D4ypihZd\",\"ai_04_some_notes_04-个人补充内容.md\":\"D67da2ij\",\"ai_04_some_notes_05-review_dl.md\":\"CB6AAWFj\",\"ai_04_some_notes_index.md\":\"BWjDxHIM\",\"ai_index.md\":\"FceT-BLG\",\"index.md\":\"DK1IDkdq\",\"it-learning_408_index.md\":\"DQ7Ub8n-\",\"it-learning_408_os-4.1 进程同步.md\":\"ImosRfCq\",\"it-learning_408_os-4.4 信号量机制.md\":\"CnMjdS0S\",\"it-learning_408_os-4.4 信号量机制pv操作之“可见”.md\":\"KW2s8fDp\",\"it-learning_c___01_开发环境搭建与基础数据类型.md\":\"DVAfnfKI\",\"it-learning_c___02_控制流语句与复合数据类型.md\":\"o_Iw4hag\",\"it-learning_c___03_指针与引用.md\":\"Bw6bYMMc\",\"it-learning_c___04_自定义数据类型与函数.md\":\"Cyyzd5R-\",\"it-learning_c___05_头文件与指针的算术运算.md\":\"DejaB1_U\",\"it-learning_c___06_字符串、数组、指针与函数.md\":\"D3aHSP55\",\"it-learning_c___07_函数进阶与内存管理.md\":\"DqUS2M8n\",\"it-learning_c___08_运算符优先级表.md\":\"CtazDwSH\",\"it-learning_c___09_指针、内存管理和类的基础.md\":\"L48egUic\",\"it-learning_c___10_深入类和对象.md\":\"BpLLILo4\",\"it-learning_c___11_类的大小、继承与权限控制.md\":\"DYFJyGgE\",\"it-learning_c___12_继承进阶.md\":\"CqNcG1Ig\",\"it-learning_c___13_类型转换和多态与虚函数.md\":\"DaeCEerH\",\"it-learning_c___14_纯虚函数、抽象类、深浅拷贝及智能指针.md\":\"B5cvBNtL\",\"it-learning_c___15_运算符重载与 string 类详解.md\":\"CZX-FnOl\",\"it-learning_c___16_有序容器与无序容器.md\":\"CJwgGEAo\",\"it-learning_c___17_模板.md\":\"4CdEsdGf\",\"it-learning_c___18_迭代器与其应用.md\":\"DmftJhgX\",\"it-learning_c___19_c__ 标准库常用算法.md\":\"Bymm15dk\",\"it-learning_c___20_c__ 异常处理 - 第19次课.md\":\"Sn8BieQI\",\"it-learning_c___21_友元及友元相关内容.md\":\"D1xuHqMb\",\"it-learning_c___22_c__ io 流详解-feadbc607d7f.md\":\"BD7P3tXk\",\"it-learning_c___23_c__ io 流详解.md\":\"azsZ5g77\",\"it-learning_c___24_位运算符总结.md\":\"BOkaz89o\",\"it-learning_c___25_c__三种继承方式.md\":\"DUn7n_et\",\"it-learning_c___26_c__11 高级特性.md\":\"CyrPVDkT\",\"it-learning_c___27_c__14 新特性.md\":\"6YQuRCGz\",\"it-learning_c___28_c__17 新特性.md\":\"BqJAdDo-\",\"it-learning_c___29_多文件和 makefile工程管理.md\":\"DvfAbEZ0\",\"it-learning_c___30_c__大型项目cmake工程管理.md\":\"CJvCgGVT\",\"it-learning_c___31_c__ 主要就业方向与技术能力分析报告.md\":\"CqJbtbjv\",\"it-learning_c___32_c__ 基础知识回顾.md\":\"Dx5_xIPx\",\"it-learning_c___index.md\":\"BAg94tAw\",\"it-learning_index.md\":\"D1maUb85\",\"it-learning_java_01.java-se.md\":\"CV9z-Ph2\",\"it-learning_java_02.sql.md\":\"gilr6jOh\",\"it-learning_java_03.java-web.md\":\"DXRkrx3K\",\"it-learning_java_05.mybatis.md\":\"HjU_MlJz\",\"it-learning_java_index.md\":\"DkRBc8cW\",\"it-learning_linux_01.linux基础.md\":\"BBs1RcBf\",\"it-learning_linux_02.shell.md\":\"BCfUk33T\",\"it-learning_linux_03.mpi并行计算.md\":\"gpRl9TGp\",\"it-learning_linux_04.docker.md\":\"DN_C173y\",\"it-learning_linux_index.md\":\"BVALaZgc\",\"job_interview_algorithm_post_index.md\":\"hS-i5N_u\",\"job_interview_algorithm_post_model_framework_001_transformer.md\":\"LvqqCzf9\",\"job_interview_algorithm_post_model_framework_002_normalization.md\":\"N-q7VS0F\",\"job_interview_algorithm_post_model_framework_003_position-embedding.md\":\"BzS9FT0f\",\"job_interview_algorithm_post_model_framework_004_activation.md\":\"CxfcY-oh\",\"job_interview_algorithm_post_model_framework_005_transformer-other.md\":\"B2njneQr\",\"job_interview_algorithm_post_model_framework_006_llm-frame.md\":\"DGroGrLz\",\"job_interview_algorithm_post_model_framework_007_moe.md\":\"BMQgyvEU\",\"job_interview_algorithm_post_model_framework_基础内容面试点.md\":\"B1pwzhK0\",\"job_interview_algorithm_post_model_framework_手撕内容.md\":\"DuGvZX1g\",\"job_interview_algorithm_post_sum_knowledge_index.md\":\"DTUo71x7\",\"job_interview_algorithm_post_sum_knowledge_p0-00_场景题.md\":\"Z5BhOUcP\",\"job_interview_algorithm_post_sum_knowledge_p1-01_分词器.md\":\"DG2eb09I\",\"job_interview_algorithm_post_sum_knowledge_p1-02_词向量.md\":\"DjxrHTfc\",\"job_interview_algorithm_post_sum_knowledge_p2-01_注意力机制.md\":\"BGzOB_m0\",\"job_interview_algorithm_post_sum_knowledge_p2-02_位置编码.md\":\"CMuG2lT2\",\"job_interview_algorithm_post_sum_knowledge_p2-03_归一化.md\":\"Cq0n4AiK\",\"job_interview_algorithm_post_sum_knowledge_p2-04_残差连接.md\":\"DuEkWZPo\",\"job_interview_algorithm_post_sum_knowledge_p3-01_多层感知机.md\":\"Lo5LuBKV\",\"job_interview_algorithm_post_sum_knowledge_p3-02_激活函数.md\":\"B5tCzgM2\",\"job_interview_algorithm_post_sum_knowledge_p3-03_损失函数.md\":\"3OZi1xk0\",\"job_interview_algorithm_post_sum_knowledge_p4-01_预训练技术.md\":\"DjankyqI\",\"job_interview_algorithm_post_sum_knowledge_p5-01_后训练技术.md\":\"J2ab4E7V\",\"job_interview_algorithm_post_sum_knowledge_p6-01_推理优化.md\":\"nrc9Je7c\",\"job_interview_algorithm_post_sum_knowledge_p7-01_大模型架构.md\":\"BcXRF7RO\",\"job_interview_algorithm_post_sum_knowledge_p8_01_大模型应用.md\":\"C7EIiF_5\",\"job_interview_algorithm_post_sum_knowledge_p9-01_torch的数据.md\":\"DU-tVO0q\",\"job_interview_index.md\":\"CK06T0i_\",\"job_interview_java_index.md\":\"C0TwjbqV\",\"my_think_01_不同商家的视野.md\":\"oNKuD8ev\",\"my_think_02_学而篇.md\":\"DIXp_fou\",\"my_think_03_重温士兵突击.md\":\"iuGDsQYW\",\"my_think_04_你很好，慢慢来.md\":\"D80QW609\",\"my_think_05_健康是第一重要.md\":\"xhbjArk5\",\"my_think_index.md\":\"Ys8bgN2a\",\"question_list_doccano账户管理.md\":\"4xMMl7Bn\",\"question_list_index.md\":\"Bx3eFS0B\",\"question_list_专英翻转课堂—pytorch.md\":\"C2nclqWo\",\"question_list_虚拟机网络问题.md\":\"Cxh_Plki\",\"readme.md\":\"DJufORId\",\"update_update_log.md\":\"axEQFBi_\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"zh-CN\",\"dir\":\"ltr\",\"title\":\"码医森\",\"description\":\"计算机知识的学习站点\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":true,\"themeConfig\":{\"siteTitle\":\"CoderEthan学习站\",\"logo\":\"/imgs/home-page-logo.svg\",\"outline\":{\"label\":\"本文目录\",\"level\":[2,4]},\"search\":{\"provider\":\"local\"},\"socialLinks\":[{\"icon\":{\"svg\":\"<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" viewBox=\\\"0 0 496 512\\\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\\\"#6841d2\\\" d=\\\"M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3 .3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5 .3-6.2 2.3zm44.2-1.7c-2.9 .7-4.9 2.6-4.6 4.9 .3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3 .7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3 .3 2.9 2.3 3.9 1.6 1 3.6 .7 4.3-.7 .7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3 .7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3 .7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z\\\"/></svg>\"},\"link\":\"https://github.com/ethanliu6/\"},{\"icon\":{\"svg\":\"<svg xmlns=\\\"http://www.w3.org/2000/svg\\\" viewBox=\\\"0 0 512 512\\\"><!--!Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free Copyright 2024 Fonticons, Inc.--><path fill=\\\"#6841d2\\\" d=\\\"M488.6 104.1C505.3 122.2 513 143.8 511.9 169.8V372.2C511.5 398.6 502.7 420.3 485.4 437.3C468.2 454.3 446.3 463.2 419.9 464H92C65.6 463.2 43.8 454.2 26.7 436.8C9.7 419.4 .8 396.5 0 368.2V169.8C.8 143.8 9.7 122.2 26.7 104.1C43.8 87.8 65.6 78.8 92 78H121.4L96.1 52.2C90.3 46.5 87.4 39.2 87.4 30.4C87.4 21.6 90.3 14.3 96.1 8.6C101.8 2.9 109.1 0 117.9 0C126.7 0 134 2.9 139.8 8.6L213.1 78H301.1L375.6 8.6C381.7 2.9 389.2 0 398 0C406.8 0 414.1 2.9 419.9 8.6C425.6 14.3 428.5 21.6 428.5 30.4C428.5 39.2 425.6 46.5 419.9 52.2L394.6 78L423.9 78C450.3 78.8 471.9 87.8 488.6 104.1H488.6zM449.8 173.8C449.4 164.2 446.1 156.4 439.1 150.3C433.9 144.2 425.1 140.9 416.4 140.5H96.1C86.5 140.9 78.6 144.2 72.5 150.3C66.3 156.4 63.1 164.2 62.7 173.8V368.2C62.7 377.4 66 385.2 72.5 391.7C79 398.2 86.9 401.5 96.1 401.5H416.4C425.6 401.5 433.4 398.2 439.7 391.7C446 385.2 449.4 377.4 449.8 368.2L449.8 173.8zM185.5 216.5C191.8 222.8 195.2 230.6 195.6 239.7V273C195.2 282.2 191.9 289.9 185.8 296.2C179.6 302.5 171.8 305.7 162.2 305.7C152.6 305.7 144.7 302.5 138.6 296.2C132.5 289.9 129.2 282.2 128.8 273V239.7C129.2 230.6 132.6 222.8 138.9 216.5C145.2 210.2 152.1 206.9 162.2 206.5C171.4 206.9 179.2 210.2 185.5 216.5H185.5zM377 216.5C383.3 222.8 386.7 230.6 387.1 239.7V273C386.7 282.2 383.4 289.9 377.3 296.2C371.2 302.5 363.3 305.7 353.7 305.7C344.1 305.7 336.3 302.5 330.1 296.2C323.1 289.9 320.7 282.2 320.4 273V239.7C320.7 230.6 324.1 222.8 330.4 216.5C336.7 210.2 344.5 206.9 353.7 206.5C362.9 206.9 370.7 210.2 377 216.5H377z\\\"/></svg>\"},\"link\":\"https://space.bilibili.com/1327099977/\"}],\"nav\":[{\"text\":\"AI\",\"items\":[{\"text\":\"DL基础理论\",\"link\":\"/AI/01_deep_learning_theory/\"},{\"text\":\"分布式训练\",\"link\":\"/AI/02_distribute_training/\"},{\"text\":\"Transformer个人梳理\",\"link\":\"/AI/03_Transformer/\"},{\"text\":\"DL个人笔记\",\"link\":\"/AI/04_some_notes/\"}]},{\"text\":\"计算机学科内容\",\"items\":[{\"text\":\"408知识\",\"link\":\"/IT-learning/408/\"},{\"text\":\"C++基础\",\"link\":\"/IT-learning/c++/\"},{\"text\":\"Java后端\",\"link\":\"/IT-learning/Java/\"},{\"text\":\"Linux技术\",\"link\":\"/IT-learning/Linux/\"}]},{\"text\":\"求职面试\",\"items\":[{\"text\":\"Java面经\",\"link\":\"/Job_Interview/Java/\"},{\"text\":\"算法岗\",\"link\":\"/Job_Interview/Algorithm_post/\"}]},{\"text\":\"其他维护\",\"items\":[{\"text\":\"站点更新\",\"link\":\"/update/update_log\"},{\"text\":\"问题清单\",\"link\":\"/question_list/\"}]},{\"text\":\"感悟和日常\",\"items\":[{\"text\":\"关于我\",\"link\":\"/about_me/\"},{\"text\":\"站长感悟\",\"link\":\"/my_think/\"},{\"text\":\"旧版博客\",\"link\":\"https://EthanLiu6.github.io\"}]}],\"footer\":{\"message\":\"ICP备案号: <a href=\\\"https://beian.miit.gov.cn/\\\" target=\\\"_blank\\\">蜀ICP备2024103116号</a><br>公安备案号: <a href=\\\"https://beian.mps.gov.cn/#/query/webSearch?code=51012202001928\\\" rel=\\\"noreferrer\\\" target=\\\"_blank\\\">川公网安备51012202001928</a>\",\"copyright\":\"版权所有 © 2024-present  <a href=\\\"mailto:16693226842@163.com\\\" target=\\\"_blank\\\">Ethan.Liu</a>\"},\"editLink\":{\"pattern\":\"https://github.com/EthanLiu6/coderethan.fun/edit/master/docs/:path\",\"text\":\"在 GitHub 上编辑此页面 OR 提出修改意见\"},\"lastUpdated\":{\"text\":\"最后更新于\",\"formatOptions\":{\"dateStyle\":\"long\",\"timeStyle\":\"short\"}},\"docFooter\":{\"prev\":\"上一篇\",\"next\":\"下一篇\"},\"darkModeSwitchLabel\":\"深色模式\",\"lightModeSwitchTitle\":\"切换到浅色模式\",\"darkModeSwitchTitle\":\"切换到深色模式\",\"sidebar\":{\"/AI/\":[{\"items\":[{\"text\":\"01_deep_learning_theory\",\"items\":[{\"text\":\"01-feedforward_network\",\"link\":\"/AI/01_deep_learning_theory/01-feedforward_network.html\"},{\"text\":\"02-back_propagation\",\"link\":\"/AI/01_deep_learning_theory/02-back_propagation.html\"},{\"text\":\"03-bp_example_demo\",\"link\":\"/AI/01_deep_learning_theory/03-bp_example_demo.html\"},{\"text\":\"04-convolution_neural_network\",\"link\":\"/AI/01_deep_learning_theory/04-convolution_neural_network.html\"},{\"text\":\"05-deep_learning_model\",\"link\":\"/AI/01_deep_learning_theory/05-deep_learning_model.html\"},{\"text\":\"06-pytorch_install\",\"link\":\"/AI/01_deep_learning_theory/06-pytorch_install.html\"},{\"text\":\"07-operators\",\"link\":\"/AI/01_deep_learning_theory/07-operators.html\"},{\"text\":\"08-activation_functions\",\"link\":\"/AI/01_deep_learning_theory/08-activation_functions.html\"},{\"text\":\"09-recurrent_neural_network\",\"link\":\"/AI/01_deep_learning_theory/09-recurrent_neural_network.html\"},{\"text\":\"10-seq2seq\",\"link\":\"/AI/01_deep_learning_theory/10-seq2seq.html\"},{\"text\":\"11-1attentions\",\"link\":\"/AI/01_deep_learning_theory/11-1attentions.html\"},{\"text\":\"11-2attention-extension\",\"link\":\"/AI/01_deep_learning_theory/11-2attention-extension.html\"},{\"text\":\"12-weight-initialization\",\"link\":\"/AI/01_deep_learning_theory/12-weight-initialization.html\"},{\"text\":\"13-optimizers\",\"link\":\"/AI/01_deep_learning_theory/13-optimizers.html\"},{\"text\":\"14-regularization\",\"link\":\"/AI/01_deep_learning_theory/14-regularization.html\"},{\"text\":\"15-deep-learning-tuning-guide\",\"link\":\"/AI/01_deep_learning_theory/15-deep-learning-tuning-guide.html\"},{\"text\":\"20-pytorch-tensor\",\"link\":\"/AI/01_deep_learning_theory/20-pytorch-tensor.html\"},{\"text\":\"21-pytorch-autograd\",\"link\":\"/AI/01_deep_learning_theory/21-pytorch-autograd.html\"},{\"text\":\"22-pytorch-module\",\"link\":\"/AI/01_deep_learning_theory/22-pytorch-module.html\"},{\"text\":\"23-1training-example-1\",\"link\":\"/AI/01_deep_learning_theory/23-1training-example-1.html\"},{\"text\":\"23-2decoder\",\"link\":\"/AI/01_deep_learning_theory/23-2decoder.html\"},{\"text\":\"23-3encoder\",\"link\":\"/AI/01_deep_learning_theory/23-3encoder.html\"},{\"text\":\"23-4transformer\",\"link\":\"/AI/01_deep_learning_theory/23-4transformer.html\"},{\"text\":\"24-pytorch-optimizer\",\"link\":\"/AI/01_deep_learning_theory/24-pytorch-optimizer.html\"},{\"text\":\"25-pytorch-lr-scheduler\",\"link\":\"/AI/01_deep_learning_theory/25-pytorch-lr-scheduler.html\"},{\"text\":\"26-pytorch-dataloader\",\"link\":\"/AI/01_deep_learning_theory/26-pytorch-dataloader.html\"},{\"text\":\"27-pytorch-model-save\",\"link\":\"/AI/01_deep_learning_theory/27-pytorch-model-save.html\"},{\"text\":\"28-pytorch-tensorboard\",\"link\":\"/AI/01_deep_learning_theory/28-pytorch-tensorboard.html\"},{\"text\":\"29-pytorch-graph-mode\",\"link\":\"/AI/01_deep_learning_theory/29-pytorch-graph-mode.html\"},{\"text\":\"30-1training-example-cv\",\"link\":\"/AI/01_deep_learning_theory/30-1training-example-cv.html\"},{\"text\":\"30-3main\",\"link\":\"/AI/01_deep_learning_theory/30-3main.html\"},{\"text\":\"31-1stable-diffusion\",\"link\":\"/AI/01_deep_learning_theory/31-1stable-diffusion.html\"},{\"text\":\"31-2SDXL\",\"link\":\"/AI/01_deep_learning_theory/31-2SDXL.html\"},{\"text\":\"31-3VAE\",\"link\":\"/AI/01_deep_learning_theory/31-3VAE.html\"},{\"text\":\"40-nlp-bert_ner\",\"link\":\"/AI/01_deep_learning_theory/40-nlp-bert_ner.html\"},{\"text\":\"41-nlp-t5_question-answering\",\"link\":\"/AI/01_deep_learning_theory/41-nlp-t5_question-answering.html\"},{\"text\":\"42-nlp-gpt\",\"link\":\"/AI/01_deep_learning_theory/42-nlp-gpt.html\"},{\"text\":\"43-scaling-law\",\"link\":\"/AI/01_deep_learning_theory/43-scaling-law.html\"},{\"text\":\"44-distribute-training\",\"link\":\"/AI/01_deep_learning_theory/44-distribute-training.html\"},{\"text\":\"45-LLM-History\",\"link\":\"/AI/01_deep_learning_theory/45-LLM-History.html\"},{\"text\":\"46-LLM-GPT-Extension\",\"link\":\"/AI/01_deep_learning_theory/46-LLM-GPT-Extension.html\"},{\"text\":\"46-nlp-llama\",\"link\":\"/AI/01_deep_learning_theory/46-nlp-llama.html\"},{\"text\":\"47-LLM-DeepSeek-Structure\",\"link\":\"/AI/01_deep_learning_theory/47-LLM-DeepSeek-Structure.html\"},{\"text\":\"47-nlp-deepseek\",\"link\":\"/AI/01_deep_learning_theory/47-nlp-deepseek.html\"}],\"collapsed\":true},{\"text\":\"02_distribute_training\",\"items\":[{\"text\":\"00_large-scale-model-trainning\",\"link\":\"/AI/02_distribute_training/00_large-scale-model-trainning.html\"},{\"text\":\"01_coding\",\"link\":\"/AI/02_distribute_training/01_coding.html\"},{\"text\":\"01_offload-and-recompute\",\"link\":\"/AI/02_distribute_training/01_offload-and-recompute.html\"},{\"text\":\"02_amp\",\"link\":\"/AI/02_distribute_training/02_amp.html\"},{\"text\":\"03_coding\",\"link\":\"/AI/02_distribute_training/03_coding.html\"},{\"text\":\"03_pytorch-DP\",\"link\":\"/AI/02_distribute_training/03_pytorch-DP.html\"},{\"text\":\"04_pytorch-DDP\",\"link\":\"/AI/02_distribute_training/04_pytorch-DDP.html\"},{\"text\":\"05_pytorch-DDP-IMPL\",\"link\":\"/AI/02_distribute_training/05_pytorch-DDP-IMPL.html\"},{\"text\":\"05_pytorch-DDP-IMPL_DDP_ORIGIN\",\"link\":\"/AI/02_distribute_training/05_pytorch-DDP-IMPL_DDP_ORIGIN.html\"},{\"text\":\"06_collective-comm\",\"link\":\"/AI/02_distribute_training/06_collective-comm.html\"},{\"text\":\"06_torchrun-process-group\",\"link\":\"/AI/02_distribute_training/06_torchrun-process-group.html\"},{\"text\":\"07_ZeRO-Optimizer\",\"link\":\"/AI/02_distribute_training/07_ZeRO-Optimizer.html\"},{\"text\":\"08_pytorch-ZeRO-1\",\"link\":\"/AI/02_distribute_training/08_pytorch-ZeRO-1.html\"},{\"text\":\"09_pytorch-FSDP-v1\",\"link\":\"/AI/02_distribute_training/09_pytorch-FSDP-v1.html\"},{\"text\":\"10_pytorch-FSDP-v2\",\"link\":\"/AI/02_distribute_training/10_pytorch-FSDP-v2.html\"},{\"text\":\"11_deepspeed-ZeRO-1-2-IMPL\",\"link\":\"/AI/02_distribute_training/11_deepspeed-ZeRO-1-2-IMPL.html\"},{\"text\":\"12_deepspeed-ZeRO-3-IMPL\",\"link\":\"/AI/02_distribute_training/12_deepspeed-ZeRO-3-IMPL.html\"},{\"text\":\"13_megatron-ZeRO-1-IMPL\",\"link\":\"/AI/02_distribute_training/13_megatron-ZeRO-1-IMPL.html\"},{\"text\":\"14_TP-Theory\",\"link\":\"/AI/02_distribute_training/14_TP-Theory.html\"},{\"text\":\"15_megatron-TP-IMPL\",\"link\":\"/AI/02_distribute_training/15_megatron-TP-IMPL.html\"},{\"text\":\"16_pytorch-TP-IMPL\",\"link\":\"/AI/02_distribute_training/16_pytorch-TP-IMPL.html\"},{\"text\":\"17_PP-Theory\",\"link\":\"/AI/02_distribute_training/17_PP-Theory.html\"},{\"text\":\"18_pytorch-PP-IMPL\",\"link\":\"/AI/02_distribute_training/18_pytorch-PP-IMPL.html\"},{\"text\":\"19_deepspeed-PP-IMPL\",\"link\":\"/AI/02_distribute_training/19_deepspeed-PP-IMPL.html\"},{\"text\":\"20_megatron-PP-IMPL\",\"link\":\"/AI/02_distribute_training/20_megatron-PP-IMPL.html\"},{\"text\":\"21_SP-Theory\",\"link\":\"/AI/02_distribute_training/21_SP-Theory.html\"},{\"text\":\"22_megatron-SP-IMPL\",\"link\":\"/AI/02_distribute_training/22_megatron-SP-IMPL.html\"},{\"text\":\"23_3D-Parallel-Theory\",\"link\":\"/AI/02_distribute_training/23_3D-Parallel-Theory.html\"},{\"text\":\"24_megatron-3D-Parallel-IMPL\",\"link\":\"/AI/02_distribute_training/24_megatron-3D-Parallel-IMPL.html\"},{\"text\":\"25_pytorch-3D-Parallel-IMPL\",\"link\":\"/AI/02_distribute_training/25_pytorch-3D-Parallel-IMPL.html\"},{\"text\":\"26_CP-Theory\",\"link\":\"/AI/02_distribute_training/26_CP-Theory.html\"},{\"text\":\"27_megatron-CP-IMPL\",\"link\":\"/AI/02_distribute_training/27_megatron-CP-IMPL.html\"},{\"text\":\"28_MOE-Theory\",\"link\":\"/AI/02_distribute_training/28_MOE-Theory.html\"},{\"text\":\"28_MOE-Theory_DeepSeekMOE\",\"link\":\"/AI/02_distribute_training/28_MOE-Theory_DeepSeekMOE.html\"},{\"text\":\"29_megatron-MOE-IMPL\",\"link\":\"/AI/02_distribute_training/29_megatron-MOE-IMPL.html\"},{\"text\":\"30_deepspeed-MOE-IMPL\",\"link\":\"/AI/02_distribute_training/30_deepspeed-MOE-IMPL.html\"},{\"text\":\"31_deepspeed-code-IMPL\",\"link\":\"/AI/02_distribute_training/31_deepspeed-code-IMPL.html\"},{\"text\":\"32_collective-operations\",\"link\":\"/AI/02_distribute_training/32_collective-operations.html\"},{\"text\":\"33_pytorch_distribute\",\"link\":\"/AI/02_distribute_training/33_pytorch_distribute.html\"}],\"collapsed\":true},{\"text\":\"03_Transformer\",\"items\":[{\"text\":\"01-Transformer的由来\",\"link\":\"/AI/03_Transformer/01-Transformer的由来.html\"},{\"text\":\"02-Transformer架构解读\",\"link\":\"/AI/03_Transformer/02-Transformer架构解读.html\"},{\"text\":\"03-Transformer源码构建\",\"link\":\"/AI/03_Transformer/03-Transformer源码构建.html\"}],\"collapsed\":true},{\"text\":\"04_some_notes\",\"items\":[{\"text\":\"00-DL_base_notes\",\"link\":\"/AI/04_some_notes/00-DL_base_notes.html\"},{\"text\":\"01-class_logs\",\"link\":\"/AI/04_some_notes/01-class_logs.html\"},{\"text\":\"02-some_detials\",\"link\":\"/AI/04_some_notes/02-some_detials.html\"},{\"text\":\"03-Bert理解\",\"link\":\"/AI/04_some_notes/03-Bert理解.html\"},{\"text\":\"04-个人补充内容\",\"link\":\"/AI/04_some_notes/04-个人补充内容.html\"},{\"text\":\"05-Review_DL\",\"link\":\"/AI/04_some_notes/05-Review_DL.html\"}],\"collapsed\":true}]}],\"/IT-learning/\":[{\"items\":[{\"text\":\"408\",\"items\":[{\"text\":\"OS-4.1 进程同步\",\"link\":\"/IT-learning/408/OS-4.1 进程同步.html\"},{\"text\":\"OS-4.4 信号量机制\",\"link\":\"/IT-learning/408/OS-4.4 信号量机制.html\"},{\"text\":\"OS-4.4 信号量机制pv操作之“可见”\",\"link\":\"/IT-learning/408/OS-4.4 信号量机制pv操作之“可见”.html\"}],\"collapsed\":true},{\"text\":\"Java\",\"items\":[{\"text\":\"01.java-se\",\"link\":\"/IT-learning/Java/01.java-se.html\"},{\"text\":\"02.sql\",\"link\":\"/IT-learning/Java/02.sql.html\"},{\"text\":\"03.java-web\",\"link\":\"/IT-learning/Java/03.java-web.html\"},{\"text\":\"05.MyBatis\",\"link\":\"/IT-learning/Java/05.MyBatis.html\"}],\"collapsed\":true},{\"text\":\"Linux\",\"items\":[{\"text\":\"01.Linux基础\",\"link\":\"/IT-learning/Linux/01.Linux基础.html\"},{\"text\":\"02.Shell\",\"link\":\"/IT-learning/Linux/02.Shell.html\"},{\"text\":\"03.MPI并行计算\",\"link\":\"/IT-learning/Linux/03.MPI并行计算.html\"},{\"text\":\"04.Docker\",\"link\":\"/IT-learning/Linux/04.Docker.html\"}],\"collapsed\":true},{\"text\":\"c++\",\"items\":[{\"text\":\"01_开发环境搭建与基础数据类型\",\"link\":\"/IT-learning/c++/01_开发环境搭建与基础数据类型.html\"},{\"text\":\"02_控制流语句与复合数据类型\",\"link\":\"/IT-learning/c++/02_控制流语句与复合数据类型.html\"},{\"text\":\"03_指针与引用\",\"link\":\"/IT-learning/c++/03_指针与引用.html\"},{\"text\":\"04_自定义数据类型与函数\",\"link\":\"/IT-learning/c++/04_自定义数据类型与函数.html\"},{\"text\":\"05_头文件与指针的算术运算\",\"link\":\"/IT-learning/c++/05_头文件与指针的算术运算.html\"},{\"text\":\"06_字符串、数组、指针与函数\",\"link\":\"/IT-learning/c++/06_字符串、数组、指针与函数.html\"},{\"text\":\"07_函数进阶与内存管理\",\"link\":\"/IT-learning/c++/07_函数进阶与内存管理.html\"},{\"text\":\"08_运算符优先级表\",\"link\":\"/IT-learning/c++/08_运算符优先级表.html\"},{\"text\":\"09_指针、内存管理和类的基础\",\"link\":\"/IT-learning/c++/09_指针、内存管理和类的基础.html\"},{\"text\":\"10_深入类和对象\",\"link\":\"/IT-learning/c++/10_深入类和对象.html\"},{\"text\":\"11_类的大小、继承与权限控制\",\"link\":\"/IT-learning/c++/11_类的大小、继承与权限控制.html\"},{\"text\":\"12_继承进阶\",\"link\":\"/IT-learning/c++/12_继承进阶.html\"},{\"text\":\"13_类型转换和多态与虚函数\",\"link\":\"/IT-learning/c++/13_类型转换和多态与虚函数.html\"},{\"text\":\"14_纯虚函数、抽象类、深浅拷贝及智能指针\",\"link\":\"/IT-learning/c++/14_纯虚函数、抽象类、深浅拷贝及智能指针.html\"},{\"text\":\"15_运算符重载与 String 类详解\",\"link\":\"/IT-learning/c++/15_运算符重载与 String 类详解.html\"},{\"text\":\"16_有序容器与无序容器\",\"link\":\"/IT-learning/c++/16_有序容器与无序容器.html\"},{\"text\":\"17_模板\",\"link\":\"/IT-learning/c++/17_模板.html\"},{\"text\":\"18_迭代器与其应用\",\"link\":\"/IT-learning/c++/18_迭代器与其应用.html\"},{\"text\":\"19_C++ 标准库常用算法\",\"link\":\"/IT-learning/c++/19_C++ 标准库常用算法.html\"},{\"text\":\"20_C++ 异常处理 - 第19次课\",\"link\":\"/IT-learning/c++/20_C++ 异常处理 - 第19次课.html\"},{\"text\":\"21_友元及友元相关内容\",\"link\":\"/IT-learning/c++/21_友元及友元相关内容.html\"},{\"text\":\"22_C++ IO 流详解-feadbc607d7f\",\"link\":\"/IT-learning/c++/22_C++ IO 流详解-feadbc607d7f.html\"},{\"text\":\"23_C++ IO 流详解\",\"link\":\"/IT-learning/c++/23_C++ IO 流详解.html\"},{\"text\":\"24_位运算符总结\",\"link\":\"/IT-learning/c++/24_位运算符总结.html\"},{\"text\":\"25_C++三种继承方式\",\"link\":\"/IT-learning/c++/25_C++三种继承方式.html\"},{\"text\":\"26_C++11 高级特性\",\"link\":\"/IT-learning/c++/26_C++11 高级特性.html\"},{\"text\":\"27_C++14 新特性\",\"link\":\"/IT-learning/c++/27_C++14 新特性.html\"},{\"text\":\"28_C++17 新特性\",\"link\":\"/IT-learning/c++/28_C++17 新特性.html\"},{\"text\":\"29_多文件和 Makefile工程管理\",\"link\":\"/IT-learning/c++/29_多文件和 Makefile工程管理.html\"},{\"text\":\"30_C++大型项目CMake工程管理\",\"link\":\"/IT-learning/c++/30_C++大型项目CMake工程管理.html\"},{\"text\":\"31_C++ 主要就业方向与技术能力分析报告\",\"link\":\"/IT-learning/c++/31_C++ 主要就业方向与技术能力分析报告.html\"},{\"text\":\"32_C++ 基础知识回顾\",\"link\":\"/IT-learning/c++/32_C++ 基础知识回顾.html\"}],\"collapsed\":true}]}],\"/Job_Interview/\":[{\"items\":[{\"text\":\"Algorithm_post\",\"items\":[{\"text\":\"model_framework\",\"items\":[{\"text\":\"001_Transformer\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/001_Transformer.html\"},{\"text\":\"002_Normalization\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/002_Normalization.html\"},{\"text\":\"003_Position-Embedding\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/003_Position-Embedding.html\"},{\"text\":\"004_Activation\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/004_Activation.html\"},{\"text\":\"005_Transformer-Other\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/005_Transformer-Other.html\"},{\"text\":\"006_LLM-Frame\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/006_LLM-Frame.html\"},{\"text\":\"007_MoE\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/007_MoE.html\"},{\"text\":\"基础内容面试点\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/基础内容面试点.html\"},{\"text\":\"手撕内容\",\"link\":\"/Job_Interview/Algorithm_post/model_framework/手撕内容.html\"}],\"collapsed\":true},{\"text\":\"sum_knowledge\",\"items\":[{\"text\":\"p0-00_场景题\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p0-00_场景题.html\"},{\"text\":\"p1-01_分词器\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p1-01_分词器.html\"},{\"text\":\"p1-02_词向量\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p1-02_词向量.html\"},{\"text\":\"p2-01_注意力机制\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p2-01_注意力机制.html\"},{\"text\":\"p2-02_位置编码\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p2-02_位置编码.html\"},{\"text\":\"p2-03_归一化\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p2-03_归一化.html\"},{\"text\":\"p2-04_残差连接\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p2-04_残差连接.html\"},{\"text\":\"p3-01_多层感知机\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p3-01_多层感知机.html\"},{\"text\":\"p3-02_激活函数\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p3-02_激活函数.html\"},{\"text\":\"p3-03_损失函数\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p3-03_损失函数.html\"},{\"text\":\"p4-01_预训练技术\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p4-01_预训练技术.html\"},{\"text\":\"p5-01_后训练技术\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p5-01_后训练技术.html\"},{\"text\":\"p6-01_推理优化\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p6-01_推理优化.html\"},{\"text\":\"p7-01_大模型架构\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p7-01_大模型架构.html\"},{\"text\":\"p8_01_大模型应用\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p8_01_大模型应用.html\"},{\"text\":\"p9-01_torch的数据\",\"link\":\"/Job_Interview/Algorithm_post/sum_knowledge/p9-01_torch的数据.html\"}],\"collapsed\":true}],\"collapsed\":true}]}],\"/my_think/\":[{\"items\":[{\"text\":\"01_不同商家的视野\",\"link\":\"/my_think/01_不同商家的视野.html\"},{\"text\":\"02_学而篇\",\"link\":\"/my_think/02_学而篇.html\"},{\"text\":\"03_重温士兵突击\",\"link\":\"/my_think/03_重温士兵突击.html\"},{\"text\":\"04_你很好，慢慢来\",\"link\":\"/my_think/04_你很好，慢慢来.html\"},{\"text\":\"05_健康是第一重要\",\"link\":\"/my_think/05_健康是第一重要.html\"}]}],\"/question_list/\":[{\"items\":[{\"text\":\"doccano账户管理\",\"link\":\"/question_list/doccano账户管理.html\"},{\"text\":\"专英翻转课堂—PyTorch\",\"link\":\"/question_list/专英翻转课堂—PyTorch.html\"},{\"text\":\"虚拟机网络问题\",\"link\":\"/question_list/虚拟机网络问题.html\"}]}],\"/update/\":[{\"items\":[{\"text\":\"update_log\",\"link\":\"/update/update_log.html\"}]}]}},\"locales\":{},\"scrollOffset\":134,\"cleanUrls\":false}");</script>
    
  </body>
</html>